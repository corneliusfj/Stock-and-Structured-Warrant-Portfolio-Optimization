{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMvmi20iXtZ7"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1pHMK_F0-s-"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade pandas\n",
        "#!pip install --upgrade pandas-datareader\n",
        "!pip install yfinance\n",
        "!pip install PyPortfolioOpt\n",
        "!poetry add PyPortfolioOpt\n",
        "!apt-get install python3.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRxJdOSmm84L"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "from scipy.stats import *\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Importing numpy, pandas and Series + DataFrame:\n",
        "import numpy as np\n",
        "import numpy.linalg\n",
        "from numpy.linalg import inv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "# Imports for plotly:\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# To keep graph within the nobebook:\n",
        "%matplotlib inline\n",
        "\n",
        "# To hide warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import for datareading:\n",
        "import pandas_datareader as web\n",
        "from pandas_datareader import data, wb\n",
        "import requests\n",
        "import datetime as dt\n",
        "import dateutil.relativedelta\n",
        "\n",
        "# Efficient frontier\n",
        "from pypfopt import EfficientFrontier\n",
        "from pypfopt import risk_models\n",
        "from pypfopt import expected_returns\n",
        "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
        "from pypfopt import black_litterman, risk_models\n",
        "from pypfopt import BlackLittermanModel, plotting\n",
        "from pypfopt import EfficientFrontier, objective_functions\n",
        "\n",
        "# LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy7GGknOsqZ4"
      },
      "source": [
        "# Stocks Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asset_stock = ['ADRO.JK', 'ASII.JK', 'BBRI.JK', 'BBTN.JK', 'BMRI.JK', 'BUMI.JK', 'EXCL.JK', 'MFIN.JK', 'PGAS.JK', 'TLKM.JK']"
      ],
      "metadata": {
        "id": "yWM94EOvkWFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMF3POLHcghZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e5f98e-53eb-40b2-c5a1-4d8a0456221b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  10 of 10 completed\n"
          ]
        }
      ],
      "source": [
        "data_stock6 = yf.download(asset_stock, start=\"2018-01-01\", end=\"2023-05-10\")\n",
        "data_stock6.index = pd.to_datetime(data_stock6.index).date\n",
        "data_asset6 = pd.concat([data_stock6],axis=1,sort=False).reset_index()\n",
        "data_asset6.rename(columns={'index':'Date'}, inplace=True)\n",
        "data_asset6.index = data_asset6['Date']\n",
        "data_asset6 = data_asset6.dropna()\n",
        "df6 = data_asset6['Close']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ACnfa9Fcgha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "9e3dd9f6-07c9-459a-b717-448191a5c42a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot\n",
        "plt.figure(figsize=(8,4))\n",
        "for i in df6.columns.values:\n",
        "    plt.plot( df6[i],  label=i)\n",
        "plt.title('Price of the Assets', fontsize=16)\n",
        "plt.xlabel('Date',fontsize=14)\n",
        "plt.ylabel('Price in IDR',fontsize=14)\n",
        "plt.legend(df6.columns.values, loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9SgrfrfsoRa"
      },
      "source": [
        "## Data Preparation 0\n",
        "1st of January 2018 - 9th of May 2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLzpajSxYqN5"
      },
      "outputs": [],
      "source": [
        "# Period parameters\n",
        "days_period = 20\n",
        "days_predict = 10\n",
        "\n",
        "# ADRO\n",
        "ADRO_0 = yf.download(\"ADRO.JK\", start=\"2021-11-10\", end=\"2022-05-10\")\n",
        "ADRO_0.insert(4,\"Return\", ADRO_0['Close'].pct_change())\n",
        "ADRO_0 = ADRO_0.dropna()\n",
        "ADRO_0_test = yf.download(\"ADRO.JK\", start=\"2022-05-09\", end=\"2022-06-10\")\n",
        "ADRO_0_test.insert(4,\"Return\", ADRO_0_test['Close'].pct_change())\n",
        "ADRO_0_test = ADRO_0_test.dropna()\n",
        "training_ADRO_0 = ADRO_0.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ADRO_0_scaled = sc.fit_transform(training_ADRO_0)\n",
        "X_ADRO_0_train = []\n",
        "y_ADRO_0_train = []\n",
        "for i in range(days_period, len(ADRO_0)-1):\n",
        "    X_ADRO_0_train.append(training_ADRO_0_scaled[i-days_period:i, 0])\n",
        "    y_ADRO_0_train.append(training_ADRO_0_scaled[i, 0])\n",
        "X_ADRO_0_train, y_ADRO_0_train = np.array(X_ADRO_0_train), np.array(y_ADRO_0_train)\n",
        "X_ADRO_0_train = np.reshape(X_ADRO_0_train, (X_ADRO_0_train.shape[0], X_ADRO_0_train.shape[1], 1))\n",
        "model_ADRO_0 = Sequential()\n",
        "model_ADRO_0.add(LSTM(units=50,return_sequences=True,input_shape=(X_ADRO_0_train.shape[1], 1)))\n",
        "model_ADRO_0.add(Dropout(0.2))\n",
        "model_ADRO_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_0.add(Dropout(0.2))\n",
        "model_ADRO_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_0.add(Dropout(0.2))\n",
        "model_ADRO_0.add(LSTM(units=50))\n",
        "model_ADRO_0.add(Dropout(0.2))\n",
        "model_ADRO_0.add(Dense(units=1))\n",
        "model_ADRO_0.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ADRO_0.fit(X_ADRO_0_train,y_ADRO_0_train,epochs=10,batch_size=16)\n",
        "\n",
        "# ASII\n",
        "ASII_0 = yf.download(\"ASII.JK\", start=\"2021-11-10\", end=\"2022-05-10\")\n",
        "ASII_0.insert(4,\"Return\", ASII_0['Close'].pct_change())\n",
        "ASII_0 = ASII_0.dropna()\n",
        "ASII_0_test = yf.download(\"ASII.JK\", start=\"2022-05-09\", end=\"2022-06-10\")\n",
        "ASII_0_test.insert(4,\"Return\", ASII_0_test['Close'].pct_change())\n",
        "ASII_0_test = ASII_0_test.dropna()\n",
        "training_ASII_0 = ASII_0.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ASII_0_scaled = sc.fit_transform(training_ASII_0)\n",
        "X_ASII_0_train = []\n",
        "y_ASII_0_train = []\n",
        "for i in range(days_period, len(ASII_0)-1):\n",
        "    X_ASII_0_train.append(training_ASII_0_scaled[i-days_period:i, 0])\n",
        "    y_ASII_0_train.append(training_ASII_0_scaled[i, 0])\n",
        "X_ASII_0_train, y_ASII_0_train = np.array(X_ASII_0_train), np.array(y_ASII_0_train)\n",
        "X_ASII_0_train = np.reshape(X_ASII_0_train, (X_ASII_0_train.shape[0], X_ASII_0_train.shape[1], 1))\n",
        "model_ASII_0 = Sequential()\n",
        "model_ASII_0.add(LSTM(units=50,return_sequences=True,input_shape=(X_ASII_0_train.shape[1], 1)))\n",
        "model_ASII_0.add(Dropout(0.2))\n",
        "model_ASII_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_0.add(Dropout(0.2))\n",
        "model_ASII_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_0.add(Dropout(0.2))\n",
        "model_ASII_0.add(LSTM(units=50))\n",
        "model_ASII_0.add(Dropout(0.2))\n",
        "model_ASII_0.add(Dense(units=1))\n",
        "model_ASII_0.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ASII_0.fit(X_ASII_0_train,y_ASII_0_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BMRI\n",
        "BMRI_0 = yf.download(\"BMRI.JK\", start=\"2021-11-10\", end=\"2022-05-10\")\n",
        "BMRI_0.insert(4,\"Return\", BMRI_0['Close'].pct_change())\n",
        "BMRI_0 = BMRI_0.dropna()\n",
        "BMRI_0_test = yf.download(\"BMRI.JK\", start=\"2022-05-09\", end=\"2022-06-10\")\n",
        "BMRI_0_test.insert(4,\"Return\", BMRI_0_test['Close'].pct_change())\n",
        "BMRI_0_test = BMRI_0_test.dropna()\n",
        "training_BMRI_0 = BMRI_0.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BMRI_0_scaled = sc.fit_transform(training_BMRI_0)\n",
        "X_BMRI_0_train = []\n",
        "y_BMRI_0_train = []\n",
        "for i in range(days_period, len(BMRI_0)-1):\n",
        "    X_BMRI_0_train.append(training_BMRI_0_scaled[i-days_period:i, 0])\n",
        "    y_BMRI_0_train.append(training_BMRI_0_scaled[i, 0])\n",
        "X_BMRI_0_train, y_BMRI_0_train = np.array(X_BMRI_0_train), np.array(y_BMRI_0_train)\n",
        "X_BMRI_0_train = np.reshape(X_BMRI_0_train, (X_BMRI_0_train.shape[0], X_BMRI_0_train.shape[1], 1))\n",
        "model_BMRI_0 = Sequential()\n",
        "model_BMRI_0.add(LSTM(units=50,return_sequences=True,input_shape=(X_BMRI_0_train.shape[1], 1)))\n",
        "model_BMRI_0.add(Dropout(0.2))\n",
        "model_BMRI_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_0.add(Dropout(0.2))\n",
        "model_BMRI_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_0.add(Dropout(0.2))\n",
        "model_BMRI_0.add(LSTM(units=50))\n",
        "model_BMRI_0.add(Dropout(0.2))\n",
        "model_BMRI_0.add(Dense(units=1))\n",
        "model_BMRI_0.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BMRI_0.fit(X_BMRI_0_train,y_BMRI_0_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBRI\n",
        "BBRI_0 = yf.download(\"BBRI.JK\", start=\"2021-11-10\", end=\"2022-05-10\")\n",
        "BBRI_0.insert(4,\"Return\", BBRI_0['Close'].pct_change())\n",
        "BBRI_0 = BBRI_0.dropna()\n",
        "BBRI_0_test = yf.download(\"BBRI.JK\", start=\"2022-05-09\", end=\"2022-06-10\")\n",
        "BBRI_0_test.insert(4,\"Return\", BBRI_0_test['Close'].pct_change())\n",
        "BBRI_0_test = BBRI_0_test.dropna()\n",
        "training_BBRI_0 = BBRI_0.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBRI_0_scaled = sc.fit_transform(training_BBRI_0)\n",
        "X_BBRI_0_train = []\n",
        "y_BBRI_0_train = []\n",
        "for i in range(days_period, len(BBRI_0)-1):\n",
        "    X_BBRI_0_train.append(training_BBRI_0_scaled[i-days_period:i, 0])\n",
        "    y_BBRI_0_train.append(training_BBRI_0_scaled[i, 0])\n",
        "X_BBRI_0_train, y_BBRI_0_train = np.array(X_BBRI_0_train), np.array(y_BBRI_0_train)\n",
        "X_BBRI_0_train = np.reshape(X_BBRI_0_train, (X_BBRI_0_train.shape[0], X_BBRI_0_train.shape[1], 1))\n",
        "model_BBRI_0 = Sequential()\n",
        "model_BBRI_0.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBRI_0_train.shape[1], 1)))\n",
        "model_BBRI_0.add(Dropout(0.2))\n",
        "model_BBRI_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_0.add(Dropout(0.2))\n",
        "model_BBRI_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_0.add(Dropout(0.2))\n",
        "model_BBRI_0.add(LSTM(units=50))\n",
        "model_BBRI_0.add(Dropout(0.2))\n",
        "model_BBRI_0.add(Dense(units=1))\n",
        "model_BBRI_0.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBRI_0.fit(X_BBRI_0_train,y_BBRI_0_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBTN\n",
        "BBTN_0 = yf.download(\"BBTN.JK\", start=\"2021-11-10\", end=\"2022-05-10\")\n",
        "BBTN_0.insert(4,\"Return\", BBTN_0['Close'].pct_change())\n",
        "BBTN_0 = BBTN_0.dropna()\n",
        "BBTN_0_test = yf.download(\"BBTN.JK\", start=\"2022-05-09\", end=\"2022-06-10\")\n",
        "BBTN_0_test.insert(4,\"Return\", BBTN_0_test['Close'].pct_change())\n",
        "BBTN_0_test = BBTN_0_test.dropna()\n",
        "training_BBTN_0 = BBTN_0.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBTN_0_scaled = sc.fit_transform(training_BBTN_0)\n",
        "X_BBTN_0_train = []\n",
        "y_BBTN_0_train = []\n",
        "for i in range(days_period, len(BBTN_0)-1):\n",
        "    X_BBTN_0_train.append(training_BBTN_0_scaled[i-days_period:i, 0])\n",
        "    y_BBTN_0_train.append(training_BBTN_0_scaled[i, 0])\n",
        "X_BBTN_0_train, y_BBTN_0_train = np.array(X_BBTN_0_train), np.array(y_BBTN_0_train)\n",
        "X_BBTN_0_train = np.reshape(X_BBTN_0_train, (X_BBTN_0_train.shape[0], X_BBTN_0_train.shape[1], 1))\n",
        "model_BBTN_0 = Sequential()\n",
        "model_BBTN_0.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBTN_0_train.shape[1], 1)))\n",
        "model_BBTN_0.add(Dropout(0.2))\n",
        "model_BBTN_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_0.add(Dropout(0.2))\n",
        "model_BBTN_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_0.add(Dropout(0.2))\n",
        "model_BBTN_0.add(LSTM(units=50))\n",
        "model_BBTN_0.add(Dropout(0.2))\n",
        "model_BBTN_0.add(Dense(units=1))\n",
        "model_BBTN_0.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBTN_0.fit(X_BBTN_0_train,y_BBTN_0_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BUMI\n",
        "BUMI_0 = yf.download(\"BUMI.JK\", start=\"2021-11-10\", end=\"2022-05-10\")\n",
        "BUMI_0.insert(4,\"Return\", BUMI_0['Close'].pct_change())\n",
        "BUMI_0 = BUMI_0.dropna()\n",
        "BUMI_0_test = yf.download(\"BUMI.JK\", start=\"2022-05-09\", end=\"2022-06-10\")\n",
        "BUMI_0_test.insert(4,\"Return\", BUMI_0_test['Close'].pct_change())\n",
        "BUMI_0_test = BUMI_0_test.dropna()\n",
        "training_BUMI_0 = BUMI_0.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BUMI_0_scaled = sc.fit_transform(training_BUMI_0)\n",
        "X_BUMI_0_train = []\n",
        "y_BUMI_0_train = []\n",
        "for i in range(days_period, len(BUMI_0)-1):\n",
        "    X_BUMI_0_train.append(training_BUMI_0_scaled[i-days_period:i, 0])\n",
        "    y_BUMI_0_train.append(training_BUMI_0_scaled[i, 0])\n",
        "X_BUMI_0_train, y_BUMI_0_train = np.array(X_BUMI_0_train), np.array(y_BUMI_0_train)\n",
        "X_BUMI_0_train = np.reshape(X_BUMI_0_train, (X_BUMI_0_train.shape[0], X_BUMI_0_train.shape[1], 1))\n",
        "model_BUMI_0 = Sequential()\n",
        "model_BUMI_0.add(LSTM(units=50,return_sequences=True,input_shape=(X_BUMI_0_train.shape[1], 1)))\n",
        "model_BUMI_0.add(Dropout(0.2))\n",
        "model_BUMI_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_0.add(Dropout(0.2))\n",
        "model_BUMI_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_0.add(Dropout(0.2))\n",
        "model_BUMI_0.add(LSTM(units=50))\n",
        "model_BUMI_0.add(Dropout(0.2))\n",
        "model_BUMI_0.add(Dense(units=1))\n",
        "model_BUMI_0.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BUMI_0.fit(X_BUMI_0_train,y_BUMI_0_train,epochs=10,batch_size=16)\n",
        "\n",
        "# MFIN\n",
        "MFIN_0 = yf.download(\"MFIN.JK\", start=\"2021-11-10\", end=\"2022-05-10\")\n",
        "MFIN_0.insert(4,\"Return\", MFIN_0['Close'].pct_change())\n",
        "MFIN_0 = MFIN_0.dropna()\n",
        "MFIN_0_test = yf.download(\"MFIN.JK\", start=\"2022-05-09\", end=\"2022-06-10\")\n",
        "MFIN_0_test.insert(4,\"Return\", MFIN_0_test['Close'].pct_change())\n",
        "MFIN_0_test = MFIN_0_test.dropna()\n",
        "training_MFIN_0 = MFIN_0.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_MFIN_0_scaled = sc.fit_transform(training_MFIN_0)\n",
        "X_MFIN_0_train = []\n",
        "y_MFIN_0_train = []\n",
        "for i in range(days_period, len(MFIN_0)-1):\n",
        "    X_MFIN_0_train.append(training_MFIN_0_scaled[i-days_period:i, 0])\n",
        "    y_MFIN_0_train.append(training_MFIN_0_scaled[i, 0])\n",
        "X_MFIN_0_train, y_MFIN_0_train = np.array(X_MFIN_0_train), np.array(y_MFIN_0_train)\n",
        "X_MFIN_0_train = np.reshape(X_MFIN_0_train, (X_MFIN_0_train.shape[0], X_MFIN_0_train.shape[1], 1))\n",
        "model_MFIN_0 = Sequential()\n",
        "model_MFIN_0.add(LSTM(units=50,return_sequences=True,input_shape=(X_MFIN_0_train.shape[1], 1)))\n",
        "model_MFIN_0.add(Dropout(0.2))\n",
        "model_MFIN_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_0.add(Dropout(0.2))\n",
        "model_MFIN_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_0.add(Dropout(0.2))\n",
        "model_MFIN_0.add(LSTM(units=50))\n",
        "model_MFIN_0.add(Dropout(0.2))\n",
        "model_MFIN_0.add(Dense(units=1))\n",
        "model_MFIN_0.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_MFIN_0.fit(X_MFIN_0_train,y_MFIN_0_train,epochs=10,batch_size=16)\n",
        "\n",
        "# EXCL\n",
        "EXCL_0 = yf.download(\"EXCL.JK\", start=\"2021-11-10\", end=\"2022-05-10\")\n",
        "EXCL_0.insert(4,\"Return\", EXCL_0['Close'].pct_change())\n",
        "EXCL_0 = EXCL_0.dropna()\n",
        "EXCL_0_test = yf.download(\"EXCL.JK\", start=\"2022-05-09\", end=\"2022-06-10\")\n",
        "EXCL_0_test.insert(4,\"Return\", EXCL_0_test['Close'].pct_change())\n",
        "EXCL_0_test = EXCL_0_test.dropna()\n",
        "training_EXCL_0 = EXCL_0.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_EXCL_0_scaled = sc.fit_transform(training_EXCL_0)\n",
        "X_EXCL_0_train = []\n",
        "y_EXCL_0_train = []\n",
        "for i in range(days_period, len(EXCL_0)-1):\n",
        "    X_EXCL_0_train.append(training_EXCL_0_scaled[i-days_period:i, 0])\n",
        "    y_EXCL_0_train.append(training_EXCL_0_scaled[i, 0])\n",
        "X_EXCL_0_train, y_EXCL_0_train = np.array(X_EXCL_0_train), np.array(y_EXCL_0_train)\n",
        "X_EXCL_0_train = np.reshape(X_EXCL_0_train, (X_EXCL_0_train.shape[0], X_EXCL_0_train.shape[1], 1))\n",
        "model_EXCL_0 = Sequential()\n",
        "model_EXCL_0.add(LSTM(units=50,return_sequences=True,input_shape=(X_EXCL_0_train.shape[1], 1)))\n",
        "model_EXCL_0.add(Dropout(0.2))\n",
        "model_EXCL_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_0.add(Dropout(0.2))\n",
        "model_EXCL_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_0.add(Dropout(0.2))\n",
        "model_EXCL_0.add(LSTM(units=50))\n",
        "model_EXCL_0.add(Dropout(0.2))\n",
        "model_EXCL_0.add(Dense(units=1))\n",
        "model_EXCL_0.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_EXCL_0.fit(X_EXCL_0_train,y_EXCL_0_train,epochs=10,batch_size=16)\n",
        "\n",
        "# PGAS\n",
        "PGAS_0 = yf.download(\"PGAS.JK\", start=\"2021-11-10\", end=\"2022-05-10\")\n",
        "PGAS_0.insert(4,\"Return\", PGAS_0['Close'].pct_change())\n",
        "PGAS_0 = PGAS_0.dropna()\n",
        "PGAS_0_test = yf.download(\"PGAS.JK\", start=\"2022-05-09\", end=\"2022-06-10\")\n",
        "PGAS_0_test.insert(4,\"Return\", PGAS_0_test['Close'].pct_change())\n",
        "PGAS_0_test = PGAS_0_test.dropna()\n",
        "training_PGAS_0 = PGAS_0.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_PGAS_0_scaled = sc.fit_transform(training_PGAS_0)\n",
        "X_PGAS_0_train = []\n",
        "y_PGAS_0_train = []\n",
        "for i in range(days_period, len(PGAS_0)-1):\n",
        "    X_PGAS_0_train.append(training_PGAS_0_scaled[i-days_period:i, 0])\n",
        "    y_PGAS_0_train.append(training_PGAS_0_scaled[i, 0])\n",
        "X_PGAS_0_train, y_PGAS_0_train = np.array(X_PGAS_0_train), np.array(y_PGAS_0_train)\n",
        "X_PGAS_0_train = np.reshape(X_PGAS_0_train, (X_PGAS_0_train.shape[0], X_PGAS_0_train.shape[1], 1))\n",
        "model_PGAS_0 = Sequential()\n",
        "model_PGAS_0.add(LSTM(units=50,return_sequences=True,input_shape=(X_PGAS_0_train.shape[1], 1)))\n",
        "model_PGAS_0.add(Dropout(0.2))\n",
        "model_PGAS_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_0.add(Dropout(0.2))\n",
        "model_PGAS_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_0.add(Dropout(0.2))\n",
        "model_PGAS_0.add(LSTM(units=50))\n",
        "model_PGAS_0.add(Dropout(0.2))\n",
        "model_PGAS_0.add(Dense(units=1))\n",
        "model_PGAS_0.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_PGAS_0.fit(X_PGAS_0_train,y_PGAS_0_train,epochs=10,batch_size=16)\n",
        "\n",
        "# TLKM\n",
        "TLKM_0 = yf.download(\"TLKM.JK\", start=\"2021-11-10\", end=\"2022-05-10\")\n",
        "TLKM_0.insert(4,\"Return\", TLKM_0['Close'].pct_change())\n",
        "TLKM_0 = TLKM_0.dropna()\n",
        "TLKM_0_test = yf.download(\"TLKM.JK\", start=\"2022-05-09\", end=\"2022-06-10\")\n",
        "TLKM_0_test.insert(4,\"Return\", TLKM_0_test['Close'].pct_change())\n",
        "TLKM_0_test = TLKM_0_test.dropna()\n",
        "training_TLKM_0 = TLKM_0.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_TLKM_0_scaled = sc.fit_transform(training_TLKM_0)\n",
        "X_TLKM_0_train = []\n",
        "y_TLKM_0_train = []\n",
        "for i in range(days_period, len(TLKM_0)-1):\n",
        "    X_TLKM_0_train.append(training_TLKM_0_scaled[i-days_period:i, 0])\n",
        "    y_TLKM_0_train.append(training_TLKM_0_scaled[i, 0])\n",
        "X_TLKM_0_train, y_TLKM_0_train = np.array(X_TLKM_0_train), np.array(y_TLKM_0_train)\n",
        "X_TLKM_0_train = np.reshape(X_TLKM_0_train, (X_TLKM_0_train.shape[0], X_TLKM_0_train.shape[1], 1))\n",
        "model_TLKM_0 = Sequential()\n",
        "model_TLKM_0.add(LSTM(units=50,return_sequences=True,input_shape=(X_TLKM_0_train.shape[1], 1)))\n",
        "model_TLKM_0.add(Dropout(0.2))\n",
        "model_TLKM_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_0.add(Dropout(0.2))\n",
        "model_TLKM_0.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_0.add(Dropout(0.2))\n",
        "model_TLKM_0.add(LSTM(units=50))\n",
        "model_TLKM_0.add(Dropout(0.2))\n",
        "model_TLKM_0.add(Dense(units=1))\n",
        "model_TLKM_0.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_TLKM_0.fit(X_TLKM_0_train,y_TLKM_0_train,epochs=10,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxxopqVhYqN7"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "real_ADRO_0_return = ADRO_0_test.iloc[:, 4:5].values\n",
        "real_ADRO_0_return = real_ADRO_0_return[:days_predict]\n",
        "ADRO_0_total = ADRO_0['Close'].copy(deep=True)\n",
        "inputs_ADRO_0 = ADRO_0_total[len(ADRO_0) - days_period: len(ADRO_0)].values\n",
        "inputs_ADRO_0 = inputs_ADRO_0.reshape(-1,1)\n",
        "inputs_ADRO_0 = sc.transform(inputs_ADRO_0)\n",
        "predicted_ADRO_0_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ADRO_0_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ADRO_0_test.append(inputs_ADRO_0[i:i+days_period, 0])\n",
        "  X_ADRO_0_test = np.array(X_ADRO_0_test)\n",
        "  X_ADRO_0_test = np.reshape(X_ADRO_0_test, (X_ADRO_0_test.shape[0], X_ADRO_0_test.shape[1], 1))\n",
        "  predicted_ADRO_0_return[j] = model_ADRO_0.predict(X_ADRO_0_test)\n",
        "  inputs_ADRO_0 += (predicted_ADRO_0_return[j])\n",
        "  inputs_ADRO_0 = inputs_ADRO_0.reshape(-1,1)\n",
        "\n",
        "# ASII\n",
        "real_ASII_0_return = ASII_0_test.iloc[:, 4:5].values\n",
        "real_ASII_0_return = real_ASII_0_return[:days_predict]\n",
        "ASII_0_total = ASII_0['Close'].copy(deep=True)\n",
        "inputs_ASII_0 = ASII_0_total[len(ASII_0) - days_period: len(ASII_0)].values\n",
        "inputs_ASII_0 = inputs_ASII_0.reshape(-1,1)\n",
        "inputs_ASII_0 = sc.transform(inputs_ASII_0)\n",
        "predicted_ASII_0_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ASII_0_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ASII_0_test.append(inputs_ASII_0[i:i+days_period, 0])\n",
        "  X_ASII_0_test = np.array(X_ASII_0_test)\n",
        "  X_ASII_0_test = np.reshape(X_ASII_0_test, (X_ASII_0_test.shape[0], X_ASII_0_test.shape[1], 1))\n",
        "  predicted_ASII_0_return[j] = model_ASII_0.predict(X_ASII_0_test)\n",
        "  inputs_ASII_0 += (predicted_ASII_0_return[j])\n",
        "  inputs_ASII_0 = inputs_ASII_0.reshape(-1,1)\n",
        "\n",
        "# BMRI\n",
        "real_BMRI_0_return = BMRI_0_test.iloc[:, 4:5].values\n",
        "real_BMRI_0_return = real_BMRI_0_return[:days_predict]\n",
        "BMRI_0_total = BMRI_0['Close'].copy(deep=True)\n",
        "inputs_BMRI_0 = BMRI_0_total[len(BMRI_0) - days_period: len(BMRI_0)].values\n",
        "inputs_BMRI_0 = inputs_BMRI_0.reshape(-1,1)\n",
        "inputs_BMRI_0 = sc.transform(inputs_BMRI_0)\n",
        "predicted_BMRI_0_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BMRI_0_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BMRI_0_test.append(inputs_BMRI_0[i:i+days_period, 0])\n",
        "  X_BMRI_0_test = np.array(X_BMRI_0_test)\n",
        "  X_BMRI_0_test = np.reshape(X_BMRI_0_test, (X_BMRI_0_test.shape[0], X_BMRI_0_test.shape[1], 1))\n",
        "  predicted_BMRI_0_return[j] = model_BMRI_0.predict(X_BMRI_0_test)\n",
        "  inputs_BMRI_0 += (predicted_BMRI_0_return[j])\n",
        "  inputs_BMRI_0 = inputs_BMRI_0.reshape(-1,1)\n",
        "\n",
        "# BBRI\n",
        "real_BBRI_0_return = BBRI_0_test.iloc[:, 4:5].values\n",
        "real_BBRI_0_return = real_BBRI_0_return[:days_predict]\n",
        "BBRI_0_total = BBRI_0['Close'].copy(deep=True)\n",
        "inputs_BBRI_0 = BBRI_0_total[len(BBRI_0) - days_period: len(BBRI_0)].values\n",
        "inputs_BBRI_0 = inputs_BBRI_0.reshape(-1,1)\n",
        "inputs_BBRI_0 = sc.transform(inputs_BBRI_0)\n",
        "predicted_BBRI_0_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBRI_0_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBRI_0_test.append(inputs_BBRI_0[i:i+days_period, 0])\n",
        "  X_BBRI_0_test = np.array(X_BBRI_0_test)\n",
        "  X_BBRI_0_test = np.reshape(X_BBRI_0_test, (X_BBRI_0_test.shape[0], X_BBRI_0_test.shape[1], 1))\n",
        "  predicted_BBRI_0_return[j] = model_BBRI_0.predict(X_BBRI_0_test)\n",
        "  inputs_BBRI_0 += (predicted_BBRI_0_return[j])\n",
        "  inputs_BBRI_0 = inputs_BBRI_0.reshape(-1,1)\n",
        "\n",
        "# BBTN\n",
        "real_BBTN_0_return = BBTN_0_test.iloc[:, 4:5].values\n",
        "real_BBTN_0_return = real_BBTN_0_return[:days_predict]\n",
        "BBTN_0_total = BBTN_0['Close'].copy(deep=True)\n",
        "inputs_BBTN_0 = BBTN_0_total[len(BBTN_0) - days_period: len(BBTN_0)].values\n",
        "inputs_BBTN_0 = inputs_BBTN_0.reshape(-1,1)\n",
        "inputs_BBTN_0 = sc.transform(inputs_BBTN_0)\n",
        "predicted_BBTN_0_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBTN_0_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBTN_0_test.append(inputs_BBTN_0[i:i+days_period, 0])\n",
        "  X_BBTN_0_test = np.array(X_BBTN_0_test)\n",
        "  X_BBTN_0_test = np.reshape(X_BBTN_0_test, (X_BBTN_0_test.shape[0], X_BBTN_0_test.shape[1], 1))\n",
        "  predicted_BBTN_0_return[j] = model_BBTN_0.predict(X_BBTN_0_test)\n",
        "  inputs_BBTN_0 += (predicted_BBTN_0_return[j])\n",
        "  inputs_BBTN_0 = inputs_BBTN_0.reshape(-1,1)\n",
        "\n",
        "# BUMI\n",
        "real_BUMI_0_return = BUMI_0_test.iloc[:, 4:5].values\n",
        "real_BUMI_0_return = real_BUMI_0_return[:days_predict]\n",
        "BUMI_0_total = BUMI_0['Close'].copy(deep=True)\n",
        "inputs_BUMI_0 = BUMI_0_total[len(BUMI_0) - days_period: len(BUMI_0)].values\n",
        "inputs_BUMI_0 = inputs_BUMI_0.reshape(-1,1)\n",
        "inputs_BUMI_0 = sc.transform(inputs_BUMI_0)\n",
        "predicted_BUMI_0_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BUMI_0_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BUMI_0_test.append(inputs_BUMI_0[i:i+days_period, 0])\n",
        "  X_BUMI_0_test = np.array(X_BUMI_0_test)\n",
        "  X_BUMI_0_test = np.reshape(X_BUMI_0_test, (X_BUMI_0_test.shape[0], X_BUMI_0_test.shape[1], 1))\n",
        "  predicted_BUMI_0_return[j] = model_BUMI_0.predict(X_BUMI_0_test)\n",
        "  inputs_BUMI_0 += (predicted_BUMI_0_return[j])\n",
        "  inputs_BUMI_0 = inputs_BUMI_0.reshape(-1,1)\n",
        "\n",
        "# MFIN\n",
        "real_MFIN_0_return = MFIN_0_test.iloc[:, 4:5].values\n",
        "real_MFIN_0_return = real_MFIN_0_return[:days_predict]\n",
        "MFIN_0_total = MFIN_0['Close'].copy(deep=True)\n",
        "inputs_MFIN_0 = MFIN_0_total[len(MFIN_0) - days_period: len(MFIN_0)].values\n",
        "inputs_MFIN_0 = inputs_MFIN_0.reshape(-1,1)\n",
        "inputs_MFIN_0 = sc.transform(inputs_MFIN_0)\n",
        "predicted_MFIN_0_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_MFIN_0_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_MFIN_0_test.append(inputs_MFIN_0[i:i+days_period, 0])\n",
        "  X_MFIN_0_test = np.array(X_MFIN_0_test)\n",
        "  X_MFIN_0_test = np.reshape(X_MFIN_0_test, (X_MFIN_0_test.shape[0], X_MFIN_0_test.shape[1], 1))\n",
        "  predicted_MFIN_0_return[j] = model_MFIN_0.predict(X_MFIN_0_test)\n",
        "  inputs_MFIN_0 += (predicted_MFIN_0_return[j])\n",
        "  inputs_MFIN_0 = inputs_MFIN_0.reshape(-1,1)\n",
        "\n",
        "# EXCL\n",
        "real_EXCL_0_return = EXCL_0_test.iloc[:, 4:5].values\n",
        "real_EXCL_0_return = real_EXCL_0_return[:days_predict]\n",
        "EXCL_0_total = EXCL_0['Close'].copy(deep=True)\n",
        "inputs_EXCL_0 = EXCL_0_total[len(EXCL_0) - days_period: len(EXCL_0)].values\n",
        "inputs_EXCL_0 = inputs_EXCL_0.reshape(-1,1)\n",
        "inputs_EXCL_0 = sc.transform(inputs_EXCL_0)\n",
        "predicted_EXCL_0_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_EXCL_0_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_EXCL_0_test.append(inputs_EXCL_0[i:i+days_period, 0])\n",
        "  X_EXCL_0_test = np.array(X_EXCL_0_test)\n",
        "  X_EXCL_0_test = np.reshape(X_EXCL_0_test, (X_EXCL_0_test.shape[0], X_EXCL_0_test.shape[1], 1))\n",
        "  predicted_EXCL_0_return[j] = model_EXCL_0.predict(X_EXCL_0_test)\n",
        "  inputs_EXCL_0 += (predicted_EXCL_0_return[j])\n",
        "  inputs_EXCL_0 = inputs_EXCL_0.reshape(-1,1)\n",
        "\n",
        "# PGAS\n",
        "real_PGAS_0_return = PGAS_0_test.iloc[:, 4:5].values\n",
        "real_PGAS_0_return = real_PGAS_0_return[:days_predict]\n",
        "PGAS_0_total = PGAS_0['Close'].copy(deep=True)\n",
        "inputs_PGAS_0 = PGAS_0_total[len(PGAS_0) - days_period: len(PGAS_0)].values\n",
        "inputs_PGAS_0 = inputs_PGAS_0.reshape(-1,1)\n",
        "inputs_PGAS_0 = sc.transform(inputs_PGAS_0)\n",
        "predicted_PGAS_0_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_PGAS_0_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_PGAS_0_test.append(inputs_PGAS_0[i:i+days_period, 0])\n",
        "  X_PGAS_0_test = np.array(X_PGAS_0_test)\n",
        "  X_PGAS_0_test = np.reshape(X_PGAS_0_test, (X_PGAS_0_test.shape[0], X_PGAS_0_test.shape[1], 1))\n",
        "  predicted_PGAS_0_return[j] = model_PGAS_0.predict(X_PGAS_0_test)\n",
        "  inputs_PGAS_0 += (predicted_PGAS_0_return[j])\n",
        "  inputs_PGAS_0 = inputs_PGAS_0.reshape(-1,1)\n",
        "\n",
        "# TLKM\n",
        "real_TLKM_0_return = TLKM_0_test.iloc[:, 4:5].values\n",
        "real_TLKM_0_return = real_TLKM_0_return[:days_predict]\n",
        "TLKM_0_total = TLKM_0['Close'].copy(deep=True)\n",
        "inputs_TLKM_0 = TLKM_0_total[len(TLKM_0) - days_period: len(TLKM_0)].values\n",
        "inputs_TLKM_0 = inputs_TLKM_0.reshape(-1,1)\n",
        "inputs_TLKM_0 = sc.transform(inputs_TLKM_0)\n",
        "predicted_TLKM_0_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_TLKM_0_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_TLKM_0_test.append(inputs_TLKM_0[i:i+days_period, 0])\n",
        "  X_TLKM_0_test = np.array(X_TLKM_0_test)\n",
        "  X_TLKM_0_test = np.reshape(X_TLKM_0_test, (X_TLKM_0_test.shape[0], X_TLKM_0_test.shape[1], 1))\n",
        "  predicted_TLKM_0_return[j] = model_TLKM_0.predict(X_TLKM_0_test)\n",
        "  inputs_TLKM_0 += (predicted_TLKM_0_return[j])\n",
        "  inputs_TLKM_0 = inputs_TLKM_0.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfN3QhXFYqN7"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "predicted_ADRO_0_return = np.squeeze(np.asarray(predicted_ADRO_0_return))\n",
        "predicted_ADRO_0_return = predicted_ADRO_0_return.reshape(-1,1)\n",
        "predicted_ADRO_0_return = sc.inverse_transform(predicted_ADRO_0_return)\n",
        "# ASII\n",
        "predicted_ASII_0_return = np.squeeze(np.asarray(predicted_ASII_0_return))\n",
        "predicted_ASII_0_return = predicted_ASII_0_return.reshape(-1,1)\n",
        "predicted_ASII_0_return = sc.inverse_transform(predicted_ASII_0_return)\n",
        "# BMRI\n",
        "predicted_BMRI_0_return = np.squeeze(np.asarray(predicted_BMRI_0_return))\n",
        "predicted_BMRI_0_return = predicted_BMRI_0_return.reshape(-1,1)\n",
        "predicted_BMRI_0_return = sc.inverse_transform(predicted_BMRI_0_return)\n",
        "# BBRI\n",
        "predicted_BBRI_0_return = np.squeeze(np.asarray(predicted_BBRI_0_return))\n",
        "predicted_BBRI_0_return = predicted_BBRI_0_return.reshape(-1,1)\n",
        "predicted_BBRI_0_return = sc.inverse_transform(predicted_BBRI_0_return)\n",
        "# BBTN\n",
        "predicted_BBTN_0_return = np.squeeze(np.asarray(predicted_BBTN_0_return))\n",
        "predicted_BBTN_0_return = predicted_BBTN_0_return.reshape(-1,1)\n",
        "predicted_BBTN_0_return = sc.inverse_transform(predicted_BBTN_0_return)\n",
        "# BUMI\n",
        "predicted_BUMI_0_return = np.squeeze(np.asarray(predicted_BUMI_0_return))\n",
        "predicted_BUMI_0_return = predicted_BUMI_0_return.reshape(-1,1)\n",
        "predicted_BUMI_0_return = sc.inverse_transform(predicted_BUMI_0_return)\n",
        "# MFIN\n",
        "predicted_MFIN_0_return = np.squeeze(np.asarray(predicted_MFIN_0_return))\n",
        "predicted_MFIN_0_return = predicted_MFIN_0_return.reshape(-1,1)\n",
        "predicted_MFIN_0_return = sc.inverse_transform(predicted_MFIN_0_return)\n",
        "# EXCL\n",
        "predicted_EXCL_0_return = np.squeeze(np.asarray(predicted_EXCL_0_return))\n",
        "predicted_EXCL_0_return = predicted_EXCL_0_return.reshape(-1,1)\n",
        "predicted_EXCL_0_return = sc.inverse_transform(predicted_EXCL_0_return)\n",
        "# PGAS\n",
        "predicted_PGAS_0_return = np.squeeze(np.asarray(predicted_PGAS_0_return))\n",
        "predicted_PGAS_0_return = predicted_PGAS_0_return.reshape(-1,1)\n",
        "predicted_PGAS_0_return = sc.inverse_transform(predicted_PGAS_0_return)\n",
        "# TLKM\n",
        "predicted_TLKM_0_return = np.squeeze(np.asarray(predicted_TLKM_0_return))\n",
        "predicted_TLKM_0_return = predicted_TLKM_0_return.reshape(-1,1)\n",
        "predicted_TLKM_0_return = sc.inverse_transform(predicted_TLKM_0_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted0 = pd.DataFrame(predicted_ADRO_0_return)\n",
        "predicted0.rename(columns={0:'ADRO'}, inplace=True)\n",
        "predicted0.insert(1,\"ASII\", predicted_ASII_0_return)\n",
        "predicted0.insert(2,\"BBRI\", predicted_BBRI_0_return)\n",
        "predicted0.insert(3,\"BBTN\", predicted_BBTN_0_return)\n",
        "predicted0.insert(4,\"BMRI\", predicted_BMRI_0_return)\n",
        "predicted0.insert(5,\"BUMI\", predicted_BUMI_0_return)\n",
        "predicted0.insert(6,\"EXCL\", predicted_EXCL_0_return)\n",
        "predicted0.insert(7,\"MFIN\", predicted_MFIN_0_return)\n",
        "predicted0.insert(8,\"PGAS\", predicted_PGAS_0_return)\n",
        "predicted0.insert(9,\"TLKM\", predicted_TLKM_0_return)"
      ],
      "metadata": {
        "id": "La-5S2kpI_BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prFqRZMlKcga",
        "outputId": "d2f6df8c-95af-4c8b-df2c-d3f789b10d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADRO      ASII      BBRI      BBTN      BMRI      BUMI      EXCL  \\\n",
              "0  0.029142  0.022499  0.046271  0.000729  0.046970  0.029754  0.024562   \n",
              "1  0.028687  0.021792  0.044928  0.000208  0.045098  0.028441  0.023744   \n",
              "2  0.028071  0.020895  0.043302 -0.000438  0.042886  0.026869  0.022679   \n",
              "3  0.027244  0.019763  0.041345 -0.001238  0.040283  0.025004  0.021321   \n",
              "4  0.026147  0.018346  0.038998 -0.002221  0.037234  0.022812  0.019617   \n",
              "5  0.024710  0.016584  0.036198 -0.003425  0.033682  0.020199  0.017513   \n",
              "6  0.022850  0.014410  0.032878 -0.004891  0.029572  0.017131  0.014952   \n",
              "7  0.020472  0.011756  0.028969 -0.006666  0.024851  0.013536  0.011878   \n",
              "8  0.017474  0.008549  0.024401 -0.008804  0.019476  0.009367  0.008238   \n",
              "9  0.013747  0.004718  0.019111 -0.011358  0.013425  0.004576  0.003989   \n",
              "\n",
              "       MFIN      PGAS      TLKM  \n",
              "0  0.035846  0.059170 -0.006802  \n",
              "1  0.034991  0.057184 -0.007959  \n",
              "2  0.033870  0.054855 -0.009240  \n",
              "3  0.032427  0.052134 -0.010659  \n",
              "4  0.030597  0.048968 -0.012226  \n",
              "5  0.028312  0.045302 -0.013960  \n",
              "6  0.025496  0.041081 -0.015876  \n",
              "7  0.022075  0.036249 -0.017993  \n",
              "8  0.017976  0.030758 -0.020329  \n",
              "9  0.013137  0.024570 -0.022902  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cadf423-56e5-4bdd-b09f-2940a604c044\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADRO</th>\n",
              "      <th>ASII</th>\n",
              "      <th>BBRI</th>\n",
              "      <th>BBTN</th>\n",
              "      <th>BMRI</th>\n",
              "      <th>BUMI</th>\n",
              "      <th>EXCL</th>\n",
              "      <th>MFIN</th>\n",
              "      <th>PGAS</th>\n",
              "      <th>TLKM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.029142</td>\n",
              "      <td>0.022499</td>\n",
              "      <td>0.046271</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>0.046970</td>\n",
              "      <td>0.029754</td>\n",
              "      <td>0.024562</td>\n",
              "      <td>0.035846</td>\n",
              "      <td>0.059170</td>\n",
              "      <td>-0.006802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.028687</td>\n",
              "      <td>0.021792</td>\n",
              "      <td>0.044928</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>0.045098</td>\n",
              "      <td>0.028441</td>\n",
              "      <td>0.023744</td>\n",
              "      <td>0.034991</td>\n",
              "      <td>0.057184</td>\n",
              "      <td>-0.007959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.028071</td>\n",
              "      <td>0.020895</td>\n",
              "      <td>0.043302</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>0.042886</td>\n",
              "      <td>0.026869</td>\n",
              "      <td>0.022679</td>\n",
              "      <td>0.033870</td>\n",
              "      <td>0.054855</td>\n",
              "      <td>-0.009240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.027244</td>\n",
              "      <td>0.019763</td>\n",
              "      <td>0.041345</td>\n",
              "      <td>-0.001238</td>\n",
              "      <td>0.040283</td>\n",
              "      <td>0.025004</td>\n",
              "      <td>0.021321</td>\n",
              "      <td>0.032427</td>\n",
              "      <td>0.052134</td>\n",
              "      <td>-0.010659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.026147</td>\n",
              "      <td>0.018346</td>\n",
              "      <td>0.038998</td>\n",
              "      <td>-0.002221</td>\n",
              "      <td>0.037234</td>\n",
              "      <td>0.022812</td>\n",
              "      <td>0.019617</td>\n",
              "      <td>0.030597</td>\n",
              "      <td>0.048968</td>\n",
              "      <td>-0.012226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.024710</td>\n",
              "      <td>0.016584</td>\n",
              "      <td>0.036198</td>\n",
              "      <td>-0.003425</td>\n",
              "      <td>0.033682</td>\n",
              "      <td>0.020199</td>\n",
              "      <td>0.017513</td>\n",
              "      <td>0.028312</td>\n",
              "      <td>0.045302</td>\n",
              "      <td>-0.013960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.022850</td>\n",
              "      <td>0.014410</td>\n",
              "      <td>0.032878</td>\n",
              "      <td>-0.004891</td>\n",
              "      <td>0.029572</td>\n",
              "      <td>0.017131</td>\n",
              "      <td>0.014952</td>\n",
              "      <td>0.025496</td>\n",
              "      <td>0.041081</td>\n",
              "      <td>-0.015876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.020472</td>\n",
              "      <td>0.011756</td>\n",
              "      <td>0.028969</td>\n",
              "      <td>-0.006666</td>\n",
              "      <td>0.024851</td>\n",
              "      <td>0.013536</td>\n",
              "      <td>0.011878</td>\n",
              "      <td>0.022075</td>\n",
              "      <td>0.036249</td>\n",
              "      <td>-0.017993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.017474</td>\n",
              "      <td>0.008549</td>\n",
              "      <td>0.024401</td>\n",
              "      <td>-0.008804</td>\n",
              "      <td>0.019476</td>\n",
              "      <td>0.009367</td>\n",
              "      <td>0.008238</td>\n",
              "      <td>0.017976</td>\n",
              "      <td>0.030758</td>\n",
              "      <td>-0.020329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.013747</td>\n",
              "      <td>0.004718</td>\n",
              "      <td>0.019111</td>\n",
              "      <td>-0.011358</td>\n",
              "      <td>0.013425</td>\n",
              "      <td>0.004576</td>\n",
              "      <td>0.003989</td>\n",
              "      <td>0.013137</td>\n",
              "      <td>0.024570</td>\n",
              "      <td>-0.022902</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cadf423-56e5-4bdd-b09f-2940a604c044')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5cadf423-56e5-4bdd-b09f-2940a604c044 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5cadf423-56e5-4bdd-b09f-2940a604c044');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4gKUvoiYqN8"
      },
      "source": [
        "## Data Preparation 1\n",
        "1st of January 2018 - 9th of June 2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e70fd1-43b8-4231-e4e1-28f497392fe6",
        "id": "83JKxNaY9Pzy"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 44ms/step - loss: 0.0746\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0276\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0253\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0218\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0248\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0224\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0231\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0224\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0229\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0243\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 43ms/step - loss: 0.1186\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0375\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0349\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0239\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0291\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0232\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0212\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0232\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0215\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0188\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 10s 40ms/step - loss: 0.1490\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0374\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0259\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0205\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0210\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0176\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0181\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0163\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0156\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0160\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 41ms/step - loss: 0.2000\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0648\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0370\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0348\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 0.0300\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0281\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0267\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.0282\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0261\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0262\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 43ms/step - loss: 0.0734\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0281\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0215\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0191\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0159\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0157\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0169\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0156\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0167\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0158\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 42ms/step - loss: 0.0744\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0672\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0622\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0596\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0506\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0494\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 76ms/step - loss: 0.0497\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.0504\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 71ms/step - loss: 0.0479\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 73ms/step - loss: 0.0457\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 41ms/step - loss: 0.0594\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 73ms/step - loss: 0.0286\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 75ms/step - loss: 0.0211\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.0188\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 73ms/step - loss: 0.0211\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 75ms/step - loss: 0.0197\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 75ms/step - loss: 0.0175\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.0193\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 76ms/step - loss: 0.0217\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 61ms/step - loss: 0.0208\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 8s 40ms/step - loss: 0.1173\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0522\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0509\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 0.0402\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 71ms/step - loss: 0.0364\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 80ms/step - loss: 0.0322\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 76ms/step - loss: 0.0329\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0346\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 76ms/step - loss: 0.0307\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 71ms/step - loss: 0.0316\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 8s 41ms/step - loss: 0.1263\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0528\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0345\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0321\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0272\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.0241\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0251\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 71ms/step - loss: 0.0248\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 76ms/step - loss: 0.0244\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.0268\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 12s 83ms/step - loss: 0.2366\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 73ms/step - loss: 0.0764\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 76ms/step - loss: 0.0468\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 81ms/step - loss: 0.0461\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 78ms/step - loss: 0.0322\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 86ms/step - loss: 0.0313\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.0340\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.0279\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 71ms/step - loss: 0.0295\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.0271\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1d91f8c430>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Period parameters\n",
        "days_period = 20\n",
        "days_predict = 10\n",
        "\n",
        "# ADRO\n",
        "ADRO_1 = yf.download(\"ADRO.JK\", start=\"2021-12-10\", end=\"2022-06-10\")\n",
        "ADRO_1.insert(4,\"Return\", ADRO_1['Close'].pct_change())\n",
        "ADRO_1 = ADRO_1.dropna()\n",
        "ADRO_1_test = yf.download(\"ADRO.JK\", start=\"2022-06-09\", end=\"2022-07-10\")\n",
        "ADRO_1_test.insert(4,\"Return\", ADRO_1_test['Close'].pct_change())\n",
        "ADRO_1_test = ADRO_1_test.dropna()\n",
        "training_ADRO_1 = ADRO_1.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ADRO_1_scaled = sc.fit_transform(training_ADRO_1)\n",
        "X_ADRO_1_train = []\n",
        "y_ADRO_1_train = []\n",
        "for i in range(days_period, len(ADRO_1)-1):\n",
        "    X_ADRO_1_train.append(training_ADRO_1_scaled[i-days_period:i, 0])\n",
        "    y_ADRO_1_train.append(training_ADRO_1_scaled[i, 0])\n",
        "X_ADRO_1_train, y_ADRO_1_train = np.array(X_ADRO_1_train), np.array(y_ADRO_1_train)\n",
        "X_ADRO_1_train = np.reshape(X_ADRO_1_train, (X_ADRO_1_train.shape[0], X_ADRO_1_train.shape[1], 1))\n",
        "model_ADRO_1 = Sequential()\n",
        "model_ADRO_1.add(LSTM(units=50,return_sequences=True,input_shape=(X_ADRO_1_train.shape[1], 1)))\n",
        "model_ADRO_1.add(Dropout(0.2))\n",
        "model_ADRO_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_1.add(Dropout(0.2))\n",
        "model_ADRO_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_1.add(Dropout(0.2))\n",
        "model_ADRO_1.add(LSTM(units=50))\n",
        "model_ADRO_1.add(Dropout(0.2))\n",
        "model_ADRO_1.add(Dense(units=1))\n",
        "model_ADRO_1.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ADRO_1.fit(X_ADRO_1_train,y_ADRO_1_train,epochs=10,batch_size=16)\n",
        "\n",
        "# ASII\n",
        "ASII_1 = yf.download(\"ASII.JK\", start=\"2021-12-10\", end=\"2022-06-10\")\n",
        "ASII_1.insert(4,\"Return\", ASII_1['Close'].pct_change())\n",
        "ASII_1 = ASII_1.dropna()\n",
        "ASII_1_test = yf.download(\"ASII.JK\", start=\"2022-06-09\", end=\"2022-07-10\")\n",
        "ASII_1_test.insert(4,\"Return\", ASII_1_test['Close'].pct_change())\n",
        "ASII_1_test = ASII_1_test.dropna()\n",
        "training_ASII_1 = ASII_1.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ASII_1_scaled = sc.fit_transform(training_ASII_1)\n",
        "X_ASII_1_train = []\n",
        "y_ASII_1_train = []\n",
        "for i in range(days_period, len(ASII_1)-1):\n",
        "    X_ASII_1_train.append(training_ASII_1_scaled[i-days_period:i, 0])\n",
        "    y_ASII_1_train.append(training_ASII_1_scaled[i, 0])\n",
        "X_ASII_1_train, y_ASII_1_train = np.array(X_ASII_1_train), np.array(y_ASII_1_train)\n",
        "X_ASII_1_train = np.reshape(X_ASII_1_train, (X_ASII_1_train.shape[0], X_ASII_1_train.shape[1], 1))\n",
        "model_ASII_1 = Sequential()\n",
        "model_ASII_1.add(LSTM(units=50,return_sequences=True,input_shape=(X_ASII_1_train.shape[1], 1)))\n",
        "model_ASII_1.add(Dropout(0.2))\n",
        "model_ASII_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_1.add(Dropout(0.2))\n",
        "model_ASII_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_1.add(Dropout(0.2))\n",
        "model_ASII_1.add(LSTM(units=50))\n",
        "model_ASII_1.add(Dropout(0.2))\n",
        "model_ASII_1.add(Dense(units=1))\n",
        "model_ASII_1.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ASII_1.fit(X_ASII_1_train,y_ASII_1_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BMRI\n",
        "BMRI_1 = yf.download(\"BMRI.JK\", start=\"2021-12-10\", end=\"2022-06-10\")\n",
        "BMRI_1.insert(4,\"Return\", BMRI_1['Close'].pct_change())\n",
        "BMRI_1 = BMRI_1.dropna()\n",
        "BMRI_1_test = yf.download(\"BMRI.JK\", start=\"2022-06-09\", end=\"2022-07-10\")\n",
        "BMRI_1_test.insert(4,\"Return\", BMRI_1_test['Close'].pct_change())\n",
        "BMRI_1_test = BMRI_1_test.dropna()\n",
        "training_BMRI_1 = BMRI_1.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BMRI_1_scaled = sc.fit_transform(training_BMRI_1)\n",
        "X_BMRI_1_train = []\n",
        "y_BMRI_1_train = []\n",
        "for i in range(days_period, len(BMRI_1)-1):\n",
        "    X_BMRI_1_train.append(training_BMRI_1_scaled[i-days_period:i, 0])\n",
        "    y_BMRI_1_train.append(training_BMRI_1_scaled[i, 0])\n",
        "X_BMRI_1_train, y_BMRI_1_train = np.array(X_BMRI_1_train), np.array(y_BMRI_1_train)\n",
        "X_BMRI_1_train = np.reshape(X_BMRI_1_train, (X_BMRI_1_train.shape[0], X_BMRI_1_train.shape[1], 1))\n",
        "model_BMRI_1 = Sequential()\n",
        "model_BMRI_1.add(LSTM(units=50,return_sequences=True,input_shape=(X_BMRI_1_train.shape[1], 1)))\n",
        "model_BMRI_1.add(Dropout(0.2))\n",
        "model_BMRI_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_1.add(Dropout(0.2))\n",
        "model_BMRI_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_1.add(Dropout(0.2))\n",
        "model_BMRI_1.add(LSTM(units=50))\n",
        "model_BMRI_1.add(Dropout(0.2))\n",
        "model_BMRI_1.add(Dense(units=1))\n",
        "model_BMRI_1.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BMRI_1.fit(X_BMRI_1_train,y_BMRI_1_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBRI\n",
        "BBRI_1 = yf.download(\"BBRI.JK\", start=\"2021-12-10\", end=\"2022-06-10\")\n",
        "BBRI_1.insert(4,\"Return\", BBRI_1['Close'].pct_change())\n",
        "BBRI_1 = BBRI_1.dropna()\n",
        "BBRI_1_test = yf.download(\"BBRI.JK\", start=\"2022-06-09\", end=\"2022-07-10\")\n",
        "BBRI_1_test.insert(4,\"Return\", BBRI_1_test['Close'].pct_change())\n",
        "BBRI_1_test = BBRI_1_test.dropna()\n",
        "training_BBRI_1 = BBRI_1.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBRI_1_scaled = sc.fit_transform(training_BBRI_1)\n",
        "X_BBRI_1_train = []\n",
        "y_BBRI_1_train = []\n",
        "for i in range(days_period, len(BBRI_1)-1):\n",
        "    X_BBRI_1_train.append(training_BBRI_1_scaled[i-days_period:i, 0])\n",
        "    y_BBRI_1_train.append(training_BBRI_1_scaled[i, 0])\n",
        "X_BBRI_1_train, y_BBRI_1_train = np.array(X_BBRI_1_train), np.array(y_BBRI_1_train)\n",
        "X_BBRI_1_train = np.reshape(X_BBRI_1_train, (X_BBRI_1_train.shape[0], X_BBRI_1_train.shape[1], 1))\n",
        "model_BBRI_1 = Sequential()\n",
        "model_BBRI_1.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBRI_1_train.shape[1], 1)))\n",
        "model_BBRI_1.add(Dropout(0.2))\n",
        "model_BBRI_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_1.add(Dropout(0.2))\n",
        "model_BBRI_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_1.add(Dropout(0.2))\n",
        "model_BBRI_1.add(LSTM(units=50))\n",
        "model_BBRI_1.add(Dropout(0.2))\n",
        "model_BBRI_1.add(Dense(units=1))\n",
        "model_BBRI_1.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBRI_1.fit(X_BBRI_1_train,y_BBRI_1_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBTN\n",
        "BBTN_1 = yf.download(\"BBTN.JK\", start=\"2021-12-10\", end=\"2022-06-10\")\n",
        "BBTN_1.insert(4,\"Return\", BBTN_1['Close'].pct_change())\n",
        "BBTN_1 = BBTN_1.dropna()\n",
        "BBTN_1_test = yf.download(\"BBTN.JK\", start=\"2022-06-09\", end=\"2022-07-10\")\n",
        "BBTN_1_test.insert(4,\"Return\", BBTN_1_test['Close'].pct_change())\n",
        "BBTN_1_test = BBTN_1_test.dropna()\n",
        "training_BBTN_1 = BBTN_1.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBTN_1_scaled = sc.fit_transform(training_BBTN_1)\n",
        "X_BBTN_1_train = []\n",
        "y_BBTN_1_train = []\n",
        "for i in range(days_period, len(BBTN_1)-1):\n",
        "    X_BBTN_1_train.append(training_BBTN_1_scaled[i-days_period:i, 0])\n",
        "    y_BBTN_1_train.append(training_BBTN_1_scaled[i, 0])\n",
        "X_BBTN_1_train, y_BBTN_1_train = np.array(X_BBTN_1_train), np.array(y_BBTN_1_train)\n",
        "X_BBTN_1_train = np.reshape(X_BBTN_1_train, (X_BBTN_1_train.shape[0], X_BBTN_1_train.shape[1], 1))\n",
        "model_BBTN_1 = Sequential()\n",
        "model_BBTN_1.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBTN_1_train.shape[1], 1)))\n",
        "model_BBTN_1.add(Dropout(0.2))\n",
        "model_BBTN_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_1.add(Dropout(0.2))\n",
        "model_BBTN_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_1.add(Dropout(0.2))\n",
        "model_BBTN_1.add(LSTM(units=50))\n",
        "model_BBTN_1.add(Dropout(0.2))\n",
        "model_BBTN_1.add(Dense(units=1))\n",
        "model_BBTN_1.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBTN_1.fit(X_BBTN_1_train,y_BBTN_1_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BUMI\n",
        "BUMI_1 = yf.download(\"BUMI.JK\", start=\"2021-12-10\", end=\"2022-06-10\")\n",
        "BUMI_1.insert(4,\"Return\", BUMI_1['Close'].pct_change())\n",
        "BUMI_1 = BUMI_1.dropna()\n",
        "BUMI_1_test = yf.download(\"BUMI.JK\", start=\"2022-06-09\", end=\"2022-07-10\")\n",
        "BUMI_1_test.insert(4,\"Return\", BUMI_1_test['Close'].pct_change())\n",
        "BUMI_1_test = BUMI_1_test.dropna()\n",
        "training_BUMI_1 = BUMI_1.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BUMI_1_scaled = sc.fit_transform(training_BUMI_1)\n",
        "X_BUMI_1_train = []\n",
        "y_BUMI_1_train = []\n",
        "for i in range(days_period, len(BUMI_1)-1):\n",
        "    X_BUMI_1_train.append(training_BUMI_1_scaled[i-days_period:i, 0])\n",
        "    y_BUMI_1_train.append(training_BUMI_1_scaled[i, 0])\n",
        "X_BUMI_1_train, y_BUMI_1_train = np.array(X_BUMI_1_train), np.array(y_BUMI_1_train)\n",
        "X_BUMI_1_train = np.reshape(X_BUMI_1_train, (X_BUMI_1_train.shape[0], X_BUMI_1_train.shape[1], 1))\n",
        "model_BUMI_1 = Sequential()\n",
        "model_BUMI_1.add(LSTM(units=50,return_sequences=True,input_shape=(X_BUMI_1_train.shape[1], 1)))\n",
        "model_BUMI_1.add(Dropout(0.2))\n",
        "model_BUMI_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_1.add(Dropout(0.2))\n",
        "model_BUMI_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_1.add(Dropout(0.2))\n",
        "model_BUMI_1.add(LSTM(units=50))\n",
        "model_BUMI_1.add(Dropout(0.2))\n",
        "model_BUMI_1.add(Dense(units=1))\n",
        "model_BUMI_1.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BUMI_1.fit(X_BUMI_1_train,y_BUMI_1_train,epochs=10,batch_size=16)\n",
        "\n",
        "# MFIN\n",
        "MFIN_1 = yf.download(\"MFIN.JK\", start=\"2021-12-10\", end=\"2022-06-10\")\n",
        "MFIN_1.insert(4,\"Return\", MFIN_1['Close'].pct_change())\n",
        "MFIN_1 = MFIN_1.dropna()\n",
        "MFIN_1_test = yf.download(\"MFIN.JK\", start=\"2022-06-09\", end=\"2022-07-10\")\n",
        "MFIN_1_test.insert(4,\"Return\", MFIN_1_test['Close'].pct_change())\n",
        "MFIN_1_test = MFIN_1_test.dropna()\n",
        "training_MFIN_1 = MFIN_1.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_MFIN_1_scaled = sc.fit_transform(training_MFIN_1)\n",
        "X_MFIN_1_train = []\n",
        "y_MFIN_1_train = []\n",
        "for i in range(days_period, len(MFIN_1)-1):\n",
        "    X_MFIN_1_train.append(training_MFIN_1_scaled[i-days_period:i, 0])\n",
        "    y_MFIN_1_train.append(training_MFIN_1_scaled[i, 0])\n",
        "X_MFIN_1_train, y_MFIN_1_train = np.array(X_MFIN_1_train), np.array(y_MFIN_1_train)\n",
        "X_MFIN_1_train = np.reshape(X_MFIN_1_train, (X_MFIN_1_train.shape[0], X_MFIN_1_train.shape[1], 1))\n",
        "model_MFIN_1 = Sequential()\n",
        "model_MFIN_1.add(LSTM(units=50,return_sequences=True,input_shape=(X_MFIN_1_train.shape[1], 1)))\n",
        "model_MFIN_1.add(Dropout(0.2))\n",
        "model_MFIN_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_1.add(Dropout(0.2))\n",
        "model_MFIN_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_1.add(Dropout(0.2))\n",
        "model_MFIN_1.add(LSTM(units=50))\n",
        "model_MFIN_1.add(Dropout(0.2))\n",
        "model_MFIN_1.add(Dense(units=1))\n",
        "model_MFIN_1.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_MFIN_1.fit(X_MFIN_1_train,y_MFIN_1_train,epochs=10,batch_size=16)\n",
        "\n",
        "# EXCL\n",
        "EXCL_1 = yf.download(\"EXCL.JK\", start=\"2021-12-10\", end=\"2022-06-10\")\n",
        "EXCL_1.insert(4,\"Return\", EXCL_1['Close'].pct_change())\n",
        "EXCL_1 = EXCL_1.dropna()\n",
        "EXCL_1_test = yf.download(\"EXCL.JK\", start=\"2022-06-09\", end=\"2022-07-10\")\n",
        "EXCL_1_test.insert(4,\"Return\", EXCL_1_test['Close'].pct_change())\n",
        "EXCL_1_test = EXCL_1_test.dropna()\n",
        "training_EXCL_1 = EXCL_1.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_EXCL_1_scaled = sc.fit_transform(training_EXCL_1)\n",
        "X_EXCL_1_train = []\n",
        "y_EXCL_1_train = []\n",
        "for i in range(days_period, len(EXCL_1)-1):\n",
        "    X_EXCL_1_train.append(training_EXCL_1_scaled[i-days_period:i, 0])\n",
        "    y_EXCL_1_train.append(training_EXCL_1_scaled[i, 0])\n",
        "X_EXCL_1_train, y_EXCL_1_train = np.array(X_EXCL_1_train), np.array(y_EXCL_1_train)\n",
        "X_EXCL_1_train = np.reshape(X_EXCL_1_train, (X_EXCL_1_train.shape[0], X_EXCL_1_train.shape[1], 1))\n",
        "model_EXCL_1 = Sequential()\n",
        "model_EXCL_1.add(LSTM(units=50,return_sequences=True,input_shape=(X_EXCL_1_train.shape[1], 1)))\n",
        "model_EXCL_1.add(Dropout(0.2))\n",
        "model_EXCL_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_1.add(Dropout(0.2))\n",
        "model_EXCL_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_1.add(Dropout(0.2))\n",
        "model_EXCL_1.add(LSTM(units=50))\n",
        "model_EXCL_1.add(Dropout(0.2))\n",
        "model_EXCL_1.add(Dense(units=1))\n",
        "model_EXCL_1.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_EXCL_1.fit(X_EXCL_1_train,y_EXCL_1_train,epochs=10,batch_size=16)\n",
        "\n",
        "# PGAS\n",
        "PGAS_1 = yf.download(\"PGAS.JK\", start=\"2021-12-10\", end=\"2022-06-10\")\n",
        "PGAS_1.insert(4,\"Return\", PGAS_1['Close'].pct_change())\n",
        "PGAS_1 = PGAS_1.dropna()\n",
        "PGAS_1_test = yf.download(\"PGAS.JK\", start=\"2022-06-09\", end=\"2022-07-10\")\n",
        "PGAS_1_test.insert(4,\"Return\", PGAS_1_test['Close'].pct_change())\n",
        "PGAS_1_test = PGAS_1_test.dropna()\n",
        "training_PGAS_1 = PGAS_1.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_PGAS_1_scaled = sc.fit_transform(training_PGAS_1)\n",
        "X_PGAS_1_train = []\n",
        "y_PGAS_1_train = []\n",
        "for i in range(days_period, len(PGAS_1)-1):\n",
        "    X_PGAS_1_train.append(training_PGAS_1_scaled[i-days_period:i, 0])\n",
        "    y_PGAS_1_train.append(training_PGAS_1_scaled[i, 0])\n",
        "X_PGAS_1_train, y_PGAS_1_train = np.array(X_PGAS_1_train), np.array(y_PGAS_1_train)\n",
        "X_PGAS_1_train = np.reshape(X_PGAS_1_train, (X_PGAS_1_train.shape[0], X_PGAS_1_train.shape[1], 1))\n",
        "model_PGAS_1 = Sequential()\n",
        "model_PGAS_1.add(LSTM(units=50,return_sequences=True,input_shape=(X_PGAS_1_train.shape[1], 1)))\n",
        "model_PGAS_1.add(Dropout(0.2))\n",
        "model_PGAS_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_1.add(Dropout(0.2))\n",
        "model_PGAS_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_1.add(Dropout(0.2))\n",
        "model_PGAS_1.add(LSTM(units=50))\n",
        "model_PGAS_1.add(Dropout(0.2))\n",
        "model_PGAS_1.add(Dense(units=1))\n",
        "model_PGAS_1.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_PGAS_1.fit(X_PGAS_1_train,y_PGAS_1_train,epochs=10,batch_size=16)\n",
        "\n",
        "# TLKM\n",
        "TLKM_1 = yf.download(\"TLKM.JK\", start=\"2021-12-10\", end=\"2022-06-10\")\n",
        "TLKM_1.insert(4,\"Return\", TLKM_1['Close'].pct_change())\n",
        "TLKM_1 = TLKM_1.dropna()\n",
        "TLKM_1_test = yf.download(\"TLKM.JK\", start=\"2022-06-09\", end=\"2022-07-10\")\n",
        "TLKM_1_test.insert(4,\"Return\", TLKM_1_test['Close'].pct_change())\n",
        "TLKM_1_test = TLKM_1_test.dropna()\n",
        "training_TLKM_1 = TLKM_1.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_TLKM_1_scaled = sc.fit_transform(training_TLKM_1)\n",
        "X_TLKM_1_train = []\n",
        "y_TLKM_1_train = []\n",
        "for i in range(days_period, len(TLKM_1)-1):\n",
        "    X_TLKM_1_train.append(training_TLKM_1_scaled[i-days_period:i, 0])\n",
        "    y_TLKM_1_train.append(training_TLKM_1_scaled[i, 0])\n",
        "X_TLKM_1_train, y_TLKM_1_train = np.array(X_TLKM_1_train), np.array(y_TLKM_1_train)\n",
        "X_TLKM_1_train = np.reshape(X_TLKM_1_train, (X_TLKM_1_train.shape[0], X_TLKM_1_train.shape[1], 1))\n",
        "model_TLKM_1 = Sequential()\n",
        "model_TLKM_1.add(LSTM(units=50,return_sequences=True,input_shape=(X_TLKM_1_train.shape[1], 1)))\n",
        "model_TLKM_1.add(Dropout(0.2))\n",
        "model_TLKM_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_1.add(Dropout(0.2))\n",
        "model_TLKM_1.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_1.add(Dropout(0.2))\n",
        "model_TLKM_1.add(LSTM(units=50))\n",
        "model_TLKM_1.add(Dropout(0.2))\n",
        "model_TLKM_1.add(Dense(units=1))\n",
        "model_TLKM_1.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_TLKM_1.fit(X_TLKM_1_train,y_TLKM_1_train,epochs=10,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb983996-017f-4a9e-e0aa-178015c30860",
        "id": "TaTktAyv9Pzz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ],
      "source": [
        "# ADRO\n",
        "real_ADRO_1_return = ADRO_1_test.iloc[:, 4:5].values\n",
        "real_ADRO_1_return = real_ADRO_1_return[:days_predict]\n",
        "ADRO_1_total = ADRO_1['Close'].copy(deep=True)\n",
        "inputs_ADRO_1 = ADRO_1_total[len(ADRO_1) - days_period: len(ADRO_1)].values\n",
        "inputs_ADRO_1 = inputs_ADRO_1.reshape(-1,1)\n",
        "inputs_ADRO_1 = sc.transform(inputs_ADRO_1)\n",
        "predicted_ADRO_1_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ADRO_1_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ADRO_1_test.append(inputs_ADRO_1[i:i+days_period, 0])\n",
        "  X_ADRO_1_test = np.array(X_ADRO_1_test)\n",
        "  X_ADRO_1_test = np.reshape(X_ADRO_1_test, (X_ADRO_1_test.shape[0], X_ADRO_1_test.shape[1], 1))\n",
        "  predicted_ADRO_1_return[j] = model_ADRO_1.predict(X_ADRO_1_test)\n",
        "  inputs_ADRO_1 += (predicted_ADRO_1_return[j])\n",
        "  inputs_ADRO_1 = inputs_ADRO_1.reshape(-1,1)\n",
        "\n",
        "# ASII\n",
        "real_ASII_1_return = ASII_1_test.iloc[:, 4:5].values\n",
        "real_ASII_1_return = real_ASII_1_return[:days_predict]\n",
        "ASII_1_total = ASII_1['Close'].copy(deep=True)\n",
        "inputs_ASII_1 = ASII_1_total[len(ASII_1) - days_period: len(ASII_1)].values\n",
        "inputs_ASII_1 = inputs_ASII_1.reshape(-1,1)\n",
        "inputs_ASII_1 = sc.transform(inputs_ASII_1)\n",
        "predicted_ASII_1_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ASII_1_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ASII_1_test.append(inputs_ASII_1[i:i+days_period, 0])\n",
        "  X_ASII_1_test = np.array(X_ASII_1_test)\n",
        "  X_ASII_1_test = np.reshape(X_ASII_1_test, (X_ASII_1_test.shape[0], X_ASII_1_test.shape[1], 1))\n",
        "  predicted_ASII_1_return[j] = model_ASII_1.predict(X_ASII_1_test)\n",
        "  inputs_ASII_1 += (predicted_ASII_1_return[j])\n",
        "  inputs_ASII_1 = inputs_ASII_1.reshape(-1,1)\n",
        "\n",
        "# BMRI\n",
        "real_BMRI_1_return = BMRI_1_test.iloc[:, 4:5].values\n",
        "real_BMRI_1_return = real_BMRI_1_return[:days_predict]\n",
        "BMRI_1_total = BMRI_1['Close'].copy(deep=True)\n",
        "inputs_BMRI_1 = BMRI_1_total[len(BMRI_1) - days_period: len(BMRI_1)].values\n",
        "inputs_BMRI_1 = inputs_BMRI_1.reshape(-1,1)\n",
        "inputs_BMRI_1 = sc.transform(inputs_BMRI_1)\n",
        "predicted_BMRI_1_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BMRI_1_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BMRI_1_test.append(inputs_BMRI_1[i:i+days_period, 0])\n",
        "  X_BMRI_1_test = np.array(X_BMRI_1_test)\n",
        "  X_BMRI_1_test = np.reshape(X_BMRI_1_test, (X_BMRI_1_test.shape[0], X_BMRI_1_test.shape[1], 1))\n",
        "  predicted_BMRI_1_return[j] = model_BMRI_1.predict(X_BMRI_1_test)\n",
        "  inputs_BMRI_1 += (predicted_BMRI_1_return[j])\n",
        "  inputs_BMRI_1 = inputs_BMRI_1.reshape(-1,1)\n",
        "\n",
        "# BBRI\n",
        "real_BBRI_1_return = BBRI_1_test.iloc[:, 4:5].values\n",
        "real_BBRI_1_return = real_BBRI_1_return[:days_predict]\n",
        "BBRI_1_total = BBRI_1['Close'].copy(deep=True)\n",
        "inputs_BBRI_1 = BBRI_1_total[len(BBRI_1) - days_period: len(BBRI_1)].values\n",
        "inputs_BBRI_1 = inputs_BBRI_1.reshape(-1,1)\n",
        "inputs_BBRI_1 = sc.transform(inputs_BBRI_1)\n",
        "predicted_BBRI_1_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBRI_1_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBRI_1_test.append(inputs_BBRI_1[i:i+days_period, 0])\n",
        "  X_BBRI_1_test = np.array(X_BBRI_1_test)\n",
        "  X_BBRI_1_test = np.reshape(X_BBRI_1_test, (X_BBRI_1_test.shape[0], X_BBRI_1_test.shape[1], 1))\n",
        "  predicted_BBRI_1_return[j] = model_BBRI_1.predict(X_BBRI_1_test)\n",
        "  inputs_BBRI_1 += (predicted_BBRI_1_return[j])\n",
        "  inputs_BBRI_1 = inputs_BBRI_1.reshape(-1,1)\n",
        "\n",
        "# BBTN\n",
        "real_BBTN_1_return = BBTN_1_test.iloc[:, 4:5].values\n",
        "real_BBTN_1_return = real_BBTN_1_return[:days_predict]\n",
        "BBTN_1_total = BBTN_1['Close'].copy(deep=True)\n",
        "inputs_BBTN_1 = BBTN_1_total[len(BBTN_1) - days_period: len(BBTN_1)].values\n",
        "inputs_BBTN_1 = inputs_BBTN_1.reshape(-1,1)\n",
        "inputs_BBTN_1 = sc.transform(inputs_BBTN_1)\n",
        "predicted_BBTN_1_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBTN_1_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBTN_1_test.append(inputs_BBTN_1[i:i+days_period, 0])\n",
        "  X_BBTN_1_test = np.array(X_BBTN_1_test)\n",
        "  X_BBTN_1_test = np.reshape(X_BBTN_1_test, (X_BBTN_1_test.shape[0], X_BBTN_1_test.shape[1], 1))\n",
        "  predicted_BBTN_1_return[j] = model_BBTN_1.predict(X_BBTN_1_test)\n",
        "  inputs_BBTN_1 += (predicted_BBTN_1_return[j])\n",
        "  inputs_BBTN_1 = inputs_BBTN_1.reshape(-1,1)\n",
        "\n",
        "# BUMI\n",
        "real_BUMI_1_return = BUMI_1_test.iloc[:, 4:5].values\n",
        "real_BUMI_1_return = real_BUMI_1_return[:days_predict]\n",
        "BUMI_1_total = BUMI_1['Close'].copy(deep=True)\n",
        "inputs_BUMI_1 = BUMI_1_total[len(BUMI_1) - days_period: len(BUMI_1)].values\n",
        "inputs_BUMI_1 = inputs_BUMI_1.reshape(-1,1)\n",
        "inputs_BUMI_1 = sc.transform(inputs_BUMI_1)\n",
        "predicted_BUMI_1_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BUMI_1_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BUMI_1_test.append(inputs_BUMI_1[i:i+days_period, 0])\n",
        "  X_BUMI_1_test = np.array(X_BUMI_1_test)\n",
        "  X_BUMI_1_test = np.reshape(X_BUMI_1_test, (X_BUMI_1_test.shape[0], X_BUMI_1_test.shape[1], 1))\n",
        "  predicted_BUMI_1_return[j] = model_BUMI_1.predict(X_BUMI_1_test)\n",
        "  inputs_BUMI_1 += (predicted_BUMI_1_return[j])\n",
        "  inputs_BUMI_1 = inputs_BUMI_1.reshape(-1,1)\n",
        "\n",
        "# MFIN\n",
        "real_MFIN_1_return = MFIN_1_test.iloc[:, 4:5].values\n",
        "real_MFIN_1_return = real_MFIN_1_return[:days_predict]\n",
        "MFIN_1_total = MFIN_1['Close'].copy(deep=True)\n",
        "inputs_MFIN_1 = MFIN_1_total[len(MFIN_1) - days_period: len(MFIN_1)].values\n",
        "inputs_MFIN_1 = inputs_MFIN_1.reshape(-1,1)\n",
        "inputs_MFIN_1 = sc.transform(inputs_MFIN_1)\n",
        "predicted_MFIN_1_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_MFIN_1_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_MFIN_1_test.append(inputs_MFIN_1[i:i+days_period, 0])\n",
        "  X_MFIN_1_test = np.array(X_MFIN_1_test)\n",
        "  X_MFIN_1_test = np.reshape(X_MFIN_1_test, (X_MFIN_1_test.shape[0], X_MFIN_1_test.shape[1], 1))\n",
        "  predicted_MFIN_1_return[j] = model_MFIN_1.predict(X_MFIN_1_test)\n",
        "  inputs_MFIN_1 += (predicted_MFIN_1_return[j])\n",
        "  inputs_MFIN_1 = inputs_MFIN_1.reshape(-1,1)\n",
        "\n",
        "# EXCL\n",
        "real_EXCL_1_return = EXCL_1_test.iloc[:, 4:5].values\n",
        "real_EXCL_1_return = real_EXCL_1_return[:days_predict]\n",
        "EXCL_1_total = EXCL_1['Close'].copy(deep=True)\n",
        "inputs_EXCL_1 = EXCL_1_total[len(EXCL_1) - days_period: len(EXCL_1)].values\n",
        "inputs_EXCL_1 = inputs_EXCL_1.reshape(-1,1)\n",
        "inputs_EXCL_1 = sc.transform(inputs_EXCL_1)\n",
        "predicted_EXCL_1_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_EXCL_1_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_EXCL_1_test.append(inputs_EXCL_1[i:i+days_period, 0])\n",
        "  X_EXCL_1_test = np.array(X_EXCL_1_test)\n",
        "  X_EXCL_1_test = np.reshape(X_EXCL_1_test, (X_EXCL_1_test.shape[0], X_EXCL_1_test.shape[1], 1))\n",
        "  predicted_EXCL_1_return[j] = model_EXCL_1.predict(X_EXCL_1_test)\n",
        "  inputs_EXCL_1 += (predicted_EXCL_1_return[j])\n",
        "  inputs_EXCL_1 = inputs_EXCL_1.reshape(-1,1)\n",
        "\n",
        "# PGAS\n",
        "real_PGAS_1_return = PGAS_1_test.iloc[:, 4:5].values\n",
        "real_PGAS_1_return = real_PGAS_1_return[:days_predict]\n",
        "PGAS_1_total = PGAS_1['Close'].copy(deep=True)\n",
        "inputs_PGAS_1 = PGAS_1_total[len(PGAS_1) - days_period: len(PGAS_1)].values\n",
        "inputs_PGAS_1 = inputs_PGAS_1.reshape(-1,1)\n",
        "inputs_PGAS_1 = sc.transform(inputs_PGAS_1)\n",
        "predicted_PGAS_1_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_PGAS_1_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_PGAS_1_test.append(inputs_PGAS_1[i:i+days_period, 0])\n",
        "  X_PGAS_1_test = np.array(X_PGAS_1_test)\n",
        "  X_PGAS_1_test = np.reshape(X_PGAS_1_test, (X_PGAS_1_test.shape[0], X_PGAS_1_test.shape[1], 1))\n",
        "  predicted_PGAS_1_return[j] = model_PGAS_1.predict(X_PGAS_1_test)\n",
        "  inputs_PGAS_1 += (predicted_PGAS_1_return[j])\n",
        "  inputs_PGAS_1 = inputs_PGAS_1.reshape(-1,1)\n",
        "\n",
        "# TLKM\n",
        "real_TLKM_1_return = TLKM_1_test.iloc[:, 4:5].values\n",
        "real_TLKM_1_return = real_TLKM_1_return[:days_predict]\n",
        "TLKM_1_total = TLKM_1['Close'].copy(deep=True)\n",
        "inputs_TLKM_1 = TLKM_1_total[len(TLKM_1) - days_period: len(TLKM_1)].values\n",
        "inputs_TLKM_1 = inputs_TLKM_1.reshape(-1,1)\n",
        "inputs_TLKM_1 = sc.transform(inputs_TLKM_1)\n",
        "predicted_TLKM_1_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_TLKM_1_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_TLKM_1_test.append(inputs_TLKM_1[i:i+days_period, 0])\n",
        "  X_TLKM_1_test = np.array(X_TLKM_1_test)\n",
        "  X_TLKM_1_test = np.reshape(X_TLKM_1_test, (X_TLKM_1_test.shape[0], X_TLKM_1_test.shape[1], 1))\n",
        "  predicted_TLKM_1_return[j] = model_TLKM_1.predict(X_TLKM_1_test)\n",
        "  inputs_TLKM_1 += (predicted_TLKM_1_return[j])\n",
        "  inputs_TLKM_1 = inputs_TLKM_1.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPMBVdyE9Pz0"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "predicted_ADRO_1_return = np.squeeze(np.asarray(predicted_ADRO_1_return))\n",
        "predicted_ADRO_1_return = predicted_ADRO_1_return.reshape(-1,1)\n",
        "predicted_ADRO_1_return = sc.inverse_transform(predicted_ADRO_1_return)\n",
        "# ASII\n",
        "predicted_ASII_1_return = np.squeeze(np.asarray(predicted_ASII_1_return))\n",
        "predicted_ASII_1_return = predicted_ASII_1_return.reshape(-1,1)\n",
        "predicted_ASII_1_return = sc.inverse_transform(predicted_ASII_1_return)\n",
        "# BMRI\n",
        "predicted_BMRI_1_return = np.squeeze(np.asarray(predicted_BMRI_1_return))\n",
        "predicted_BMRI_1_return = predicted_BMRI_1_return.reshape(-1,1)\n",
        "predicted_BMRI_1_return = sc.inverse_transform(predicted_BMRI_1_return)\n",
        "# BBRI\n",
        "predicted_BBRI_1_return = np.squeeze(np.asarray(predicted_BBRI_1_return))\n",
        "predicted_BBRI_1_return = predicted_BBRI_1_return.reshape(-1,1)\n",
        "predicted_BBRI_1_return = sc.inverse_transform(predicted_BBRI_1_return)\n",
        "# BBTN\n",
        "predicted_BBTN_1_return = np.squeeze(np.asarray(predicted_BBTN_1_return))\n",
        "predicted_BBTN_1_return = predicted_BBTN_1_return.reshape(-1,1)\n",
        "predicted_BBTN_1_return = sc.inverse_transform(predicted_BBTN_1_return)\n",
        "# BUMI\n",
        "predicted_BUMI_1_return = np.squeeze(np.asarray(predicted_BUMI_1_return))\n",
        "predicted_BUMI_1_return = predicted_BUMI_1_return.reshape(-1,1)\n",
        "predicted_BUMI_1_return = sc.inverse_transform(predicted_BUMI_1_return)\n",
        "# MFIN\n",
        "predicted_MFIN_1_return = np.squeeze(np.asarray(predicted_MFIN_1_return))\n",
        "predicted_MFIN_1_return = predicted_MFIN_1_return.reshape(-1,1)\n",
        "predicted_MFIN_1_return = sc.inverse_transform(predicted_MFIN_1_return)\n",
        "# EXCL\n",
        "predicted_EXCL_1_return = np.squeeze(np.asarray(predicted_EXCL_1_return))\n",
        "predicted_EXCL_1_return = predicted_EXCL_1_return.reshape(-1,1)\n",
        "predicted_EXCL_1_return = sc.inverse_transform(predicted_EXCL_1_return)\n",
        "# PGAS\n",
        "predicted_PGAS_1_return = np.squeeze(np.asarray(predicted_PGAS_1_return))\n",
        "predicted_PGAS_1_return = predicted_PGAS_1_return.reshape(-1,1)\n",
        "predicted_PGAS_1_return = sc.inverse_transform(predicted_PGAS_1_return)\n",
        "# TLKM\n",
        "predicted_TLKM_1_return = np.squeeze(np.asarray(predicted_TLKM_1_return))\n",
        "predicted_TLKM_1_return = predicted_TLKM_1_return.reshape(-1,1)\n",
        "predicted_TLKM_1_return = sc.inverse_transform(predicted_TLKM_1_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqMEewFd9Pz1"
      },
      "outputs": [],
      "source": [
        "predicted1 = pd.DataFrame(predicted_ADRO_1_return)\n",
        "predicted1.rename(columns={0:'ADRO'}, inplace=True)\n",
        "predicted1.insert(1,\"ASII\", predicted_ASII_1_return)\n",
        "predicted1.insert(2,\"BBRI\", predicted_BBRI_1_return)\n",
        "predicted1.insert(3,\"BBTN\", predicted_BBTN_1_return)\n",
        "predicted1.insert(4,\"BMRI\", predicted_BMRI_1_return)\n",
        "predicted1.insert(5,\"BUMI\", predicted_BUMI_1_return)\n",
        "predicted1.insert(6,\"EXCL\", predicted_EXCL_1_return)\n",
        "predicted1.insert(7,\"MFIN\", predicted_MFIN_1_return)\n",
        "predicted1.insert(8,\"PGAS\", predicted_PGAS_1_return)\n",
        "predicted1.insert(9,\"TLKM\", predicted_TLKM_1_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJKWoSvzPSMm",
        "outputId": "5c6bf754-82a8-4980-dac5-bc350f942232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADRO      ASII      BBRI      BBTN      BMRI      BUMI      EXCL  \\\n",
              "0 -0.007398  0.017600  0.026404  0.003474  0.023060  0.002148 -0.000970   \n",
              "1 -0.008169  0.016457  0.025395  0.002399  0.022303  0.001517 -0.001755   \n",
              "2 -0.009090  0.015061  0.024159  0.001144  0.021348  0.000735 -0.002706   \n",
              "3 -0.010183  0.013368  0.022652 -0.000317  0.020153 -0.000231 -0.003852   \n",
              "4 -0.011477  0.011330  0.020822 -0.002013  0.018668 -0.001416 -0.005226   \n",
              "5 -0.013000  0.008897  0.018609 -0.003978  0.016835 -0.002861 -0.006864   \n",
              "6 -0.014783  0.006019  0.015950 -0.006244  0.014590 -0.004616 -0.008801   \n",
              "7 -0.016854  0.002650  0.012774 -0.008845  0.011864 -0.006734 -0.011075   \n",
              "8 -0.019244 -0.001251  0.009013 -0.011814  0.008582 -0.009266 -0.013717   \n",
              "9 -0.021975 -0.005708  0.004603 -0.015179  0.004671 -0.012266 -0.016756   \n",
              "\n",
              "       MFIN      PGAS      TLKM  \n",
              "0  0.033367  0.018451  0.008050  \n",
              "1  0.032150  0.017539  0.006765  \n",
              "2  0.030655  0.016435  0.005249  \n",
              "3  0.028826  0.015102  0.003468  \n",
              "4  0.026601  0.013496  0.001385  \n",
              "5  0.023911  0.011566 -0.001037  \n",
              "6  0.020683  0.009258 -0.003832  \n",
              "7  0.016841  0.006508 -0.007033  \n",
              "8  0.012316  0.003256 -0.010661  \n",
              "9  0.007052 -0.000563 -0.014727  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-255424ce-5c24-4b6c-a36b-dbc2512e1e5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADRO</th>\n",
              "      <th>ASII</th>\n",
              "      <th>BBRI</th>\n",
              "      <th>BBTN</th>\n",
              "      <th>BMRI</th>\n",
              "      <th>BUMI</th>\n",
              "      <th>EXCL</th>\n",
              "      <th>MFIN</th>\n",
              "      <th>PGAS</th>\n",
              "      <th>TLKM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.007398</td>\n",
              "      <td>0.017600</td>\n",
              "      <td>0.026404</td>\n",
              "      <td>0.003474</td>\n",
              "      <td>0.023060</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>-0.000970</td>\n",
              "      <td>0.033367</td>\n",
              "      <td>0.018451</td>\n",
              "      <td>0.008050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.008169</td>\n",
              "      <td>0.016457</td>\n",
              "      <td>0.025395</td>\n",
              "      <td>0.002399</td>\n",
              "      <td>0.022303</td>\n",
              "      <td>0.001517</td>\n",
              "      <td>-0.001755</td>\n",
              "      <td>0.032150</td>\n",
              "      <td>0.017539</td>\n",
              "      <td>0.006765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.009090</td>\n",
              "      <td>0.015061</td>\n",
              "      <td>0.024159</td>\n",
              "      <td>0.001144</td>\n",
              "      <td>0.021348</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>-0.002706</td>\n",
              "      <td>0.030655</td>\n",
              "      <td>0.016435</td>\n",
              "      <td>0.005249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.010183</td>\n",
              "      <td>0.013368</td>\n",
              "      <td>0.022652</td>\n",
              "      <td>-0.000317</td>\n",
              "      <td>0.020153</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>-0.003852</td>\n",
              "      <td>0.028826</td>\n",
              "      <td>0.015102</td>\n",
              "      <td>0.003468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.011477</td>\n",
              "      <td>0.011330</td>\n",
              "      <td>0.020822</td>\n",
              "      <td>-0.002013</td>\n",
              "      <td>0.018668</td>\n",
              "      <td>-0.001416</td>\n",
              "      <td>-0.005226</td>\n",
              "      <td>0.026601</td>\n",
              "      <td>0.013496</td>\n",
              "      <td>0.001385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.013000</td>\n",
              "      <td>0.008897</td>\n",
              "      <td>0.018609</td>\n",
              "      <td>-0.003978</td>\n",
              "      <td>0.016835</td>\n",
              "      <td>-0.002861</td>\n",
              "      <td>-0.006864</td>\n",
              "      <td>0.023911</td>\n",
              "      <td>0.011566</td>\n",
              "      <td>-0.001037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.014783</td>\n",
              "      <td>0.006019</td>\n",
              "      <td>0.015950</td>\n",
              "      <td>-0.006244</td>\n",
              "      <td>0.014590</td>\n",
              "      <td>-0.004616</td>\n",
              "      <td>-0.008801</td>\n",
              "      <td>0.020683</td>\n",
              "      <td>0.009258</td>\n",
              "      <td>-0.003832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.016854</td>\n",
              "      <td>0.002650</td>\n",
              "      <td>0.012774</td>\n",
              "      <td>-0.008845</td>\n",
              "      <td>0.011864</td>\n",
              "      <td>-0.006734</td>\n",
              "      <td>-0.011075</td>\n",
              "      <td>0.016841</td>\n",
              "      <td>0.006508</td>\n",
              "      <td>-0.007033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.019244</td>\n",
              "      <td>-0.001251</td>\n",
              "      <td>0.009013</td>\n",
              "      <td>-0.011814</td>\n",
              "      <td>0.008582</td>\n",
              "      <td>-0.009266</td>\n",
              "      <td>-0.013717</td>\n",
              "      <td>0.012316</td>\n",
              "      <td>0.003256</td>\n",
              "      <td>-0.010661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.021975</td>\n",
              "      <td>-0.005708</td>\n",
              "      <td>0.004603</td>\n",
              "      <td>-0.015179</td>\n",
              "      <td>0.004671</td>\n",
              "      <td>-0.012266</td>\n",
              "      <td>-0.016756</td>\n",
              "      <td>0.007052</td>\n",
              "      <td>-0.000563</td>\n",
              "      <td>-0.014727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-255424ce-5c24-4b6c-a36b-dbc2512e1e5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-255424ce-5c24-4b6c-a36b-dbc2512e1e5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-255424ce-5c24-4b6c-a36b-dbc2512e1e5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWO-2sVncbua"
      },
      "source": [
        "## Data Preparation 2\n",
        "1st of January 2018 - 9th of July 2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e5f609c-f556-42d4-da58-76770d95b956",
        "id": "CKtyBXj3Gwqk"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 43ms/step - loss: 0.0663\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0324\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0300\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0277\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0262\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0279\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0240\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0263\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0258\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0242\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 40ms/step - loss: 0.1484\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0386\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0251\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0297\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0251\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0241\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0236\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0247\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0247\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0234\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 40ms/step - loss: 0.1153\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0275\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0242\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0235\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0206\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 0.0186\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0153\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0172\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0176\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0182\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 42ms/step - loss: 0.1908\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 0.0559\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0340\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0365\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0268\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0261\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0259\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0246\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0261\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0257\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 11s 41ms/step - loss: 0.0837\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0216\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0139\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0116\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0134\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0112\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0112\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0114\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0123\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0122\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 41ms/step - loss: 0.0950\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0530\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0457\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0407\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0421\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0439\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0401\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0457\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0428\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0425\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 43ms/step - loss: 0.1056\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0325\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0258\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0250\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0203\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0215\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0241\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0221\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0205\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0210\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 40ms/step - loss: 0.1235\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0659\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0479\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0476\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0399\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0409\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0413\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.0391\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0376\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 73ms/step - loss: 0.0401\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 8s 42ms/step - loss: 0.1673\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0408\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0328\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0315\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0304\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 71ms/step - loss: 0.0298\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 73ms/step - loss: 0.0311\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 74ms/step - loss: 0.0318\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 73ms/step - loss: 0.0301\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0309\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 8s 41ms/step - loss: 0.2672\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0577\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0354\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0313\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0334\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 74ms/step - loss: 0.0255\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 73ms/step - loss: 0.0242\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0285\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0303\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 74ms/step - loss: 0.0313\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1d72b4d870>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Period parameters\n",
        "days_period = 20\n",
        "days_predict = 10\n",
        "\n",
        "# ADRO\n",
        "ADRO_2 = yf.download(\"ADRO.JK\", start=\"2022-01-10\", end=\"2022-07-10\")\n",
        "ADRO_2.insert(4,\"Return\", ADRO_2['Close'].pct_change())\n",
        "ADRO_2 = ADRO_2.dropna()\n",
        "ADRO_2_test = yf.download(\"ADRO.JK\", start=\"2022-07-09\", end=\"2022-08-10\")\n",
        "ADRO_2_test.insert(4,\"Return\", ADRO_2_test['Close'].pct_change())\n",
        "ADRO_2_test = ADRO_2_test.dropna()\n",
        "training_ADRO_2 = ADRO_2.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ADRO_2_scaled = sc.fit_transform(training_ADRO_2)\n",
        "X_ADRO_2_train = []\n",
        "y_ADRO_2_train = []\n",
        "for i in range(days_period, len(ADRO_2)-1):\n",
        "    X_ADRO_2_train.append(training_ADRO_2_scaled[i-days_period:i, 0])\n",
        "    y_ADRO_2_train.append(training_ADRO_2_scaled[i, 0])\n",
        "X_ADRO_2_train, y_ADRO_2_train = np.array(X_ADRO_2_train), np.array(y_ADRO_2_train)\n",
        "X_ADRO_2_train = np.reshape(X_ADRO_2_train, (X_ADRO_2_train.shape[0], X_ADRO_2_train.shape[1], 1))\n",
        "model_ADRO_2 = Sequential()\n",
        "model_ADRO_2.add(LSTM(units=50,return_sequences=True,input_shape=(X_ADRO_2_train.shape[1], 1)))\n",
        "model_ADRO_2.add(Dropout(0.2))\n",
        "model_ADRO_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_2.add(Dropout(0.2))\n",
        "model_ADRO_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_2.add(Dropout(0.2))\n",
        "model_ADRO_2.add(LSTM(units=50))\n",
        "model_ADRO_2.add(Dropout(0.2))\n",
        "model_ADRO_2.add(Dense(units=1))\n",
        "model_ADRO_2.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ADRO_2.fit(X_ADRO_2_train,y_ADRO_2_train,epochs=10,batch_size=16)\n",
        "\n",
        "# ASII\n",
        "ASII_2 = yf.download(\"ASII.JK\", start=\"2022-01-10\", end=\"2022-07-10\")\n",
        "ASII_2.insert(4,\"Return\", ASII_2['Close'].pct_change())\n",
        "ASII_2 = ASII_2.dropna()\n",
        "ASII_2_test = yf.download(\"ASII.JK\", start=\"2022-07-09\", end=\"2022-08-10\")\n",
        "ASII_2_test.insert(4,\"Return\", ASII_2_test['Close'].pct_change())\n",
        "ASII_2_test = ASII_2_test.dropna()\n",
        "training_ASII_2 = ASII_2.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ASII_2_scaled = sc.fit_transform(training_ASII_2)\n",
        "X_ASII_2_train = []\n",
        "y_ASII_2_train = []\n",
        "for i in range(days_period, len(ASII_2)-1):\n",
        "    X_ASII_2_train.append(training_ASII_2_scaled[i-days_period:i, 0])\n",
        "    y_ASII_2_train.append(training_ASII_2_scaled[i, 0])\n",
        "X_ASII_2_train, y_ASII_2_train = np.array(X_ASII_2_train), np.array(y_ASII_2_train)\n",
        "X_ASII_2_train = np.reshape(X_ASII_2_train, (X_ASII_2_train.shape[0], X_ASII_2_train.shape[1], 1))\n",
        "model_ASII_2 = Sequential()\n",
        "model_ASII_2.add(LSTM(units=50,return_sequences=True,input_shape=(X_ASII_2_train.shape[1], 1)))\n",
        "model_ASII_2.add(Dropout(0.2))\n",
        "model_ASII_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_2.add(Dropout(0.2))\n",
        "model_ASII_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_2.add(Dropout(0.2))\n",
        "model_ASII_2.add(LSTM(units=50))\n",
        "model_ASII_2.add(Dropout(0.2))\n",
        "model_ASII_2.add(Dense(units=1))\n",
        "model_ASII_2.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ASII_2.fit(X_ASII_2_train,y_ASII_2_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BMRI\n",
        "BMRI_2 = yf.download(\"BMRI.JK\", start=\"2022-01-10\", end=\"2022-07-10\")\n",
        "BMRI_2.insert(4,\"Return\", BMRI_2['Close'].pct_change())\n",
        "BMRI_2 = BMRI_2.dropna()\n",
        "BMRI_2_test = yf.download(\"BMRI.JK\", start=\"2022-07-09\", end=\"2022-08-10\")\n",
        "BMRI_2_test.insert(4,\"Return\", BMRI_2_test['Close'].pct_change())\n",
        "BMRI_2_test = BMRI_2_test.dropna()\n",
        "training_BMRI_2 = BMRI_2.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BMRI_2_scaled = sc.fit_transform(training_BMRI_2)\n",
        "X_BMRI_2_train = []\n",
        "y_BMRI_2_train = []\n",
        "for i in range(days_period, len(BMRI_2)-1):\n",
        "    X_BMRI_2_train.append(training_BMRI_2_scaled[i-days_period:i, 0])\n",
        "    y_BMRI_2_train.append(training_BMRI_2_scaled[i, 0])\n",
        "X_BMRI_2_train, y_BMRI_2_train = np.array(X_BMRI_2_train), np.array(y_BMRI_2_train)\n",
        "X_BMRI_2_train = np.reshape(X_BMRI_2_train, (X_BMRI_2_train.shape[0], X_BMRI_2_train.shape[1], 1))\n",
        "model_BMRI_2 = Sequential()\n",
        "model_BMRI_2.add(LSTM(units=50,return_sequences=True,input_shape=(X_BMRI_2_train.shape[1], 1)))\n",
        "model_BMRI_2.add(Dropout(0.2))\n",
        "model_BMRI_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_2.add(Dropout(0.2))\n",
        "model_BMRI_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_2.add(Dropout(0.2))\n",
        "model_BMRI_2.add(LSTM(units=50))\n",
        "model_BMRI_2.add(Dropout(0.2))\n",
        "model_BMRI_2.add(Dense(units=1))\n",
        "model_BMRI_2.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BMRI_2.fit(X_BMRI_2_train,y_BMRI_2_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBRI\n",
        "BBRI_2 = yf.download(\"BBRI.JK\", start=\"2022-01-10\", end=\"2022-07-10\")\n",
        "BBRI_2.insert(4,\"Return\", BBRI_2['Close'].pct_change())\n",
        "BBRI_2 = BBRI_2.dropna()\n",
        "BBRI_2_test = yf.download(\"BBRI.JK\", start=\"2022-07-09\", end=\"2022-08-10\")\n",
        "BBRI_2_test.insert(4,\"Return\", BBRI_2_test['Close'].pct_change())\n",
        "BBRI_2_test = BBRI_2_test.dropna()\n",
        "training_BBRI_2 = BBRI_2.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBRI_2_scaled = sc.fit_transform(training_BBRI_2)\n",
        "X_BBRI_2_train = []\n",
        "y_BBRI_2_train = []\n",
        "for i in range(days_period, len(BBRI_2)-1):\n",
        "    X_BBRI_2_train.append(training_BBRI_2_scaled[i-days_period:i, 0])\n",
        "    y_BBRI_2_train.append(training_BBRI_2_scaled[i, 0])\n",
        "X_BBRI_2_train, y_BBRI_2_train = np.array(X_BBRI_2_train), np.array(y_BBRI_2_train)\n",
        "X_BBRI_2_train = np.reshape(X_BBRI_2_train, (X_BBRI_2_train.shape[0], X_BBRI_2_train.shape[1], 1))\n",
        "model_BBRI_2 = Sequential()\n",
        "model_BBRI_2.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBRI_2_train.shape[1], 1)))\n",
        "model_BBRI_2.add(Dropout(0.2))\n",
        "model_BBRI_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_2.add(Dropout(0.2))\n",
        "model_BBRI_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_2.add(Dropout(0.2))\n",
        "model_BBRI_2.add(LSTM(units=50))\n",
        "model_BBRI_2.add(Dropout(0.2))\n",
        "model_BBRI_2.add(Dense(units=1))\n",
        "model_BBRI_2.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBRI_2.fit(X_BBRI_2_train,y_BBRI_2_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBTN\n",
        "BBTN_2 = yf.download(\"BBTN.JK\", start=\"2022-01-10\", end=\"2022-07-10\")\n",
        "BBTN_2.insert(4,\"Return\", BBTN_2['Close'].pct_change())\n",
        "BBTN_2 = BBTN_2.dropna()\n",
        "BBTN_2_test = yf.download(\"BBTN.JK\", start=\"2022-07-09\", end=\"2022-08-10\")\n",
        "BBTN_2_test.insert(4,\"Return\", BBTN_2_test['Close'].pct_change())\n",
        "BBTN_2_test = BBTN_2_test.dropna()\n",
        "training_BBTN_2 = BBTN_2.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBTN_2_scaled = sc.fit_transform(training_BBTN_2)\n",
        "X_BBTN_2_train = []\n",
        "y_BBTN_2_train = []\n",
        "for i in range(days_period, len(BBTN_2)-1):\n",
        "    X_BBTN_2_train.append(training_BBTN_2_scaled[i-days_period:i, 0])\n",
        "    y_BBTN_2_train.append(training_BBTN_2_scaled[i, 0])\n",
        "X_BBTN_2_train, y_BBTN_2_train = np.array(X_BBTN_2_train), np.array(y_BBTN_2_train)\n",
        "X_BBTN_2_train = np.reshape(X_BBTN_2_train, (X_BBTN_2_train.shape[0], X_BBTN_2_train.shape[1], 1))\n",
        "model_BBTN_2 = Sequential()\n",
        "model_BBTN_2.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBTN_2_train.shape[1], 1)))\n",
        "model_BBTN_2.add(Dropout(0.2))\n",
        "model_BBTN_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_2.add(Dropout(0.2))\n",
        "model_BBTN_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_2.add(Dropout(0.2))\n",
        "model_BBTN_2.add(LSTM(units=50))\n",
        "model_BBTN_2.add(Dropout(0.2))\n",
        "model_BBTN_2.add(Dense(units=1))\n",
        "model_BBTN_2.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBTN_2.fit(X_BBTN_2_train,y_BBTN_2_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BUMI\n",
        "BUMI_2 = yf.download(\"BUMI.JK\", start=\"2022-01-10\", end=\"2022-07-10\")\n",
        "BUMI_2.insert(4,\"Return\", BUMI_2['Close'].pct_change())\n",
        "BUMI_2 = BUMI_2.dropna()\n",
        "BUMI_2_test = yf.download(\"BUMI.JK\", start=\"2022-07-09\", end=\"2022-08-10\")\n",
        "BUMI_2_test.insert(4,\"Return\", BUMI_2_test['Close'].pct_change())\n",
        "BUMI_2_test = BUMI_2_test.dropna()\n",
        "training_BUMI_2 = BUMI_2.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BUMI_2_scaled = sc.fit_transform(training_BUMI_2)\n",
        "X_BUMI_2_train = []\n",
        "y_BUMI_2_train = []\n",
        "for i in range(days_period, len(BUMI_2)-1):\n",
        "    X_BUMI_2_train.append(training_BUMI_2_scaled[i-days_period:i, 0])\n",
        "    y_BUMI_2_train.append(training_BUMI_2_scaled[i, 0])\n",
        "X_BUMI_2_train, y_BUMI_2_train = np.array(X_BUMI_2_train), np.array(y_BUMI_2_train)\n",
        "X_BUMI_2_train = np.reshape(X_BUMI_2_train, (X_BUMI_2_train.shape[0], X_BUMI_2_train.shape[1], 1))\n",
        "model_BUMI_2 = Sequential()\n",
        "model_BUMI_2.add(LSTM(units=50,return_sequences=True,input_shape=(X_BUMI_2_train.shape[1], 1)))\n",
        "model_BUMI_2.add(Dropout(0.2))\n",
        "model_BUMI_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_2.add(Dropout(0.2))\n",
        "model_BUMI_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_2.add(Dropout(0.2))\n",
        "model_BUMI_2.add(LSTM(units=50))\n",
        "model_BUMI_2.add(Dropout(0.2))\n",
        "model_BUMI_2.add(Dense(units=1))\n",
        "model_BUMI_2.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BUMI_2.fit(X_BUMI_2_train,y_BUMI_2_train,epochs=10,batch_size=16)\n",
        "\n",
        "# MFIN\n",
        "MFIN_2 = yf.download(\"MFIN.JK\", start=\"2022-01-10\", end=\"2022-07-10\")\n",
        "MFIN_2.insert(4,\"Return\", MFIN_2['Close'].pct_change())\n",
        "MFIN_2 = MFIN_2.dropna()\n",
        "MFIN_2_test = yf.download(\"MFIN.JK\", start=\"2022-07-09\", end=\"2022-08-10\")\n",
        "MFIN_2_test.insert(4,\"Return\", MFIN_2_test['Close'].pct_change())\n",
        "MFIN_2_test = MFIN_2_test.dropna()\n",
        "training_MFIN_2 = MFIN_2.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_MFIN_2_scaled = sc.fit_transform(training_MFIN_2)\n",
        "X_MFIN_2_train = []\n",
        "y_MFIN_2_train = []\n",
        "for i in range(days_period, len(MFIN_2)-1):\n",
        "    X_MFIN_2_train.append(training_MFIN_2_scaled[i-days_period:i, 0])\n",
        "    y_MFIN_2_train.append(training_MFIN_2_scaled[i, 0])\n",
        "X_MFIN_2_train, y_MFIN_2_train = np.array(X_MFIN_2_train), np.array(y_MFIN_2_train)\n",
        "X_MFIN_2_train = np.reshape(X_MFIN_2_train, (X_MFIN_2_train.shape[0], X_MFIN_2_train.shape[1], 1))\n",
        "model_MFIN_2 = Sequential()\n",
        "model_MFIN_2.add(LSTM(units=50,return_sequences=True,input_shape=(X_MFIN_2_train.shape[1], 1)))\n",
        "model_MFIN_2.add(Dropout(0.2))\n",
        "model_MFIN_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_2.add(Dropout(0.2))\n",
        "model_MFIN_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_2.add(Dropout(0.2))\n",
        "model_MFIN_2.add(LSTM(units=50))\n",
        "model_MFIN_2.add(Dropout(0.2))\n",
        "model_MFIN_2.add(Dense(units=1))\n",
        "model_MFIN_2.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_MFIN_2.fit(X_MFIN_2_train,y_MFIN_2_train,epochs=10,batch_size=16)\n",
        "\n",
        "# EXCL\n",
        "EXCL_2 = yf.download(\"EXCL.JK\", start=\"2022-01-10\", end=\"2022-07-10\")\n",
        "EXCL_2.insert(4,\"Return\", EXCL_2['Close'].pct_change())\n",
        "EXCL_2 = EXCL_2.dropna()\n",
        "EXCL_2_test = yf.download(\"EXCL.JK\", start=\"2022-07-09\", end=\"2022-08-10\")\n",
        "EXCL_2_test.insert(4,\"Return\", EXCL_2_test['Close'].pct_change())\n",
        "EXCL_2_test = EXCL_2_test.dropna()\n",
        "training_EXCL_2 = EXCL_2.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_EXCL_2_scaled = sc.fit_transform(training_EXCL_2)\n",
        "X_EXCL_2_train = []\n",
        "y_EXCL_2_train = []\n",
        "for i in range(days_period, len(EXCL_2)-1):\n",
        "    X_EXCL_2_train.append(training_EXCL_2_scaled[i-days_period:i, 0])\n",
        "    y_EXCL_2_train.append(training_EXCL_2_scaled[i, 0])\n",
        "X_EXCL_2_train, y_EXCL_2_train = np.array(X_EXCL_2_train), np.array(y_EXCL_2_train)\n",
        "X_EXCL_2_train = np.reshape(X_EXCL_2_train, (X_EXCL_2_train.shape[0], X_EXCL_2_train.shape[1], 1))\n",
        "model_EXCL_2 = Sequential()\n",
        "model_EXCL_2.add(LSTM(units=50,return_sequences=True,input_shape=(X_EXCL_2_train.shape[1], 1)))\n",
        "model_EXCL_2.add(Dropout(0.2))\n",
        "model_EXCL_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_2.add(Dropout(0.2))\n",
        "model_EXCL_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_2.add(Dropout(0.2))\n",
        "model_EXCL_2.add(LSTM(units=50))\n",
        "model_EXCL_2.add(Dropout(0.2))\n",
        "model_EXCL_2.add(Dense(units=1))\n",
        "model_EXCL_2.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_EXCL_2.fit(X_EXCL_2_train,y_EXCL_2_train,epochs=10,batch_size=16)\n",
        "\n",
        "# PGAS\n",
        "PGAS_2 = yf.download(\"PGAS.JK\", start=\"2022-01-10\", end=\"2022-07-10\")\n",
        "PGAS_2.insert(4,\"Return\", PGAS_2['Close'].pct_change())\n",
        "PGAS_2 = PGAS_2.dropna()\n",
        "PGAS_2_test = yf.download(\"PGAS.JK\", start=\"2022-07-09\", end=\"2022-08-10\")\n",
        "PGAS_2_test.insert(4,\"Return\", PGAS_2_test['Close'].pct_change())\n",
        "PGAS_2_test = PGAS_2_test.dropna()\n",
        "training_PGAS_2 = PGAS_2.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_PGAS_2_scaled = sc.fit_transform(training_PGAS_2)\n",
        "X_PGAS_2_train = []\n",
        "y_PGAS_2_train = []\n",
        "for i in range(days_period, len(PGAS_2)-1):\n",
        "    X_PGAS_2_train.append(training_PGAS_2_scaled[i-days_period:i, 0])\n",
        "    y_PGAS_2_train.append(training_PGAS_2_scaled[i, 0])\n",
        "X_PGAS_2_train, y_PGAS_2_train = np.array(X_PGAS_2_train), np.array(y_PGAS_2_train)\n",
        "X_PGAS_2_train = np.reshape(X_PGAS_2_train, (X_PGAS_2_train.shape[0], X_PGAS_2_train.shape[1], 1))\n",
        "model_PGAS_2 = Sequential()\n",
        "model_PGAS_2.add(LSTM(units=50,return_sequences=True,input_shape=(X_PGAS_2_train.shape[1], 1)))\n",
        "model_PGAS_2.add(Dropout(0.2))\n",
        "model_PGAS_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_2.add(Dropout(0.2))\n",
        "model_PGAS_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_2.add(Dropout(0.2))\n",
        "model_PGAS_2.add(LSTM(units=50))\n",
        "model_PGAS_2.add(Dropout(0.2))\n",
        "model_PGAS_2.add(Dense(units=1))\n",
        "model_PGAS_2.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_PGAS_2.fit(X_PGAS_2_train,y_PGAS_2_train,epochs=10,batch_size=16)\n",
        "\n",
        "# TLKM\n",
        "TLKM_2 = yf.download(\"TLKM.JK\", start=\"2022-01-10\", end=\"2022-07-10\")\n",
        "TLKM_2.insert(4,\"Return\", TLKM_2['Close'].pct_change())\n",
        "TLKM_2 = TLKM_2.dropna()\n",
        "TLKM_2_test = yf.download(\"TLKM.JK\", start=\"2022-07-09\", end=\"2022-08-10\")\n",
        "TLKM_2_test.insert(4,\"Return\", TLKM_2_test['Close'].pct_change())\n",
        "TLKM_2_test = TLKM_2_test.dropna()\n",
        "training_TLKM_2 = TLKM_2.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_TLKM_2_scaled = sc.fit_transform(training_TLKM_2)\n",
        "X_TLKM_2_train = []\n",
        "y_TLKM_2_train = []\n",
        "for i in range(days_period, len(TLKM_2)-1):\n",
        "    X_TLKM_2_train.append(training_TLKM_2_scaled[i-days_period:i, 0])\n",
        "    y_TLKM_2_train.append(training_TLKM_2_scaled[i, 0])\n",
        "X_TLKM_2_train, y_TLKM_2_train = np.array(X_TLKM_2_train), np.array(y_TLKM_2_train)\n",
        "X_TLKM_2_train = np.reshape(X_TLKM_2_train, (X_TLKM_2_train.shape[0], X_TLKM_2_train.shape[1], 1))\n",
        "model_TLKM_2 = Sequential()\n",
        "model_TLKM_2.add(LSTM(units=50,return_sequences=True,input_shape=(X_TLKM_2_train.shape[1], 1)))\n",
        "model_TLKM_2.add(Dropout(0.2))\n",
        "model_TLKM_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_2.add(Dropout(0.2))\n",
        "model_TLKM_2.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_2.add(Dropout(0.2))\n",
        "model_TLKM_2.add(LSTM(units=50))\n",
        "model_TLKM_2.add(Dropout(0.2))\n",
        "model_TLKM_2.add(Dense(units=1))\n",
        "model_TLKM_2.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_TLKM_2.fit(X_TLKM_2_train,y_TLKM_2_train,epochs=10,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3ovpqyCGwqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c9cf53-e52d-4118-fa47-97395343194d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        }
      ],
      "source": [
        "# ADRO\n",
        "real_ADRO_2_return = ADRO_2_test.iloc[:, 4:5].values\n",
        "real_ADRO_2_return = real_ADRO_2_return[:days_predict]\n",
        "ADRO_2_total = ADRO_2['Close'].copy(deep=True)\n",
        "inputs_ADRO_2 = ADRO_2_total[len(ADRO_2) - days_period: len(ADRO_2)].values\n",
        "inputs_ADRO_2 = inputs_ADRO_2.reshape(-1,1)\n",
        "inputs_ADRO_2 = sc.transform(inputs_ADRO_2)\n",
        "predicted_ADRO_2_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ADRO_2_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ADRO_2_test.append(inputs_ADRO_2[i:i+days_period, 0])\n",
        "  X_ADRO_2_test = np.array(X_ADRO_2_test)\n",
        "  X_ADRO_2_test = np.reshape(X_ADRO_2_test, (X_ADRO_2_test.shape[0], X_ADRO_2_test.shape[1], 1))\n",
        "  predicted_ADRO_2_return[j] = model_ADRO_2.predict(X_ADRO_2_test)\n",
        "  inputs_ADRO_2 += (predicted_ADRO_2_return[j])\n",
        "  inputs_ADRO_2 = inputs_ADRO_2.reshape(-1,1)\n",
        "\n",
        "# ASII\n",
        "real_ASII_2_return = ASII_2_test.iloc[:, 4:5].values\n",
        "real_ASII_2_return = real_ASII_2_return[:days_predict]\n",
        "ASII_2_total = ASII_2['Close'].copy(deep=True)\n",
        "inputs_ASII_2 = ASII_2_total[len(ASII_2) - days_period: len(ASII_2)].values\n",
        "inputs_ASII_2 = inputs_ASII_2.reshape(-1,1)\n",
        "inputs_ASII_2 = sc.transform(inputs_ASII_2)\n",
        "predicted_ASII_2_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ASII_2_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ASII_2_test.append(inputs_ASII_2[i:i+days_period, 0])\n",
        "  X_ASII_2_test = np.array(X_ASII_2_test)\n",
        "  X_ASII_2_test = np.reshape(X_ASII_2_test, (X_ASII_2_test.shape[0], X_ASII_2_test.shape[1], 1))\n",
        "  predicted_ASII_2_return[j] = model_ASII_2.predict(X_ASII_2_test)\n",
        "  inputs_ASII_2 += (predicted_ASII_2_return[j])\n",
        "  inputs_ASII_2 = inputs_ASII_2.reshape(-1,1)\n",
        "\n",
        "# BMRI\n",
        "real_BMRI_2_return = BMRI_2_test.iloc[:, 4:5].values\n",
        "real_BMRI_2_return = real_BMRI_2_return[:days_predict]\n",
        "BMRI_2_total = BMRI_2['Close'].copy(deep=True)\n",
        "inputs_BMRI_2 = BMRI_2_total[len(BMRI_2) - days_period: len(BMRI_2)].values\n",
        "inputs_BMRI_2 = inputs_BMRI_2.reshape(-1,1)\n",
        "inputs_BMRI_2 = sc.transform(inputs_BMRI_2)\n",
        "predicted_BMRI_2_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BMRI_2_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BMRI_2_test.append(inputs_BMRI_2[i:i+days_period, 0])\n",
        "  X_BMRI_2_test = np.array(X_BMRI_2_test)\n",
        "  X_BMRI_2_test = np.reshape(X_BMRI_2_test, (X_BMRI_2_test.shape[0], X_BMRI_2_test.shape[1], 1))\n",
        "  predicted_BMRI_2_return[j] = model_BMRI_2.predict(X_BMRI_2_test)\n",
        "  inputs_BMRI_2 += (predicted_BMRI_2_return[j])\n",
        "  inputs_BMRI_2 = inputs_BMRI_2.reshape(-1,1)\n",
        "\n",
        "# BBRI\n",
        "real_BBRI_2_return = BBRI_2_test.iloc[:, 4:5].values\n",
        "real_BBRI_2_return = real_BBRI_2_return[:days_predict]\n",
        "BBRI_2_total = BBRI_2['Close'].copy(deep=True)\n",
        "inputs_BBRI_2 = BBRI_2_total[len(BBRI_2) - days_period: len(BBRI_2)].values\n",
        "inputs_BBRI_2 = inputs_BBRI_2.reshape(-1,1)\n",
        "inputs_BBRI_2 = sc.transform(inputs_BBRI_2)\n",
        "predicted_BBRI_2_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBRI_2_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBRI_2_test.append(inputs_BBRI_2[i:i+days_period, 0])\n",
        "  X_BBRI_2_test = np.array(X_BBRI_2_test)\n",
        "  X_BBRI_2_test = np.reshape(X_BBRI_2_test, (X_BBRI_2_test.shape[0], X_BBRI_2_test.shape[1], 1))\n",
        "  predicted_BBRI_2_return[j] = model_BBRI_2.predict(X_BBRI_2_test)\n",
        "  inputs_BBRI_2 += (predicted_BBRI_2_return[j])\n",
        "  inputs_BBRI_2 = inputs_BBRI_2.reshape(-1,1)\n",
        "\n",
        "# BBTN\n",
        "real_BBTN_2_return = BBTN_2_test.iloc[:, 4:5].values\n",
        "real_BBTN_2_return = real_BBTN_2_return[:days_predict]\n",
        "BBTN_2_total = BBTN_2['Close'].copy(deep=True)\n",
        "inputs_BBTN_2 = BBTN_2_total[len(BBTN_2) - days_period: len(BBTN_2)].values\n",
        "inputs_BBTN_2 = inputs_BBTN_2.reshape(-1,1)\n",
        "inputs_BBTN_2 = sc.transform(inputs_BBTN_2)\n",
        "predicted_BBTN_2_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBTN_2_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBTN_2_test.append(inputs_BBTN_2[i:i+days_period, 0])\n",
        "  X_BBTN_2_test = np.array(X_BBTN_2_test)\n",
        "  X_BBTN_2_test = np.reshape(X_BBTN_2_test, (X_BBTN_2_test.shape[0], X_BBTN_2_test.shape[1], 1))\n",
        "  predicted_BBTN_2_return[j] = model_BBTN_2.predict(X_BBTN_2_test)\n",
        "  inputs_BBTN_2 += (predicted_BBTN_2_return[j])\n",
        "  inputs_BBTN_2 = inputs_BBTN_2.reshape(-1,1)\n",
        "\n",
        "# BUMI\n",
        "real_BUMI_2_return = BUMI_2_test.iloc[:, 4:5].values\n",
        "real_BUMI_2_return = real_BUMI_2_return[:days_predict]\n",
        "BUMI_2_total = BUMI_2['Close'].copy(deep=True)\n",
        "inputs_BUMI_2 = BUMI_2_total[len(BUMI_2) - days_period: len(BUMI_2)].values\n",
        "inputs_BUMI_2 = inputs_BUMI_2.reshape(-1,1)\n",
        "inputs_BUMI_2 = sc.transform(inputs_BUMI_2)\n",
        "predicted_BUMI_2_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BUMI_2_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BUMI_2_test.append(inputs_BUMI_2[i:i+days_period, 0])\n",
        "  X_BUMI_2_test = np.array(X_BUMI_2_test)\n",
        "  X_BUMI_2_test = np.reshape(X_BUMI_2_test, (X_BUMI_2_test.shape[0], X_BUMI_2_test.shape[1], 1))\n",
        "  predicted_BUMI_2_return[j] = model_BUMI_2.predict(X_BUMI_2_test)\n",
        "  inputs_BUMI_2 += (predicted_BUMI_2_return[j])\n",
        "  inputs_BUMI_2 = inputs_BUMI_2.reshape(-1,1)\n",
        "\n",
        "# MFIN\n",
        "real_MFIN_2_return = MFIN_2_test.iloc[:, 4:5].values\n",
        "real_MFIN_2_return = real_MFIN_2_return[:days_predict]\n",
        "MFIN_2_total = MFIN_2['Close'].copy(deep=True)\n",
        "inputs_MFIN_2 = MFIN_2_total[len(MFIN_2) - days_period: len(MFIN_2)].values\n",
        "inputs_MFIN_2 = inputs_MFIN_2.reshape(-1,1)\n",
        "inputs_MFIN_2 = sc.transform(inputs_MFIN_2)\n",
        "predicted_MFIN_2_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_MFIN_2_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_MFIN_2_test.append(inputs_MFIN_2[i:i+days_period, 0])\n",
        "  X_MFIN_2_test = np.array(X_MFIN_2_test)\n",
        "  X_MFIN_2_test = np.reshape(X_MFIN_2_test, (X_MFIN_2_test.shape[0], X_MFIN_2_test.shape[1], 1))\n",
        "  predicted_MFIN_2_return[j] = model_MFIN_2.predict(X_MFIN_2_test)\n",
        "  inputs_MFIN_2 += (predicted_MFIN_2_return[j])\n",
        "  inputs_MFIN_2 = inputs_MFIN_2.reshape(-1,1)\n",
        "\n",
        "# EXCL\n",
        "real_EXCL_2_return = EXCL_2_test.iloc[:, 4:5].values\n",
        "real_EXCL_2_return = real_EXCL_2_return[:days_predict]\n",
        "EXCL_2_total = EXCL_2['Close'].copy(deep=True)\n",
        "inputs_EXCL_2 = EXCL_2_total[len(EXCL_2) - days_period: len(EXCL_2)].values\n",
        "inputs_EXCL_2 = inputs_EXCL_2.reshape(-1,1)\n",
        "inputs_EXCL_2 = sc.transform(inputs_EXCL_2)\n",
        "predicted_EXCL_2_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_EXCL_2_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_EXCL_2_test.append(inputs_EXCL_2[i:i+days_period, 0])\n",
        "  X_EXCL_2_test = np.array(X_EXCL_2_test)\n",
        "  X_EXCL_2_test = np.reshape(X_EXCL_2_test, (X_EXCL_2_test.shape[0], X_EXCL_2_test.shape[1], 1))\n",
        "  predicted_EXCL_2_return[j] = model_EXCL_2.predict(X_EXCL_2_test)\n",
        "  inputs_EXCL_2 += (predicted_EXCL_2_return[j])\n",
        "  inputs_EXCL_2 = inputs_EXCL_2.reshape(-1,1)\n",
        "\n",
        "# PGAS\n",
        "real_PGAS_2_return = PGAS_2_test.iloc[:, 4:5].values\n",
        "real_PGAS_2_return = real_PGAS_2_return[:days_predict]\n",
        "PGAS_2_total = PGAS_2['Close'].copy(deep=True)\n",
        "inputs_PGAS_2 = PGAS_2_total[len(PGAS_2) - days_period: len(PGAS_2)].values\n",
        "inputs_PGAS_2 = inputs_PGAS_2.reshape(-1,1)\n",
        "inputs_PGAS_2 = sc.transform(inputs_PGAS_2)\n",
        "predicted_PGAS_2_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_PGAS_2_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_PGAS_2_test.append(inputs_PGAS_2[i:i+days_period, 0])\n",
        "  X_PGAS_2_test = np.array(X_PGAS_2_test)\n",
        "  X_PGAS_2_test = np.reshape(X_PGAS_2_test, (X_PGAS_2_test.shape[0], X_PGAS_2_test.shape[1], 1))\n",
        "  predicted_PGAS_2_return[j] = model_PGAS_2.predict(X_PGAS_2_test)\n",
        "  inputs_PGAS_2 += (predicted_PGAS_2_return[j])\n",
        "  inputs_PGAS_2 = inputs_PGAS_2.reshape(-1,1)\n",
        "\n",
        "# TLKM\n",
        "real_TLKM_2_return = TLKM_2_test.iloc[:, 4:5].values\n",
        "real_TLKM_2_return = real_TLKM_2_return[:days_predict]\n",
        "TLKM_2_total = TLKM_2['Close'].copy(deep=True)\n",
        "inputs_TLKM_2 = TLKM_2_total[len(TLKM_2) - days_period: len(TLKM_2)].values\n",
        "inputs_TLKM_2 = inputs_TLKM_2.reshape(-1,1)\n",
        "inputs_TLKM_2 = sc.transform(inputs_TLKM_2)\n",
        "predicted_TLKM_2_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_TLKM_2_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_TLKM_2_test.append(inputs_TLKM_2[i:i+days_period, 0])\n",
        "  X_TLKM_2_test = np.array(X_TLKM_2_test)\n",
        "  X_TLKM_2_test = np.reshape(X_TLKM_2_test, (X_TLKM_2_test.shape[0], X_TLKM_2_test.shape[1], 1))\n",
        "  predicted_TLKM_2_return[j] = model_TLKM_2.predict(X_TLKM_2_test)\n",
        "  inputs_TLKM_2 += (predicted_TLKM_2_return[j])\n",
        "  inputs_TLKM_2 = inputs_TLKM_2.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHmqs89gGwqo"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "predicted_ADRO_2_return = np.squeeze(np.asarray(predicted_ADRO_2_return))\n",
        "predicted_ADRO_2_return = predicted_ADRO_2_return.reshape(-1,1)\n",
        "predicted_ADRO_2_return = sc.inverse_transform(predicted_ADRO_2_return)\n",
        "# ASII\n",
        "predicted_ASII_2_return = np.squeeze(np.asarray(predicted_ASII_2_return))\n",
        "predicted_ASII_2_return = predicted_ASII_2_return.reshape(-1,1)\n",
        "predicted_ASII_2_return = sc.inverse_transform(predicted_ASII_2_return)\n",
        "# BMRI\n",
        "predicted_BMRI_2_return = np.squeeze(np.asarray(predicted_BMRI_2_return))\n",
        "predicted_BMRI_2_return = predicted_BMRI_2_return.reshape(-1,1)\n",
        "predicted_BMRI_2_return = sc.inverse_transform(predicted_BMRI_2_return)\n",
        "# BBRI\n",
        "predicted_BBRI_2_return = np.squeeze(np.asarray(predicted_BBRI_2_return))\n",
        "predicted_BBRI_2_return = predicted_BBRI_2_return.reshape(-1,1)\n",
        "predicted_BBRI_2_return = sc.inverse_transform(predicted_BBRI_2_return)\n",
        "# BBTN\n",
        "predicted_BBTN_2_return = np.squeeze(np.asarray(predicted_BBTN_2_return))\n",
        "predicted_BBTN_2_return = predicted_BBTN_2_return.reshape(-1,1)\n",
        "predicted_BBTN_2_return = sc.inverse_transform(predicted_BBTN_2_return)\n",
        "# BUMI\n",
        "predicted_BUMI_2_return = np.squeeze(np.asarray(predicted_BUMI_2_return))\n",
        "predicted_BUMI_2_return = predicted_BUMI_2_return.reshape(-1,1)\n",
        "predicted_BUMI_2_return = sc.inverse_transform(predicted_BUMI_2_return)\n",
        "# MFIN\n",
        "predicted_MFIN_2_return = np.squeeze(np.asarray(predicted_MFIN_2_return))\n",
        "predicted_MFIN_2_return = predicted_MFIN_2_return.reshape(-1,1)\n",
        "predicted_MFIN_2_return = sc.inverse_transform(predicted_MFIN_2_return)\n",
        "# EXCL\n",
        "predicted_EXCL_2_return = np.squeeze(np.asarray(predicted_EXCL_2_return))\n",
        "predicted_EXCL_2_return = predicted_EXCL_2_return.reshape(-1,1)\n",
        "predicted_EXCL_2_return = sc.inverse_transform(predicted_EXCL_2_return)\n",
        "# PGAS\n",
        "predicted_PGAS_2_return = np.squeeze(np.asarray(predicted_PGAS_2_return))\n",
        "predicted_PGAS_2_return = predicted_PGAS_2_return.reshape(-1,1)\n",
        "predicted_PGAS_2_return = sc.inverse_transform(predicted_PGAS_2_return)\n",
        "# TLKM\n",
        "predicted_TLKM_2_return = np.squeeze(np.asarray(predicted_TLKM_2_return))\n",
        "predicted_TLKM_2_return = predicted_TLKM_2_return.reshape(-1,1)\n",
        "predicted_TLKM_2_return = sc.inverse_transform(predicted_TLKM_2_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QRN8eCWGwqp"
      },
      "outputs": [],
      "source": [
        "predicted2 = pd.DataFrame(predicted_ADRO_2_return)\n",
        "predicted2.rename(columns={0:'ADRO'}, inplace=True)\n",
        "predicted2.insert(1,\"ASII\", predicted_ASII_2_return)\n",
        "predicted2.insert(2,\"BBRI\", predicted_BBRI_2_return)\n",
        "predicted2.insert(3,\"BBTN\", predicted_BBTN_2_return)\n",
        "predicted2.insert(4,\"BMRI\", predicted_BMRI_2_return)\n",
        "predicted2.insert(5,\"BUMI\", predicted_BUMI_2_return)\n",
        "predicted2.insert(6,\"EXCL\", predicted_EXCL_2_return)\n",
        "predicted2.insert(7,\"MFIN\", predicted_MFIN_2_return)\n",
        "predicted2.insert(8,\"PGAS\", predicted_PGAS_2_return)\n",
        "predicted2.insert(9,\"TLKM\", predicted_TLKM_2_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir5CDQOuPfOx",
        "outputId": "62ae6875-6303-43e2-b7ef-8a59ea68ef07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADRO      ASII      BBRI      BBTN      BMRI      BUMI      EXCL  \\\n",
              "0  0.001384  0.041502  0.025122  0.006968  0.029373  0.002459  0.009882   \n",
              "1  0.000760  0.040494  0.024004  0.006276  0.028203  0.001734  0.008866   \n",
              "2 -0.000012  0.039246  0.022652  0.005419  0.026790  0.000842  0.007655   \n",
              "3 -0.000960  0.037707  0.021019  0.004363  0.025088 -0.000250  0.006216   \n",
              "4 -0.002119  0.035818  0.019056  0.003066  0.023049 -0.001573  0.004513   \n",
              "5 -0.003526  0.033510  0.016706  0.001484  0.020615 -0.003168  0.002506   \n",
              "6 -0.005225  0.030705  0.013909 -0.000438  0.017728 -0.005085  0.000151   \n",
              "7 -0.007262  0.027318  0.010601 -0.002754  0.014326 -0.007368 -0.002594   \n",
              "8 -0.009684  0.023259  0.006721 -0.005526  0.010346 -0.010060 -0.005772   \n",
              "9 -0.012542  0.018435  0.002218 -0.008811  0.005734 -0.013193 -0.009420   \n",
              "\n",
              "       MFIN      PGAS      TLKM  \n",
              "0 -0.019207 -0.010258  0.004508  \n",
              "1 -0.019662 -0.010886  0.003931  \n",
              "2 -0.020227 -0.011643  0.003176  \n",
              "3 -0.020922 -0.012552  0.002204  \n",
              "4 -0.021768 -0.013635  0.000972  \n",
              "5 -0.022789 -0.014919 -0.000568  \n",
              "6 -0.024011 -0.016429 -0.002469  \n",
              "7 -0.025458 -0.018195 -0.004785  \n",
              "8 -0.027155 -0.020245 -0.007567  \n",
              "9 -0.029123 -0.022604 -0.010863  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70ce58ff-ade2-4979-88dd-0d50dba5ffdc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADRO</th>\n",
              "      <th>ASII</th>\n",
              "      <th>BBRI</th>\n",
              "      <th>BBTN</th>\n",
              "      <th>BMRI</th>\n",
              "      <th>BUMI</th>\n",
              "      <th>EXCL</th>\n",
              "      <th>MFIN</th>\n",
              "      <th>PGAS</th>\n",
              "      <th>TLKM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001384</td>\n",
              "      <td>0.041502</td>\n",
              "      <td>0.025122</td>\n",
              "      <td>0.006968</td>\n",
              "      <td>0.029373</td>\n",
              "      <td>0.002459</td>\n",
              "      <td>0.009882</td>\n",
              "      <td>-0.019207</td>\n",
              "      <td>-0.010258</td>\n",
              "      <td>0.004508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000760</td>\n",
              "      <td>0.040494</td>\n",
              "      <td>0.024004</td>\n",
              "      <td>0.006276</td>\n",
              "      <td>0.028203</td>\n",
              "      <td>0.001734</td>\n",
              "      <td>0.008866</td>\n",
              "      <td>-0.019662</td>\n",
              "      <td>-0.010886</td>\n",
              "      <td>0.003931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.000012</td>\n",
              "      <td>0.039246</td>\n",
              "      <td>0.022652</td>\n",
              "      <td>0.005419</td>\n",
              "      <td>0.026790</td>\n",
              "      <td>0.000842</td>\n",
              "      <td>0.007655</td>\n",
              "      <td>-0.020227</td>\n",
              "      <td>-0.011643</td>\n",
              "      <td>0.003176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.000960</td>\n",
              "      <td>0.037707</td>\n",
              "      <td>0.021019</td>\n",
              "      <td>0.004363</td>\n",
              "      <td>0.025088</td>\n",
              "      <td>-0.000250</td>\n",
              "      <td>0.006216</td>\n",
              "      <td>-0.020922</td>\n",
              "      <td>-0.012552</td>\n",
              "      <td>0.002204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.002119</td>\n",
              "      <td>0.035818</td>\n",
              "      <td>0.019056</td>\n",
              "      <td>0.003066</td>\n",
              "      <td>0.023049</td>\n",
              "      <td>-0.001573</td>\n",
              "      <td>0.004513</td>\n",
              "      <td>-0.021768</td>\n",
              "      <td>-0.013635</td>\n",
              "      <td>0.000972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.003526</td>\n",
              "      <td>0.033510</td>\n",
              "      <td>0.016706</td>\n",
              "      <td>0.001484</td>\n",
              "      <td>0.020615</td>\n",
              "      <td>-0.003168</td>\n",
              "      <td>0.002506</td>\n",
              "      <td>-0.022789</td>\n",
              "      <td>-0.014919</td>\n",
              "      <td>-0.000568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.005225</td>\n",
              "      <td>0.030705</td>\n",
              "      <td>0.013909</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>0.017728</td>\n",
              "      <td>-0.005085</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>-0.024011</td>\n",
              "      <td>-0.016429</td>\n",
              "      <td>-0.002469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.007262</td>\n",
              "      <td>0.027318</td>\n",
              "      <td>0.010601</td>\n",
              "      <td>-0.002754</td>\n",
              "      <td>0.014326</td>\n",
              "      <td>-0.007368</td>\n",
              "      <td>-0.002594</td>\n",
              "      <td>-0.025458</td>\n",
              "      <td>-0.018195</td>\n",
              "      <td>-0.004785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.009684</td>\n",
              "      <td>0.023259</td>\n",
              "      <td>0.006721</td>\n",
              "      <td>-0.005526</td>\n",
              "      <td>0.010346</td>\n",
              "      <td>-0.010060</td>\n",
              "      <td>-0.005772</td>\n",
              "      <td>-0.027155</td>\n",
              "      <td>-0.020245</td>\n",
              "      <td>-0.007567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.012542</td>\n",
              "      <td>0.018435</td>\n",
              "      <td>0.002218</td>\n",
              "      <td>-0.008811</td>\n",
              "      <td>0.005734</td>\n",
              "      <td>-0.013193</td>\n",
              "      <td>-0.009420</td>\n",
              "      <td>-0.029123</td>\n",
              "      <td>-0.022604</td>\n",
              "      <td>-0.010863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70ce58ff-ade2-4979-88dd-0d50dba5ffdc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70ce58ff-ade2-4979-88dd-0d50dba5ffdc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70ce58ff-ade2-4979-88dd-0d50dba5ffdc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNLf1Q4Hcc2j"
      },
      "source": [
        "## Data Preparation 3\n",
        "1st of January 2018 - 9th of August 2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFBMRGWwGysl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5374bf1-fb13-4f33-a5a9-e4ac4889740d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 8s 41ms/step - loss: 0.0571\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0256\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0224\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0194\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0189\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0205\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0184\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0199\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0188\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0186\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 8s 39ms/step - loss: 0.1175\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0435\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0465\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0306\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0298\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0240\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0264\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0236\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.0228\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.0219\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 8s 43ms/step - loss: 0.1357\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0336\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0331\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0272\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 0.0260\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 68ms/step - loss: 0.0227\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.0216\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.0215\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 76ms/step - loss: 0.0229\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.0225\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 8s 45ms/step - loss: 0.1851\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0540\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0352\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0306\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0284\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0220\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 68ms/step - loss: 0.0240\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0280\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.0247\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0269\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 8s 43ms/step - loss: 0.1354\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0416\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0313\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0232\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 68ms/step - loss: 0.0259\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 71ms/step - loss: 0.0218\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 74ms/step - loss: 0.0258\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 77ms/step - loss: 0.0217\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0250\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.0243\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 8s 44ms/step - loss: 0.0394\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0261\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0244\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0214\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 73ms/step - loss: 0.0212\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.0197\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0208\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0194\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.0205\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 67ms/step - loss: 0.0207\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 8s 42ms/step - loss: 0.1033\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0247\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0232\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0219\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.0202\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.0197\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 71ms/step - loss: 0.0184\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 74ms/step - loss: 0.0194\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 68ms/step - loss: 0.0210\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 68ms/step - loss: 0.0199\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 12s 45ms/step - loss: 0.1411\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0547\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0523\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0449\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0413\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0422\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0399\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0416\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0450\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0412\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 40ms/step - loss: 0.1171\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0490\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0400\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0334\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0303\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0259\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0290\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0270\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0275\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0265\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 41ms/step - loss: 0.3327\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0790\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0437\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0392\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0248\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0266\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0279\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0272\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0263\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0242\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1d5409f1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Period parameters\n",
        "days_period = 20\n",
        "days_predict = 10\n",
        "\n",
        "# ADRO\n",
        "ADRO_3 = yf.download(\"ADRO.JK\", start=\"2022-02-10\", end=\"2022-08-10\")\n",
        "ADRO_3.insert(4,\"Return\", ADRO_3['Close'].pct_change())\n",
        "ADRO_3 = ADRO_3.dropna()\n",
        "ADRO_3_test = yf.download(\"ADRO.JK\", start=\"2022-08-09\", end=\"2022-09-10\")\n",
        "ADRO_3_test.insert(4,\"Return\", ADRO_3_test['Close'].pct_change())\n",
        "ADRO_3_test = ADRO_3_test.dropna()\n",
        "training_ADRO_3 = ADRO_3.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ADRO_3_scaled = sc.fit_transform(training_ADRO_3)\n",
        "X_ADRO_3_train = []\n",
        "y_ADRO_3_train = []\n",
        "for i in range(days_period, len(ADRO_3)-1):\n",
        "    X_ADRO_3_train.append(training_ADRO_3_scaled[i-days_period:i, 0])\n",
        "    y_ADRO_3_train.append(training_ADRO_3_scaled[i, 0])\n",
        "X_ADRO_3_train, y_ADRO_3_train = np.array(X_ADRO_3_train), np.array(y_ADRO_3_train)\n",
        "X_ADRO_3_train = np.reshape(X_ADRO_3_train, (X_ADRO_3_train.shape[0], X_ADRO_3_train.shape[1], 1))\n",
        "model_ADRO_3 = Sequential()\n",
        "model_ADRO_3.add(LSTM(units=50,return_sequences=True,input_shape=(X_ADRO_3_train.shape[1], 1)))\n",
        "model_ADRO_3.add(Dropout(0.2))\n",
        "model_ADRO_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_3.add(Dropout(0.2))\n",
        "model_ADRO_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_3.add(Dropout(0.2))\n",
        "model_ADRO_3.add(LSTM(units=50))\n",
        "model_ADRO_3.add(Dropout(0.2))\n",
        "model_ADRO_3.add(Dense(units=1))\n",
        "model_ADRO_3.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ADRO_3.fit(X_ADRO_3_train,y_ADRO_3_train,epochs=10,batch_size=16)\n",
        "\n",
        "# ASII\n",
        "ASII_3 = yf.download(\"ASII.JK\", start=\"2022-02-10\", end=\"2022-08-10\")\n",
        "ASII_3.insert(4,\"Return\", ASII_3['Close'].pct_change())\n",
        "ASII_3 = ASII_3.dropna()\n",
        "ASII_3_test = yf.download(\"ASII.JK\", start=\"2022-08-09\", end=\"2022-09-10\")\n",
        "ASII_3_test.insert(4,\"Return\", ASII_3_test['Close'].pct_change())\n",
        "ASII_3_test = ASII_3_test.dropna()\n",
        "training_ASII_3 = ASII_3.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ASII_3_scaled = sc.fit_transform(training_ASII_3)\n",
        "X_ASII_3_train = []\n",
        "y_ASII_3_train = []\n",
        "for i in range(days_period, len(ASII_3)-1):\n",
        "    X_ASII_3_train.append(training_ASII_3_scaled[i-days_period:i, 0])\n",
        "    y_ASII_3_train.append(training_ASII_3_scaled[i, 0])\n",
        "X_ASII_3_train, y_ASII_3_train = np.array(X_ASII_3_train), np.array(y_ASII_3_train)\n",
        "X_ASII_3_train = np.reshape(X_ASII_3_train, (X_ASII_3_train.shape[0], X_ASII_3_train.shape[1], 1))\n",
        "model_ASII_3 = Sequential()\n",
        "model_ASII_3.add(LSTM(units=50,return_sequences=True,input_shape=(X_ASII_3_train.shape[1], 1)))\n",
        "model_ASII_3.add(Dropout(0.2))\n",
        "model_ASII_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_3.add(Dropout(0.2))\n",
        "model_ASII_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_3.add(Dropout(0.2))\n",
        "model_ASII_3.add(LSTM(units=50))\n",
        "model_ASII_3.add(Dropout(0.2))\n",
        "model_ASII_3.add(Dense(units=1))\n",
        "model_ASII_3.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ASII_3.fit(X_ASII_3_train,y_ASII_3_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BMRI\n",
        "BMRI_3 = yf.download(\"BMRI.JK\", start=\"2022-02-10\", end=\"2022-08-10\")\n",
        "BMRI_3.insert(4,\"Return\", BMRI_3['Close'].pct_change())\n",
        "BMRI_3 = BMRI_3.dropna()\n",
        "BMRI_3_test = yf.download(\"BMRI.JK\", start=\"2022-08-09\", end=\"2022-09-10\")\n",
        "BMRI_3_test.insert(4,\"Return\", BMRI_3_test['Close'].pct_change())\n",
        "BMRI_3_test = BMRI_3_test.dropna()\n",
        "training_BMRI_3 = BMRI_3.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BMRI_3_scaled = sc.fit_transform(training_BMRI_3)\n",
        "X_BMRI_3_train = []\n",
        "y_BMRI_3_train = []\n",
        "for i in range(days_period, len(BMRI_3)-1):\n",
        "    X_BMRI_3_train.append(training_BMRI_3_scaled[i-days_period:i, 0])\n",
        "    y_BMRI_3_train.append(training_BMRI_3_scaled[i, 0])\n",
        "X_BMRI_3_train, y_BMRI_3_train = np.array(X_BMRI_3_train), np.array(y_BMRI_3_train)\n",
        "X_BMRI_3_train = np.reshape(X_BMRI_3_train, (X_BMRI_3_train.shape[0], X_BMRI_3_train.shape[1], 1))\n",
        "model_BMRI_3 = Sequential()\n",
        "model_BMRI_3.add(LSTM(units=50,return_sequences=True,input_shape=(X_BMRI_3_train.shape[1], 1)))\n",
        "model_BMRI_3.add(Dropout(0.2))\n",
        "model_BMRI_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_3.add(Dropout(0.2))\n",
        "model_BMRI_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_3.add(Dropout(0.2))\n",
        "model_BMRI_3.add(LSTM(units=50))\n",
        "model_BMRI_3.add(Dropout(0.2))\n",
        "model_BMRI_3.add(Dense(units=1))\n",
        "model_BMRI_3.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BMRI_3.fit(X_BMRI_3_train,y_BMRI_3_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBRI\n",
        "BBRI_3 = yf.download(\"BBRI.JK\", start=\"2022-02-10\", end=\"2022-08-10\")\n",
        "BBRI_3.insert(4,\"Return\", BBRI_3['Close'].pct_change())\n",
        "BBRI_3 = BBRI_3.dropna()\n",
        "BBRI_3_test = yf.download(\"BBRI.JK\", start=\"2022-08-09\", end=\"2022-09-10\")\n",
        "BBRI_3_test.insert(4,\"Return\", BBRI_3_test['Close'].pct_change())\n",
        "BBRI_3_test = BBRI_3_test.dropna()\n",
        "training_BBRI_3 = BBRI_3.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBRI_3_scaled = sc.fit_transform(training_BBRI_3)\n",
        "X_BBRI_3_train = []\n",
        "y_BBRI_3_train = []\n",
        "for i in range(days_period, len(BBRI_3)-1):\n",
        "    X_BBRI_3_train.append(training_BBRI_3_scaled[i-days_period:i, 0])\n",
        "    y_BBRI_3_train.append(training_BBRI_3_scaled[i, 0])\n",
        "X_BBRI_3_train, y_BBRI_3_train = np.array(X_BBRI_3_train), np.array(y_BBRI_3_train)\n",
        "X_BBRI_3_train = np.reshape(X_BBRI_3_train, (X_BBRI_3_train.shape[0], X_BBRI_3_train.shape[1], 1))\n",
        "model_BBRI_3 = Sequential()\n",
        "model_BBRI_3.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBRI_3_train.shape[1], 1)))\n",
        "model_BBRI_3.add(Dropout(0.2))\n",
        "model_BBRI_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_3.add(Dropout(0.2))\n",
        "model_BBRI_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_3.add(Dropout(0.2))\n",
        "model_BBRI_3.add(LSTM(units=50))\n",
        "model_BBRI_3.add(Dropout(0.2))\n",
        "model_BBRI_3.add(Dense(units=1))\n",
        "model_BBRI_3.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBRI_3.fit(X_BBRI_3_train,y_BBRI_3_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBTN\n",
        "BBTN_3 = yf.download(\"BBTN.JK\", start=\"2022-02-10\", end=\"2022-08-10\")\n",
        "BBTN_3.insert(4,\"Return\", BBTN_3['Close'].pct_change())\n",
        "BBTN_3 = BBTN_3.dropna()\n",
        "BBTN_3_test = yf.download(\"BBTN.JK\", start=\"2022-08-09\", end=\"2022-09-10\")\n",
        "BBTN_3_test.insert(4,\"Return\", BBTN_3_test['Close'].pct_change())\n",
        "BBTN_3_test = BBTN_3_test.dropna()\n",
        "training_BBTN_3 = BBTN_3.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBTN_3_scaled = sc.fit_transform(training_BBTN_3)\n",
        "X_BBTN_3_train = []\n",
        "y_BBTN_3_train = []\n",
        "for i in range(days_period, len(BBTN_3)-1):\n",
        "    X_BBTN_3_train.append(training_BBTN_3_scaled[i-days_period:i, 0])\n",
        "    y_BBTN_3_train.append(training_BBTN_3_scaled[i, 0])\n",
        "X_BBTN_3_train, y_BBTN_3_train = np.array(X_BBTN_3_train), np.array(y_BBTN_3_train)\n",
        "X_BBTN_3_train = np.reshape(X_BBTN_3_train, (X_BBTN_3_train.shape[0], X_BBTN_3_train.shape[1], 1))\n",
        "model_BBTN_3 = Sequential()\n",
        "model_BBTN_3.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBTN_3_train.shape[1], 1)))\n",
        "model_BBTN_3.add(Dropout(0.2))\n",
        "model_BBTN_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_3.add(Dropout(0.2))\n",
        "model_BBTN_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_3.add(Dropout(0.2))\n",
        "model_BBTN_3.add(LSTM(units=50))\n",
        "model_BBTN_3.add(Dropout(0.2))\n",
        "model_BBTN_3.add(Dense(units=1))\n",
        "model_BBTN_3.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBTN_3.fit(X_BBTN_3_train,y_BBTN_3_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BUMI\n",
        "BUMI_3 = yf.download(\"BUMI.JK\", start=\"2022-02-10\", end=\"2022-08-10\")\n",
        "BUMI_3.insert(4,\"Return\", BUMI_3['Close'].pct_change())\n",
        "BUMI_3 = BUMI_3.dropna()\n",
        "BUMI_3_test = yf.download(\"BUMI.JK\", start=\"2022-08-09\", end=\"2022-09-10\")\n",
        "BUMI_3_test.insert(4,\"Return\", BUMI_3_test['Close'].pct_change())\n",
        "BUMI_3_test = BUMI_3_test.dropna()\n",
        "training_BUMI_3 = BUMI_3.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BUMI_3_scaled = sc.fit_transform(training_BUMI_3)\n",
        "X_BUMI_3_train = []\n",
        "y_BUMI_3_train = []\n",
        "for i in range(days_period, len(BUMI_3)-1):\n",
        "    X_BUMI_3_train.append(training_BUMI_3_scaled[i-days_period:i, 0])\n",
        "    y_BUMI_3_train.append(training_BUMI_3_scaled[i, 0])\n",
        "X_BUMI_3_train, y_BUMI_3_train = np.array(X_BUMI_3_train), np.array(y_BUMI_3_train)\n",
        "X_BUMI_3_train = np.reshape(X_BUMI_3_train, (X_BUMI_3_train.shape[0], X_BUMI_3_train.shape[1], 1))\n",
        "model_BUMI_3 = Sequential()\n",
        "model_BUMI_3.add(LSTM(units=50,return_sequences=True,input_shape=(X_BUMI_3_train.shape[1], 1)))\n",
        "model_BUMI_3.add(Dropout(0.2))\n",
        "model_BUMI_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_3.add(Dropout(0.2))\n",
        "model_BUMI_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_3.add(Dropout(0.2))\n",
        "model_BUMI_3.add(LSTM(units=50))\n",
        "model_BUMI_3.add(Dropout(0.2))\n",
        "model_BUMI_3.add(Dense(units=1))\n",
        "model_BUMI_3.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BUMI_3.fit(X_BUMI_3_train,y_BUMI_3_train,epochs=10,batch_size=16)\n",
        "\n",
        "# MFIN\n",
        "MFIN_3 = yf.download(\"MFIN.JK\", start=\"2022-02-10\", end=\"2022-08-10\")\n",
        "MFIN_3.insert(4,\"Return\", MFIN_3['Close'].pct_change())\n",
        "MFIN_3 = MFIN_3.dropna()\n",
        "MFIN_3_test = yf.download(\"MFIN.JK\", start=\"2022-08-09\", end=\"2022-09-10\")\n",
        "MFIN_3_test.insert(4,\"Return\", MFIN_3_test['Close'].pct_change())\n",
        "MFIN_3_test = MFIN_3_test.dropna()\n",
        "training_MFIN_3 = MFIN_3.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_MFIN_3_scaled = sc.fit_transform(training_MFIN_3)\n",
        "X_MFIN_3_train = []\n",
        "y_MFIN_3_train = []\n",
        "for i in range(days_period, len(MFIN_3)-1):\n",
        "    X_MFIN_3_train.append(training_MFIN_3_scaled[i-days_period:i, 0])\n",
        "    y_MFIN_3_train.append(training_MFIN_3_scaled[i, 0])\n",
        "X_MFIN_3_train, y_MFIN_3_train = np.array(X_MFIN_3_train), np.array(y_MFIN_3_train)\n",
        "X_MFIN_3_train = np.reshape(X_MFIN_3_train, (X_MFIN_3_train.shape[0], X_MFIN_3_train.shape[1], 1))\n",
        "model_MFIN_3 = Sequential()\n",
        "model_MFIN_3.add(LSTM(units=50,return_sequences=True,input_shape=(X_MFIN_3_train.shape[1], 1)))\n",
        "model_MFIN_3.add(Dropout(0.2))\n",
        "model_MFIN_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_3.add(Dropout(0.2))\n",
        "model_MFIN_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_3.add(Dropout(0.2))\n",
        "model_MFIN_3.add(LSTM(units=50))\n",
        "model_MFIN_3.add(Dropout(0.2))\n",
        "model_MFIN_3.add(Dense(units=1))\n",
        "model_MFIN_3.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_MFIN_3.fit(X_MFIN_3_train,y_MFIN_3_train,epochs=10,batch_size=16)\n",
        "\n",
        "# EXCL\n",
        "EXCL_3 = yf.download(\"EXCL.JK\", start=\"2022-02-10\", end=\"2022-08-10\")\n",
        "EXCL_3.insert(4,\"Return\", EXCL_3['Close'].pct_change())\n",
        "EXCL_3 = EXCL_3.dropna()\n",
        "EXCL_3_test = yf.download(\"EXCL.JK\", start=\"2022-08-09\", end=\"2022-09-10\")\n",
        "EXCL_3_test.insert(4,\"Return\", EXCL_3_test['Close'].pct_change())\n",
        "EXCL_3_test = EXCL_3_test.dropna()\n",
        "training_EXCL_3 = EXCL_3.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_EXCL_3_scaled = sc.fit_transform(training_EXCL_3)\n",
        "X_EXCL_3_train = []\n",
        "y_EXCL_3_train = []\n",
        "for i in range(days_period, len(EXCL_3)-1):\n",
        "    X_EXCL_3_train.append(training_EXCL_3_scaled[i-days_period:i, 0])\n",
        "    y_EXCL_3_train.append(training_EXCL_3_scaled[i, 0])\n",
        "X_EXCL_3_train, y_EXCL_3_train = np.array(X_EXCL_3_train), np.array(y_EXCL_3_train)\n",
        "X_EXCL_3_train = np.reshape(X_EXCL_3_train, (X_EXCL_3_train.shape[0], X_EXCL_3_train.shape[1], 1))\n",
        "model_EXCL_3 = Sequential()\n",
        "model_EXCL_3.add(LSTM(units=50,return_sequences=True,input_shape=(X_EXCL_3_train.shape[1], 1)))\n",
        "model_EXCL_3.add(Dropout(0.2))\n",
        "model_EXCL_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_3.add(Dropout(0.2))\n",
        "model_EXCL_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_3.add(Dropout(0.2))\n",
        "model_EXCL_3.add(LSTM(units=50))\n",
        "model_EXCL_3.add(Dropout(0.2))\n",
        "model_EXCL_3.add(Dense(units=1))\n",
        "model_EXCL_3.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_EXCL_3.fit(X_EXCL_3_train,y_EXCL_3_train,epochs=10,batch_size=16)\n",
        "\n",
        "# PGAS\n",
        "PGAS_3 = yf.download(\"PGAS.JK\", start=\"2022-02-10\", end=\"2022-08-10\")\n",
        "PGAS_3.insert(4,\"Return\", PGAS_3['Close'].pct_change())\n",
        "PGAS_3 = PGAS_3.dropna()\n",
        "PGAS_3_test = yf.download(\"PGAS.JK\", start=\"2022-08-09\", end=\"2022-09-10\")\n",
        "PGAS_3_test.insert(4,\"Return\", PGAS_3_test['Close'].pct_change())\n",
        "PGAS_3_test = PGAS_3_test.dropna()\n",
        "training_PGAS_3 = PGAS_3.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_PGAS_3_scaled = sc.fit_transform(training_PGAS_3)\n",
        "X_PGAS_3_train = []\n",
        "y_PGAS_3_train = []\n",
        "for i in range(days_period, len(PGAS_3)-1):\n",
        "    X_PGAS_3_train.append(training_PGAS_3_scaled[i-days_period:i, 0])\n",
        "    y_PGAS_3_train.append(training_PGAS_3_scaled[i, 0])\n",
        "X_PGAS_3_train, y_PGAS_3_train = np.array(X_PGAS_3_train), np.array(y_PGAS_3_train)\n",
        "X_PGAS_3_train = np.reshape(X_PGAS_3_train, (X_PGAS_3_train.shape[0], X_PGAS_3_train.shape[1], 1))\n",
        "model_PGAS_3 = Sequential()\n",
        "model_PGAS_3.add(LSTM(units=50,return_sequences=True,input_shape=(X_PGAS_3_train.shape[1], 1)))\n",
        "model_PGAS_3.add(Dropout(0.2))\n",
        "model_PGAS_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_3.add(Dropout(0.2))\n",
        "model_PGAS_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_3.add(Dropout(0.2))\n",
        "model_PGAS_3.add(LSTM(units=50))\n",
        "model_PGAS_3.add(Dropout(0.2))\n",
        "model_PGAS_3.add(Dense(units=1))\n",
        "model_PGAS_3.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_PGAS_3.fit(X_PGAS_3_train,y_PGAS_3_train,epochs=10,batch_size=16)\n",
        "\n",
        "# TLKM\n",
        "TLKM_3 = yf.download(\"TLKM.JK\", start=\"2022-02-10\", end=\"2022-08-10\")\n",
        "TLKM_3.insert(4,\"Return\", TLKM_3['Close'].pct_change())\n",
        "TLKM_3 = TLKM_3.dropna()\n",
        "TLKM_3_test = yf.download(\"TLKM.JK\", start=\"2022-08-09\", end=\"2022-09-10\")\n",
        "TLKM_3_test.insert(4,\"Return\", TLKM_3_test['Close'].pct_change())\n",
        "TLKM_3_test = TLKM_3_test.dropna()\n",
        "training_TLKM_3 = TLKM_3.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_TLKM_3_scaled = sc.fit_transform(training_TLKM_3)\n",
        "X_TLKM_3_train = []\n",
        "y_TLKM_3_train = []\n",
        "for i in range(days_period, len(TLKM_3)-1):\n",
        "    X_TLKM_3_train.append(training_TLKM_3_scaled[i-days_period:i, 0])\n",
        "    y_TLKM_3_train.append(training_TLKM_3_scaled[i, 0])\n",
        "X_TLKM_3_train, y_TLKM_3_train = np.array(X_TLKM_3_train), np.array(y_TLKM_3_train)\n",
        "X_TLKM_3_train = np.reshape(X_TLKM_3_train, (X_TLKM_3_train.shape[0], X_TLKM_3_train.shape[1], 1))\n",
        "model_TLKM_3 = Sequential()\n",
        "model_TLKM_3.add(LSTM(units=50,return_sequences=True,input_shape=(X_TLKM_3_train.shape[1], 1)))\n",
        "model_TLKM_3.add(Dropout(0.2))\n",
        "model_TLKM_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_3.add(Dropout(0.2))\n",
        "model_TLKM_3.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_3.add(Dropout(0.2))\n",
        "model_TLKM_3.add(LSTM(units=50))\n",
        "model_TLKM_3.add(Dropout(0.2))\n",
        "model_TLKM_3.add(Dense(units=1))\n",
        "model_TLKM_3.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_TLKM_3.fit(X_TLKM_3_train,y_TLKM_3_train,epochs=10,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVJON_-5Gyso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c482a1da-7e75-4203-db9d-fddeb5633991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ],
      "source": [
        "# ADRO\n",
        "real_ADRO_3_return = ADRO_3_test.iloc[:, 4:5].values\n",
        "real_ADRO_3_return = real_ADRO_3_return[:days_predict]\n",
        "ADRO_3_total = ADRO_3['Close'].copy(deep=True)\n",
        "inputs_ADRO_3 = ADRO_3_total[len(ADRO_3) - days_period: len(ADRO_3)].values\n",
        "inputs_ADRO_3 = inputs_ADRO_3.reshape(-1,1)\n",
        "inputs_ADRO_3 = sc.transform(inputs_ADRO_3)\n",
        "predicted_ADRO_3_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ADRO_3_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ADRO_3_test.append(inputs_ADRO_3[i:i+days_period, 0])\n",
        "  X_ADRO_3_test = np.array(X_ADRO_3_test)\n",
        "  X_ADRO_3_test = np.reshape(X_ADRO_3_test, (X_ADRO_3_test.shape[0], X_ADRO_3_test.shape[1], 1))\n",
        "  predicted_ADRO_3_return[j] = model_ADRO_3.predict(X_ADRO_3_test)\n",
        "  inputs_ADRO_3 += (predicted_ADRO_3_return[j])\n",
        "  inputs_ADRO_3 = inputs_ADRO_3.reshape(-1,1)\n",
        "\n",
        "# ASII\n",
        "real_ASII_3_return = ASII_3_test.iloc[:, 4:5].values\n",
        "real_ASII_3_return = real_ASII_3_return[:days_predict]\n",
        "ASII_3_total = ASII_3['Close'].copy(deep=True)\n",
        "inputs_ASII_3 = ASII_3_total[len(ASII_3) - days_period: len(ASII_3)].values\n",
        "inputs_ASII_3 = inputs_ASII_3.reshape(-1,1)\n",
        "inputs_ASII_3 = sc.transform(inputs_ASII_3)\n",
        "predicted_ASII_3_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ASII_3_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ASII_3_test.append(inputs_ASII_3[i:i+days_period, 0])\n",
        "  X_ASII_3_test = np.array(X_ASII_3_test)\n",
        "  X_ASII_3_test = np.reshape(X_ASII_3_test, (X_ASII_3_test.shape[0], X_ASII_3_test.shape[1], 1))\n",
        "  predicted_ASII_3_return[j] = model_ASII_3.predict(X_ASII_3_test)\n",
        "  inputs_ASII_3 += (predicted_ASII_3_return[j])\n",
        "  inputs_ASII_3 = inputs_ASII_3.reshape(-1,1)\n",
        "\n",
        "# BMRI\n",
        "real_BMRI_3_return = BMRI_3_test.iloc[:, 4:5].values\n",
        "real_BMRI_3_return = real_BMRI_3_return[:days_predict]\n",
        "BMRI_3_total = BMRI_3['Close'].copy(deep=True)\n",
        "inputs_BMRI_3 = BMRI_3_total[len(BMRI_3) - days_period: len(BMRI_3)].values\n",
        "inputs_BMRI_3 = inputs_BMRI_3.reshape(-1,1)\n",
        "inputs_BMRI_3 = sc.transform(inputs_BMRI_3)\n",
        "predicted_BMRI_3_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BMRI_3_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BMRI_3_test.append(inputs_BMRI_3[i:i+days_period, 0])\n",
        "  X_BMRI_3_test = np.array(X_BMRI_3_test)\n",
        "  X_BMRI_3_test = np.reshape(X_BMRI_3_test, (X_BMRI_3_test.shape[0], X_BMRI_3_test.shape[1], 1))\n",
        "  predicted_BMRI_3_return[j] = model_BMRI_3.predict(X_BMRI_3_test)\n",
        "  inputs_BMRI_3 += (predicted_BMRI_3_return[j])\n",
        "  inputs_BMRI_3 = inputs_BMRI_3.reshape(-1,1)\n",
        "\n",
        "# BBRI\n",
        "real_BBRI_3_return = BBRI_3_test.iloc[:, 4:5].values\n",
        "real_BBRI_3_return = real_BBRI_3_return[:days_predict]\n",
        "BBRI_3_total = BBRI_3['Close'].copy(deep=True)\n",
        "inputs_BBRI_3 = BBRI_3_total[len(BBRI_3) - days_period: len(BBRI_3)].values\n",
        "inputs_BBRI_3 = inputs_BBRI_3.reshape(-1,1)\n",
        "inputs_BBRI_3 = sc.transform(inputs_BBRI_3)\n",
        "predicted_BBRI_3_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBRI_3_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBRI_3_test.append(inputs_BBRI_3[i:i+days_period, 0])\n",
        "  X_BBRI_3_test = np.array(X_BBRI_3_test)\n",
        "  X_BBRI_3_test = np.reshape(X_BBRI_3_test, (X_BBRI_3_test.shape[0], X_BBRI_3_test.shape[1], 1))\n",
        "  predicted_BBRI_3_return[j] = model_BBRI_3.predict(X_BBRI_3_test)\n",
        "  inputs_BBRI_3 += (predicted_BBRI_3_return[j])\n",
        "  inputs_BBRI_3 = inputs_BBRI_3.reshape(-1,1)\n",
        "\n",
        "# BBTN\n",
        "real_BBTN_3_return = BBTN_3_test.iloc[:, 4:5].values\n",
        "real_BBTN_3_return = real_BBTN_3_return[:days_predict]\n",
        "BBTN_3_total = BBTN_3['Close'].copy(deep=True)\n",
        "inputs_BBTN_3 = BBTN_3_total[len(BBTN_3) - days_period: len(BBTN_3)].values\n",
        "inputs_BBTN_3 = inputs_BBTN_3.reshape(-1,1)\n",
        "inputs_BBTN_3 = sc.transform(inputs_BBTN_3)\n",
        "predicted_BBTN_3_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBTN_3_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBTN_3_test.append(inputs_BBTN_3[i:i+days_period, 0])\n",
        "  X_BBTN_3_test = np.array(X_BBTN_3_test)\n",
        "  X_BBTN_3_test = np.reshape(X_BBTN_3_test, (X_BBTN_3_test.shape[0], X_BBTN_3_test.shape[1], 1))\n",
        "  predicted_BBTN_3_return[j] = model_BBTN_3.predict(X_BBTN_3_test)\n",
        "  inputs_BBTN_3 += (predicted_BBTN_3_return[j])\n",
        "  inputs_BBTN_3 = inputs_BBTN_3.reshape(-1,1)\n",
        "\n",
        "# BUMI\n",
        "real_BUMI_3_return = BUMI_3_test.iloc[:, 4:5].values\n",
        "real_BUMI_3_return = real_BUMI_3_return[:days_predict]\n",
        "BUMI_3_total = BUMI_3['Close'].copy(deep=True)\n",
        "inputs_BUMI_3 = BUMI_3_total[len(BUMI_3) - days_period: len(BUMI_3)].values\n",
        "inputs_BUMI_3 = inputs_BUMI_3.reshape(-1,1)\n",
        "inputs_BUMI_3 = sc.transform(inputs_BUMI_3)\n",
        "predicted_BUMI_3_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BUMI_3_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BUMI_3_test.append(inputs_BUMI_3[i:i+days_period, 0])\n",
        "  X_BUMI_3_test = np.array(X_BUMI_3_test)\n",
        "  X_BUMI_3_test = np.reshape(X_BUMI_3_test, (X_BUMI_3_test.shape[0], X_BUMI_3_test.shape[1], 1))\n",
        "  predicted_BUMI_3_return[j] = model_BUMI_3.predict(X_BUMI_3_test)\n",
        "  inputs_BUMI_3 += (predicted_BUMI_3_return[j])\n",
        "  inputs_BUMI_3 = inputs_BUMI_3.reshape(-1,1)\n",
        "\n",
        "# MFIN\n",
        "real_MFIN_3_return = MFIN_3_test.iloc[:, 4:5].values\n",
        "real_MFIN_3_return = real_MFIN_3_return[:days_predict]\n",
        "MFIN_3_total = MFIN_3['Close'].copy(deep=True)\n",
        "inputs_MFIN_3 = MFIN_3_total[len(MFIN_3) - days_period: len(MFIN_3)].values\n",
        "inputs_MFIN_3 = inputs_MFIN_3.reshape(-1,1)\n",
        "inputs_MFIN_3 = sc.transform(inputs_MFIN_3)\n",
        "predicted_MFIN_3_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_MFIN_3_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_MFIN_3_test.append(inputs_MFIN_3[i:i+days_period, 0])\n",
        "  X_MFIN_3_test = np.array(X_MFIN_3_test)\n",
        "  X_MFIN_3_test = np.reshape(X_MFIN_3_test, (X_MFIN_3_test.shape[0], X_MFIN_3_test.shape[1], 1))\n",
        "  predicted_MFIN_3_return[j] = model_MFIN_3.predict(X_MFIN_3_test)\n",
        "  inputs_MFIN_3 += (predicted_MFIN_3_return[j])\n",
        "  inputs_MFIN_3 = inputs_MFIN_3.reshape(-1,1)\n",
        "\n",
        "# EXCL\n",
        "real_EXCL_3_return = EXCL_3_test.iloc[:, 4:5].values\n",
        "real_EXCL_3_return = real_EXCL_3_return[:days_predict]\n",
        "EXCL_3_total = EXCL_3['Close'].copy(deep=True)\n",
        "inputs_EXCL_3 = EXCL_3_total[len(EXCL_3) - days_period: len(EXCL_3)].values\n",
        "inputs_EXCL_3 = inputs_EXCL_3.reshape(-1,1)\n",
        "inputs_EXCL_3 = sc.transform(inputs_EXCL_3)\n",
        "predicted_EXCL_3_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_EXCL_3_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_EXCL_3_test.append(inputs_EXCL_3[i:i+days_period, 0])\n",
        "  X_EXCL_3_test = np.array(X_EXCL_3_test)\n",
        "  X_EXCL_3_test = np.reshape(X_EXCL_3_test, (X_EXCL_3_test.shape[0], X_EXCL_3_test.shape[1], 1))\n",
        "  predicted_EXCL_3_return[j] = model_EXCL_3.predict(X_EXCL_3_test)\n",
        "  inputs_EXCL_3 += (predicted_EXCL_3_return[j])\n",
        "  inputs_EXCL_3 = inputs_EXCL_3.reshape(-1,1)\n",
        "\n",
        "# PGAS\n",
        "real_PGAS_3_return = PGAS_3_test.iloc[:, 4:5].values\n",
        "real_PGAS_3_return = real_PGAS_3_return[:days_predict]\n",
        "PGAS_3_total = PGAS_3['Close'].copy(deep=True)\n",
        "inputs_PGAS_3 = PGAS_3_total[len(PGAS_3) - days_period: len(PGAS_3)].values\n",
        "inputs_PGAS_3 = inputs_PGAS_3.reshape(-1,1)\n",
        "inputs_PGAS_3 = sc.transform(inputs_PGAS_3)\n",
        "predicted_PGAS_3_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_PGAS_3_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_PGAS_3_test.append(inputs_PGAS_3[i:i+days_period, 0])\n",
        "  X_PGAS_3_test = np.array(X_PGAS_3_test)\n",
        "  X_PGAS_3_test = np.reshape(X_PGAS_3_test, (X_PGAS_3_test.shape[0], X_PGAS_3_test.shape[1], 1))\n",
        "  predicted_PGAS_3_return[j] = model_PGAS_3.predict(X_PGAS_3_test)\n",
        "  inputs_PGAS_3 += (predicted_PGAS_3_return[j])\n",
        "  inputs_PGAS_3 = inputs_PGAS_3.reshape(-1,1)\n",
        "\n",
        "# TLKM\n",
        "real_TLKM_3_return = TLKM_3_test.iloc[:, 4:5].values\n",
        "real_TLKM_3_return = real_TLKM_3_return[:days_predict]\n",
        "TLKM_3_total = TLKM_3['Close'].copy(deep=True)\n",
        "inputs_TLKM_3 = TLKM_3_total[len(TLKM_3) - days_period: len(TLKM_3)].values\n",
        "inputs_TLKM_3 = inputs_TLKM_3.reshape(-1,1)\n",
        "inputs_TLKM_3 = sc.transform(inputs_TLKM_3)\n",
        "predicted_TLKM_3_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_TLKM_3_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_TLKM_3_test.append(inputs_TLKM_3[i:i+days_period, 0])\n",
        "  X_TLKM_3_test = np.array(X_TLKM_3_test)\n",
        "  X_TLKM_3_test = np.reshape(X_TLKM_3_test, (X_TLKM_3_test.shape[0], X_TLKM_3_test.shape[1], 1))\n",
        "  predicted_TLKM_3_return[j] = model_TLKM_3.predict(X_TLKM_3_test)\n",
        "  inputs_TLKM_3 += (predicted_TLKM_3_return[j])\n",
        "  inputs_TLKM_3 = inputs_TLKM_3.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSSXMQ_2Gysr"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "predicted_ADRO_3_return = np.squeeze(np.asarray(predicted_ADRO_3_return))\n",
        "predicted_ADRO_3_return = predicted_ADRO_3_return.reshape(-1,1)\n",
        "predicted_ADRO_3_return = sc.inverse_transform(predicted_ADRO_3_return)\n",
        "# ASII\n",
        "predicted_ASII_3_return = np.squeeze(np.asarray(predicted_ASII_3_return))\n",
        "predicted_ASII_3_return = predicted_ASII_3_return.reshape(-1,1)\n",
        "predicted_ASII_3_return = sc.inverse_transform(predicted_ASII_3_return)\n",
        "# BMRI\n",
        "predicted_BMRI_3_return = np.squeeze(np.asarray(predicted_BMRI_3_return))\n",
        "predicted_BMRI_3_return = predicted_BMRI_3_return.reshape(-1,1)\n",
        "predicted_BMRI_3_return = sc.inverse_transform(predicted_BMRI_3_return)\n",
        "# BBRI\n",
        "predicted_BBRI_3_return = np.squeeze(np.asarray(predicted_BBRI_3_return))\n",
        "predicted_BBRI_3_return = predicted_BBRI_3_return.reshape(-1,1)\n",
        "predicted_BBRI_3_return = sc.inverse_transform(predicted_BBRI_3_return)\n",
        "# BBTN\n",
        "predicted_BBTN_3_return = np.squeeze(np.asarray(predicted_BBTN_3_return))\n",
        "predicted_BBTN_3_return = predicted_BBTN_3_return.reshape(-1,1)\n",
        "predicted_BBTN_3_return = sc.inverse_transform(predicted_BBTN_3_return)\n",
        "# BUMI\n",
        "predicted_BUMI_3_return = np.squeeze(np.asarray(predicted_BUMI_3_return))\n",
        "predicted_BUMI_3_return = predicted_BUMI_3_return.reshape(-1,1)\n",
        "predicted_BUMI_3_return = sc.inverse_transform(predicted_BUMI_3_return)\n",
        "# MFIN\n",
        "predicted_MFIN_3_return = np.squeeze(np.asarray(predicted_MFIN_3_return))\n",
        "predicted_MFIN_3_return = predicted_MFIN_3_return.reshape(-1,1)\n",
        "predicted_MFIN_3_return = sc.inverse_transform(predicted_MFIN_3_return)\n",
        "# EXCL\n",
        "predicted_EXCL_3_return = np.squeeze(np.asarray(predicted_EXCL_3_return))\n",
        "predicted_EXCL_3_return = predicted_EXCL_3_return.reshape(-1,1)\n",
        "predicted_EXCL_3_return = sc.inverse_transform(predicted_EXCL_3_return)\n",
        "# PGAS\n",
        "predicted_PGAS_3_return = np.squeeze(np.asarray(predicted_PGAS_3_return))\n",
        "predicted_PGAS_3_return = predicted_PGAS_3_return.reshape(-1,1)\n",
        "predicted_PGAS_3_return = sc.inverse_transform(predicted_PGAS_3_return)\n",
        "# TLKM\n",
        "predicted_TLKM_3_return = np.squeeze(np.asarray(predicted_TLKM_3_return))\n",
        "predicted_TLKM_3_return = predicted_TLKM_3_return.reshape(-1,1)\n",
        "predicted_TLKM_3_return = sc.inverse_transform(predicted_TLKM_3_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhA8cBtgGyss"
      },
      "outputs": [],
      "source": [
        "predicted3 = pd.DataFrame(predicted_ADRO_3_return)\n",
        "predicted3.rename(columns={0:'ADRO'}, inplace=True)\n",
        "predicted3.insert(1,\"ASII\", predicted_ASII_3_return)\n",
        "predicted3.insert(2,\"BBRI\", predicted_BBRI_3_return)\n",
        "predicted3.insert(3,\"BBTN\", predicted_BBTN_3_return)\n",
        "predicted3.insert(4,\"BMRI\", predicted_BMRI_3_return)\n",
        "predicted3.insert(5,\"BUMI\", predicted_BUMI_3_return)\n",
        "predicted3.insert(6,\"EXCL\", predicted_EXCL_3_return)\n",
        "predicted3.insert(7,\"MFIN\", predicted_MFIN_3_return)\n",
        "predicted3.insert(8,\"PGAS\", predicted_PGAS_3_return)\n",
        "predicted3.insert(9,\"TLKM\", predicted_TLKM_3_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwc_eSl1Pu8v",
        "outputId": "34d50a4e-5f36-4aeb-c50c-ae95a8d388a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADRO      ASII      BBRI      BBTN      BMRI      BUMI      EXCL  \\\n",
              "0 -0.006840  0.020208  0.013649  0.010727  0.034410 -0.006550  0.009730   \n",
              "1 -0.007560  0.019131  0.012630  0.009816  0.033356 -0.007014  0.009076   \n",
              "2 -0.008440  0.017822  0.011377  0.008733  0.032066 -0.007614  0.008274   \n",
              "3 -0.009508  0.016240  0.009849  0.007443  0.030492 -0.008380  0.007286   \n",
              "4 -0.010796  0.014336  0.008003  0.005907  0.028577 -0.009345  0.006070   \n",
              "5 -0.012334  0.012057  0.005794  0.004082  0.026255 -0.010546  0.004575   \n",
              "6 -0.014156  0.009345  0.003177  0.001917  0.023453 -0.012019  0.002742   \n",
              "7 -0.016294  0.006143  0.000108 -0.000641  0.020090 -0.013823  0.000506   \n",
              "8 -0.018776  0.002397 -0.003446 -0.003645  0.016081 -0.015991 -0.002205   \n",
              "9 -0.021624 -0.001940 -0.007509 -0.007149  0.011345 -0.018536 -0.005461   \n",
              "\n",
              "       MFIN      PGAS      TLKM  \n",
              "0  0.018622  0.021110  0.024384  \n",
              "1  0.017656  0.019959  0.023135  \n",
              "2  0.016484  0.018576  0.021615  \n",
              "3  0.015067  0.016918  0.019779  \n",
              "4  0.013358  0.014940  0.017576  \n",
              "5  0.011306  0.012588  0.014955  \n",
              "6  0.008853  0.009809  0.011862  \n",
              "7  0.005940  0.006544  0.008247  \n",
              "8  0.002506  0.002738  0.004065  \n",
              "9 -0.001503 -0.001656 -0.000712  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba421504-82bd-4eaf-b8e3-cce82d8d006c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADRO</th>\n",
              "      <th>ASII</th>\n",
              "      <th>BBRI</th>\n",
              "      <th>BBTN</th>\n",
              "      <th>BMRI</th>\n",
              "      <th>BUMI</th>\n",
              "      <th>EXCL</th>\n",
              "      <th>MFIN</th>\n",
              "      <th>PGAS</th>\n",
              "      <th>TLKM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.006840</td>\n",
              "      <td>0.020208</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>0.010727</td>\n",
              "      <td>0.034410</td>\n",
              "      <td>-0.006550</td>\n",
              "      <td>0.009730</td>\n",
              "      <td>0.018622</td>\n",
              "      <td>0.021110</td>\n",
              "      <td>0.024384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.007560</td>\n",
              "      <td>0.019131</td>\n",
              "      <td>0.012630</td>\n",
              "      <td>0.009816</td>\n",
              "      <td>0.033356</td>\n",
              "      <td>-0.007014</td>\n",
              "      <td>0.009076</td>\n",
              "      <td>0.017656</td>\n",
              "      <td>0.019959</td>\n",
              "      <td>0.023135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.008440</td>\n",
              "      <td>0.017822</td>\n",
              "      <td>0.011377</td>\n",
              "      <td>0.008733</td>\n",
              "      <td>0.032066</td>\n",
              "      <td>-0.007614</td>\n",
              "      <td>0.008274</td>\n",
              "      <td>0.016484</td>\n",
              "      <td>0.018576</td>\n",
              "      <td>0.021615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.009508</td>\n",
              "      <td>0.016240</td>\n",
              "      <td>0.009849</td>\n",
              "      <td>0.007443</td>\n",
              "      <td>0.030492</td>\n",
              "      <td>-0.008380</td>\n",
              "      <td>0.007286</td>\n",
              "      <td>0.015067</td>\n",
              "      <td>0.016918</td>\n",
              "      <td>0.019779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.010796</td>\n",
              "      <td>0.014336</td>\n",
              "      <td>0.008003</td>\n",
              "      <td>0.005907</td>\n",
              "      <td>0.028577</td>\n",
              "      <td>-0.009345</td>\n",
              "      <td>0.006070</td>\n",
              "      <td>0.013358</td>\n",
              "      <td>0.014940</td>\n",
              "      <td>0.017576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.012334</td>\n",
              "      <td>0.012057</td>\n",
              "      <td>0.005794</td>\n",
              "      <td>0.004082</td>\n",
              "      <td>0.026255</td>\n",
              "      <td>-0.010546</td>\n",
              "      <td>0.004575</td>\n",
              "      <td>0.011306</td>\n",
              "      <td>0.012588</td>\n",
              "      <td>0.014955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.014156</td>\n",
              "      <td>0.009345</td>\n",
              "      <td>0.003177</td>\n",
              "      <td>0.001917</td>\n",
              "      <td>0.023453</td>\n",
              "      <td>-0.012019</td>\n",
              "      <td>0.002742</td>\n",
              "      <td>0.008853</td>\n",
              "      <td>0.009809</td>\n",
              "      <td>0.011862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.016294</td>\n",
              "      <td>0.006143</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>-0.000641</td>\n",
              "      <td>0.020090</td>\n",
              "      <td>-0.013823</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>0.005940</td>\n",
              "      <td>0.006544</td>\n",
              "      <td>0.008247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.018776</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>-0.003446</td>\n",
              "      <td>-0.003645</td>\n",
              "      <td>0.016081</td>\n",
              "      <td>-0.015991</td>\n",
              "      <td>-0.002205</td>\n",
              "      <td>0.002506</td>\n",
              "      <td>0.002738</td>\n",
              "      <td>0.004065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.021624</td>\n",
              "      <td>-0.001940</td>\n",
              "      <td>-0.007509</td>\n",
              "      <td>-0.007149</td>\n",
              "      <td>0.011345</td>\n",
              "      <td>-0.018536</td>\n",
              "      <td>-0.005461</td>\n",
              "      <td>-0.001503</td>\n",
              "      <td>-0.001656</td>\n",
              "      <td>-0.000712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba421504-82bd-4eaf-b8e3-cce82d8d006c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba421504-82bd-4eaf-b8e3-cce82d8d006c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba421504-82bd-4eaf-b8e3-cce82d8d006c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm259gTHcf0D"
      },
      "source": [
        "## Data Preparation 4\n",
        "1st of January 2018 - 9th of September 2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPVv8GF5G0Fk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6abc645-f734-444f-d57a-d56fa29fd523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 10s 43ms/step - loss: 0.1942\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0799\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0744\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0510\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0592\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0540\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0550\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0561\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0482\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0504\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 40ms/step - loss: 0.1728\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0415\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0500\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0273\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0290\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.0353\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0283\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0245\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0308\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0264\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 8s 41ms/step - loss: 0.1129\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0439\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0323\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0196\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0248\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0227\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0214\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0222\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0181\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0190\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 8s 41ms/step - loss: 0.1412\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0476\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0355\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0294\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0313\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0249\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0268\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0229\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0234\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 0.0261\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 8s 41ms/step - loss: 0.1778\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0233\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0289\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0247\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0241\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0236\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0248\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0226\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0250\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 0.0249\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 68ms/step - loss: 0.0596\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0396\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0289\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0310\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0302\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0299\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0297\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0280\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0287\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0300\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 41ms/step - loss: 0.1090\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0284\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0264\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0182\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0179\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0195\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0180\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0184\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0188\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0202\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 40ms/step - loss: 0.1345\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0463\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0457\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0448\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0455\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0409\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0439\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0425\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0444\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0430\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 47ms/step - loss: 0.1247\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0527\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0526\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0443\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0393\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0423\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0424\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0427\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0375\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0390\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 40ms/step - loss: 0.2473\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0536\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0451\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0311\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0318\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0276\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0267\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0294\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0265\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0281\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1d2fe5f5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Period parameters\n",
        "days_period = 20\n",
        "days_predict = 10\n",
        "\n",
        "# ADRO\n",
        "ADRO_4 = yf.download(\"ADRO.JK\", start=\"2022-03-10\", end=\"2022-09-10\")\n",
        "ADRO_4.insert(4,\"Return\", ADRO_4['Close'].pct_change())\n",
        "ADRO_4 = ADRO_4.dropna()\n",
        "ADRO_4_test = yf.download(\"ADRO.JK\", start=\"2022-09-09\", end=\"2022-10-10\")\n",
        "ADRO_4_test.insert(4,\"Return\", ADRO_4_test['Close'].pct_change())\n",
        "ADRO_4_test = ADRO_4_test.dropna()\n",
        "training_ADRO_4 = ADRO_4.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ADRO_4_scaled = sc.fit_transform(training_ADRO_4)\n",
        "X_ADRO_4_train = []\n",
        "y_ADRO_4_train = []\n",
        "for i in range(days_period, len(ADRO_4)-1):\n",
        "    X_ADRO_4_train.append(training_ADRO_4_scaled[i-days_period:i, 0])\n",
        "    y_ADRO_4_train.append(training_ADRO_4_scaled[i, 0])\n",
        "X_ADRO_4_train, y_ADRO_4_train = np.array(X_ADRO_4_train), np.array(y_ADRO_4_train)\n",
        "X_ADRO_4_train = np.reshape(X_ADRO_4_train, (X_ADRO_4_train.shape[0], X_ADRO_4_train.shape[1], 1))\n",
        "model_ADRO_4 = Sequential()\n",
        "model_ADRO_4.add(LSTM(units=50,return_sequences=True,input_shape=(X_ADRO_4_train.shape[1], 1)))\n",
        "model_ADRO_4.add(Dropout(0.2))\n",
        "model_ADRO_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_4.add(Dropout(0.2))\n",
        "model_ADRO_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_4.add(Dropout(0.2))\n",
        "model_ADRO_4.add(LSTM(units=50))\n",
        "model_ADRO_4.add(Dropout(0.2))\n",
        "model_ADRO_4.add(Dense(units=1))\n",
        "model_ADRO_4.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ADRO_4.fit(X_ADRO_4_train,y_ADRO_4_train,epochs=10,batch_size=16)\n",
        "\n",
        "# ASII\n",
        "ASII_4 = yf.download(\"ASII.JK\", start=\"2022-03-10\", end=\"2022-09-10\")\n",
        "ASII_4.insert(4,\"Return\", ASII_4['Close'].pct_change())\n",
        "ASII_4 = ASII_4.dropna()\n",
        "ASII_4_test = yf.download(\"ASII.JK\", start=\"2022-09-09\", end=\"2022-10-10\")\n",
        "ASII_4_test.insert(4,\"Return\", ASII_4_test['Close'].pct_change())\n",
        "ASII_4_test = ASII_4_test.dropna()\n",
        "training_ASII_4 = ASII_4.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ASII_4_scaled = sc.fit_transform(training_ASII_4)\n",
        "X_ASII_4_train = []\n",
        "y_ASII_4_train = []\n",
        "for i in range(days_period, len(ASII_4)-1):\n",
        "    X_ASII_4_train.append(training_ASII_4_scaled[i-days_period:i, 0])\n",
        "    y_ASII_4_train.append(training_ASII_4_scaled[i, 0])\n",
        "X_ASII_4_train, y_ASII_4_train = np.array(X_ASII_4_train), np.array(y_ASII_4_train)\n",
        "X_ASII_4_train = np.reshape(X_ASII_4_train, (X_ASII_4_train.shape[0], X_ASII_4_train.shape[1], 1))\n",
        "model_ASII_4 = Sequential()\n",
        "model_ASII_4.add(LSTM(units=50,return_sequences=True,input_shape=(X_ASII_4_train.shape[1], 1)))\n",
        "model_ASII_4.add(Dropout(0.2))\n",
        "model_ASII_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_4.add(Dropout(0.2))\n",
        "model_ASII_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_4.add(Dropout(0.2))\n",
        "model_ASII_4.add(LSTM(units=50))\n",
        "model_ASII_4.add(Dropout(0.2))\n",
        "model_ASII_4.add(Dense(units=1))\n",
        "model_ASII_4.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ASII_4.fit(X_ASII_4_train,y_ASII_4_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BMRI\n",
        "BMRI_4 = yf.download(\"BMRI.JK\", start=\"2022-03-10\", end=\"2022-09-10\")\n",
        "BMRI_4.insert(4,\"Return\", BMRI_4['Close'].pct_change())\n",
        "BMRI_4 = BMRI_4.dropna()\n",
        "BMRI_4_test = yf.download(\"BMRI.JK\", start=\"2022-09-09\", end=\"2022-10-10\")\n",
        "BMRI_4_test.insert(4,\"Return\", BMRI_4_test['Close'].pct_change())\n",
        "BMRI_4_test = BMRI_4_test.dropna()\n",
        "training_BMRI_4 = BMRI_4.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BMRI_4_scaled = sc.fit_transform(training_BMRI_4)\n",
        "X_BMRI_4_train = []\n",
        "y_BMRI_4_train = []\n",
        "for i in range(days_period, len(BMRI_4)-1):\n",
        "    X_BMRI_4_train.append(training_BMRI_4_scaled[i-days_period:i, 0])\n",
        "    y_BMRI_4_train.append(training_BMRI_4_scaled[i, 0])\n",
        "X_BMRI_4_train, y_BMRI_4_train = np.array(X_BMRI_4_train), np.array(y_BMRI_4_train)\n",
        "X_BMRI_4_train = np.reshape(X_BMRI_4_train, (X_BMRI_4_train.shape[0], X_BMRI_4_train.shape[1], 1))\n",
        "model_BMRI_4 = Sequential()\n",
        "model_BMRI_4.add(LSTM(units=50,return_sequences=True,input_shape=(X_BMRI_4_train.shape[1], 1)))\n",
        "model_BMRI_4.add(Dropout(0.2))\n",
        "model_BMRI_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_4.add(Dropout(0.2))\n",
        "model_BMRI_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_4.add(Dropout(0.2))\n",
        "model_BMRI_4.add(LSTM(units=50))\n",
        "model_BMRI_4.add(Dropout(0.2))\n",
        "model_BMRI_4.add(Dense(units=1))\n",
        "model_BMRI_4.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BMRI_4.fit(X_BMRI_4_train,y_BMRI_4_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBRI\n",
        "BBRI_4 = yf.download(\"BBRI.JK\", start=\"2022-03-10\", end=\"2022-09-10\")\n",
        "BBRI_4.insert(4,\"Return\", BBRI_4['Close'].pct_change())\n",
        "BBRI_4 = BBRI_4.dropna()\n",
        "BBRI_4_test = yf.download(\"BBRI.JK\", start=\"2022-09-09\", end=\"2022-10-10\")\n",
        "BBRI_4_test.insert(4,\"Return\", BBRI_4_test['Close'].pct_change())\n",
        "BBRI_4_test = BBRI_4_test.dropna()\n",
        "training_BBRI_4 = BBRI_4.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBRI_4_scaled = sc.fit_transform(training_BBRI_4)\n",
        "X_BBRI_4_train = []\n",
        "y_BBRI_4_train = []\n",
        "for i in range(days_period, len(BBRI_4)-1):\n",
        "    X_BBRI_4_train.append(training_BBRI_4_scaled[i-days_period:i, 0])\n",
        "    y_BBRI_4_train.append(training_BBRI_4_scaled[i, 0])\n",
        "X_BBRI_4_train, y_BBRI_4_train = np.array(X_BBRI_4_train), np.array(y_BBRI_4_train)\n",
        "X_BBRI_4_train = np.reshape(X_BBRI_4_train, (X_BBRI_4_train.shape[0], X_BBRI_4_train.shape[1], 1))\n",
        "model_BBRI_4 = Sequential()\n",
        "model_BBRI_4.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBRI_4_train.shape[1], 1)))\n",
        "model_BBRI_4.add(Dropout(0.2))\n",
        "model_BBRI_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_4.add(Dropout(0.2))\n",
        "model_BBRI_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_4.add(Dropout(0.2))\n",
        "model_BBRI_4.add(LSTM(units=50))\n",
        "model_BBRI_4.add(Dropout(0.2))\n",
        "model_BBRI_4.add(Dense(units=1))\n",
        "model_BBRI_4.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBRI_4.fit(X_BBRI_4_train,y_BBRI_4_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBTN\n",
        "BBTN_4 = yf.download(\"BBTN.JK\", start=\"2022-03-10\", end=\"2022-09-10\")\n",
        "BBTN_4.insert(4,\"Return\", BBTN_4['Close'].pct_change())\n",
        "BBTN_4 = BBTN_4.dropna()\n",
        "BBTN_4_test = yf.download(\"BBTN.JK\", start=\"2022-09-09\", end=\"2022-10-10\")\n",
        "BBTN_4_test.insert(4,\"Return\", BBTN_4_test['Close'].pct_change())\n",
        "BBTN_4_test = BBTN_4_test.dropna()\n",
        "training_BBTN_4 = BBTN_4.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBTN_4_scaled = sc.fit_transform(training_BBTN_4)\n",
        "X_BBTN_4_train = []\n",
        "y_BBTN_4_train = []\n",
        "for i in range(days_period, len(BBTN_4)-1):\n",
        "    X_BBTN_4_train.append(training_BBTN_4_scaled[i-days_period:i, 0])\n",
        "    y_BBTN_4_train.append(training_BBTN_4_scaled[i, 0])\n",
        "X_BBTN_4_train, y_BBTN_4_train = np.array(X_BBTN_4_train), np.array(y_BBTN_4_train)\n",
        "X_BBTN_4_train = np.reshape(X_BBTN_4_train, (X_BBTN_4_train.shape[0], X_BBTN_4_train.shape[1], 1))\n",
        "model_BBTN_4 = Sequential()\n",
        "model_BBTN_4.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBTN_4_train.shape[1], 1)))\n",
        "model_BBTN_4.add(Dropout(0.2))\n",
        "model_BBTN_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_4.add(Dropout(0.2))\n",
        "model_BBTN_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_4.add(Dropout(0.2))\n",
        "model_BBTN_4.add(LSTM(units=50))\n",
        "model_BBTN_4.add(Dropout(0.2))\n",
        "model_BBTN_4.add(Dense(units=1))\n",
        "model_BBTN_4.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBTN_4.fit(X_BBTN_4_train,y_BBTN_4_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BUMI\n",
        "BUMI_4 = yf.download(\"BUMI.JK\", start=\"2022-03-10\", end=\"2022-09-10\")\n",
        "BUMI_4.insert(4,\"Return\", BUMI_4['Close'].pct_change())\n",
        "BUMI_4 = BUMI_4.dropna()\n",
        "BUMI_4_test = yf.download(\"BUMI.JK\", start=\"2022-09-09\", end=\"2022-10-10\")\n",
        "BUMI_4_test.insert(4,\"Return\", BUMI_4_test['Close'].pct_change())\n",
        "BUMI_4_test = BUMI_4_test.dropna()\n",
        "training_BUMI_4 = BUMI_4.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BUMI_4_scaled = sc.fit_transform(training_BUMI_4)\n",
        "X_BUMI_4_train = []\n",
        "y_BUMI_4_train = []\n",
        "for i in range(days_period, len(BUMI_4)-1):\n",
        "    X_BUMI_4_train.append(training_BUMI_4_scaled[i-days_period:i, 0])\n",
        "    y_BUMI_4_train.append(training_BUMI_4_scaled[i, 0])\n",
        "X_BUMI_4_train, y_BUMI_4_train = np.array(X_BUMI_4_train), np.array(y_BUMI_4_train)\n",
        "X_BUMI_4_train = np.reshape(X_BUMI_4_train, (X_BUMI_4_train.shape[0], X_BUMI_4_train.shape[1], 1))\n",
        "model_BUMI_4 = Sequential()\n",
        "model_BUMI_4.add(LSTM(units=50,return_sequences=True,input_shape=(X_BUMI_4_train.shape[1], 1)))\n",
        "model_BUMI_4.add(Dropout(0.2))\n",
        "model_BUMI_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_4.add(Dropout(0.2))\n",
        "model_BUMI_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_4.add(Dropout(0.2))\n",
        "model_BUMI_4.add(LSTM(units=50))\n",
        "model_BUMI_4.add(Dropout(0.2))\n",
        "model_BUMI_4.add(Dense(units=1))\n",
        "model_BUMI_4.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BUMI_4.fit(X_BUMI_4_train,y_BUMI_4_train,epochs=10,batch_size=16)\n",
        "\n",
        "# MFIN\n",
        "MFIN_4 = yf.download(\"MFIN.JK\", start=\"2022-03-10\", end=\"2022-09-10\")\n",
        "MFIN_4.insert(4,\"Return\", MFIN_4['Close'].pct_change())\n",
        "MFIN_4 = MFIN_4.dropna()\n",
        "MFIN_4_test = yf.download(\"MFIN.JK\", start=\"2022-09-09\", end=\"2022-10-10\")\n",
        "MFIN_4_test.insert(4,\"Return\", MFIN_4_test['Close'].pct_change())\n",
        "MFIN_4_test = MFIN_4_test.dropna()\n",
        "training_MFIN_4 = MFIN_4.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_MFIN_4_scaled = sc.fit_transform(training_MFIN_4)\n",
        "X_MFIN_4_train = []\n",
        "y_MFIN_4_train = []\n",
        "for i in range(days_period, len(MFIN_4)-1):\n",
        "    X_MFIN_4_train.append(training_MFIN_4_scaled[i-days_period:i, 0])\n",
        "    y_MFIN_4_train.append(training_MFIN_4_scaled[i, 0])\n",
        "X_MFIN_4_train, y_MFIN_4_train = np.array(X_MFIN_4_train), np.array(y_MFIN_4_train)\n",
        "X_MFIN_4_train = np.reshape(X_MFIN_4_train, (X_MFIN_4_train.shape[0], X_MFIN_4_train.shape[1], 1))\n",
        "model_MFIN_4 = Sequential()\n",
        "model_MFIN_4.add(LSTM(units=50,return_sequences=True,input_shape=(X_MFIN_4_train.shape[1], 1)))\n",
        "model_MFIN_4.add(Dropout(0.2))\n",
        "model_MFIN_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_4.add(Dropout(0.2))\n",
        "model_MFIN_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_4.add(Dropout(0.2))\n",
        "model_MFIN_4.add(LSTM(units=50))\n",
        "model_MFIN_4.add(Dropout(0.2))\n",
        "model_MFIN_4.add(Dense(units=1))\n",
        "model_MFIN_4.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_MFIN_4.fit(X_MFIN_4_train,y_MFIN_4_train,epochs=10,batch_size=16)\n",
        "\n",
        "# EXCL\n",
        "EXCL_4 = yf.download(\"EXCL.JK\", start=\"2022-03-10\", end=\"2022-09-10\")\n",
        "EXCL_4.insert(4,\"Return\", EXCL_4['Close'].pct_change())\n",
        "EXCL_4 = EXCL_4.dropna()\n",
        "EXCL_4_test = yf.download(\"EXCL.JK\", start=\"2022-09-09\", end=\"2022-10-10\")\n",
        "EXCL_4_test.insert(4,\"Return\", EXCL_4_test['Close'].pct_change())\n",
        "EXCL_4_test = EXCL_4_test.dropna()\n",
        "training_EXCL_4 = EXCL_4.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_EXCL_4_scaled = sc.fit_transform(training_EXCL_4)\n",
        "X_EXCL_4_train = []\n",
        "y_EXCL_4_train = []\n",
        "for i in range(days_period, len(EXCL_4)-1):\n",
        "    X_EXCL_4_train.append(training_EXCL_4_scaled[i-days_period:i, 0])\n",
        "    y_EXCL_4_train.append(training_EXCL_4_scaled[i, 0])\n",
        "X_EXCL_4_train, y_EXCL_4_train = np.array(X_EXCL_4_train), np.array(y_EXCL_4_train)\n",
        "X_EXCL_4_train = np.reshape(X_EXCL_4_train, (X_EXCL_4_train.shape[0], X_EXCL_4_train.shape[1], 1))\n",
        "model_EXCL_4 = Sequential()\n",
        "model_EXCL_4.add(LSTM(units=50,return_sequences=True,input_shape=(X_EXCL_4_train.shape[1], 1)))\n",
        "model_EXCL_4.add(Dropout(0.2))\n",
        "model_EXCL_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_4.add(Dropout(0.2))\n",
        "model_EXCL_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_4.add(Dropout(0.2))\n",
        "model_EXCL_4.add(LSTM(units=50))\n",
        "model_EXCL_4.add(Dropout(0.2))\n",
        "model_EXCL_4.add(Dense(units=1))\n",
        "model_EXCL_4.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_EXCL_4.fit(X_EXCL_4_train,y_EXCL_4_train,epochs=10,batch_size=16)\n",
        "\n",
        "# PGAS\n",
        "PGAS_4 = yf.download(\"PGAS.JK\", start=\"2022-03-10\", end=\"2022-09-10\")\n",
        "PGAS_4.insert(4,\"Return\", PGAS_4['Close'].pct_change())\n",
        "PGAS_4 = PGAS_4.dropna()\n",
        "PGAS_4_test = yf.download(\"PGAS.JK\", start=\"2022-09-09\", end=\"2022-10-10\")\n",
        "PGAS_4_test.insert(4,\"Return\", PGAS_4_test['Close'].pct_change())\n",
        "PGAS_4_test = PGAS_4_test.dropna()\n",
        "training_PGAS_4 = PGAS_4.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_PGAS_4_scaled = sc.fit_transform(training_PGAS_4)\n",
        "X_PGAS_4_train = []\n",
        "y_PGAS_4_train = []\n",
        "for i in range(days_period, len(PGAS_4)-1):\n",
        "    X_PGAS_4_train.append(training_PGAS_4_scaled[i-days_period:i, 0])\n",
        "    y_PGAS_4_train.append(training_PGAS_4_scaled[i, 0])\n",
        "X_PGAS_4_train, y_PGAS_4_train = np.array(X_PGAS_4_train), np.array(y_PGAS_4_train)\n",
        "X_PGAS_4_train = np.reshape(X_PGAS_4_train, (X_PGAS_4_train.shape[0], X_PGAS_4_train.shape[1], 1))\n",
        "model_PGAS_4 = Sequential()\n",
        "model_PGAS_4.add(LSTM(units=50,return_sequences=True,input_shape=(X_PGAS_4_train.shape[1], 1)))\n",
        "model_PGAS_4.add(Dropout(0.2))\n",
        "model_PGAS_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_4.add(Dropout(0.2))\n",
        "model_PGAS_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_4.add(Dropout(0.2))\n",
        "model_PGAS_4.add(LSTM(units=50))\n",
        "model_PGAS_4.add(Dropout(0.2))\n",
        "model_PGAS_4.add(Dense(units=1))\n",
        "model_PGAS_4.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_PGAS_4.fit(X_PGAS_4_train,y_PGAS_4_train,epochs=10,batch_size=16)\n",
        "\n",
        "# TLKM\n",
        "TLKM_4 = yf.download(\"TLKM.JK\", start=\"2022-03-10\", end=\"2022-09-10\")\n",
        "TLKM_4.insert(4,\"Return\", TLKM_4['Close'].pct_change())\n",
        "TLKM_4 = TLKM_4.dropna()\n",
        "TLKM_4_test = yf.download(\"TLKM.JK\", start=\"2022-09-09\", end=\"2022-10-10\")\n",
        "TLKM_4_test.insert(4,\"Return\", TLKM_4_test['Close'].pct_change())\n",
        "TLKM_4_test = TLKM_4_test.dropna()\n",
        "training_TLKM_4 = TLKM_4.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_TLKM_4_scaled = sc.fit_transform(training_TLKM_4)\n",
        "X_TLKM_4_train = []\n",
        "y_TLKM_4_train = []\n",
        "for i in range(days_period, len(TLKM_4)-1):\n",
        "    X_TLKM_4_train.append(training_TLKM_4_scaled[i-days_period:i, 0])\n",
        "    y_TLKM_4_train.append(training_TLKM_4_scaled[i, 0])\n",
        "X_TLKM_4_train, y_TLKM_4_train = np.array(X_TLKM_4_train), np.array(y_TLKM_4_train)\n",
        "X_TLKM_4_train = np.reshape(X_TLKM_4_train, (X_TLKM_4_train.shape[0], X_TLKM_4_train.shape[1], 1))\n",
        "model_TLKM_4 = Sequential()\n",
        "model_TLKM_4.add(LSTM(units=50,return_sequences=True,input_shape=(X_TLKM_4_train.shape[1], 1)))\n",
        "model_TLKM_4.add(Dropout(0.2))\n",
        "model_TLKM_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_4.add(Dropout(0.2))\n",
        "model_TLKM_4.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_4.add(Dropout(0.2))\n",
        "model_TLKM_4.add(LSTM(units=50))\n",
        "model_TLKM_4.add(Dropout(0.2))\n",
        "model_TLKM_4.add(Dense(units=1))\n",
        "model_TLKM_4.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_TLKM_4.fit(X_TLKM_4_train,y_TLKM_4_train,epochs=10,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tBr18tCG0Fn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b26c1e9-86e7-4b96-c58b-f3527d9799ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        }
      ],
      "source": [
        "# ADRO\n",
        "real_ADRO_4_return = ADRO_4_test.iloc[:, 4:5].values\n",
        "real_ADRO_4_return = real_ADRO_4_return[:days_predict]\n",
        "ADRO_4_total = ADRO_4['Close'].copy(deep=True)\n",
        "inputs_ADRO_4 = ADRO_4_total[len(ADRO_4) - days_period: len(ADRO_4)].values\n",
        "inputs_ADRO_4 = inputs_ADRO_4.reshape(-1,1)\n",
        "inputs_ADRO_4 = sc.transform(inputs_ADRO_4)\n",
        "predicted_ADRO_4_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ADRO_4_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ADRO_4_test.append(inputs_ADRO_4[i:i+days_period, 0])\n",
        "  X_ADRO_4_test = np.array(X_ADRO_4_test)\n",
        "  X_ADRO_4_test = np.reshape(X_ADRO_4_test, (X_ADRO_4_test.shape[0], X_ADRO_4_test.shape[1], 1))\n",
        "  predicted_ADRO_4_return[j] = model_ADRO_4.predict(X_ADRO_4_test)\n",
        "  inputs_ADRO_4 += (predicted_ADRO_4_return[j])\n",
        "  inputs_ADRO_4 = inputs_ADRO_4.reshape(-1,1)\n",
        "\n",
        "# ASII\n",
        "real_ASII_4_return = ASII_4_test.iloc[:, 4:5].values\n",
        "real_ASII_4_return = real_ASII_4_return[:days_predict]\n",
        "ASII_4_total = ASII_4['Close'].copy(deep=True)\n",
        "inputs_ASII_4 = ASII_4_total[len(ASII_4) - days_period: len(ASII_4)].values\n",
        "inputs_ASII_4 = inputs_ASII_4.reshape(-1,1)\n",
        "inputs_ASII_4 = sc.transform(inputs_ASII_4)\n",
        "predicted_ASII_4_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ASII_4_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ASII_4_test.append(inputs_ASII_4[i:i+days_period, 0])\n",
        "  X_ASII_4_test = np.array(X_ASII_4_test)\n",
        "  X_ASII_4_test = np.reshape(X_ASII_4_test, (X_ASII_4_test.shape[0], X_ASII_4_test.shape[1], 1))\n",
        "  predicted_ASII_4_return[j] = model_ASII_4.predict(X_ASII_4_test)\n",
        "  inputs_ASII_4 += (predicted_ASII_4_return[j])\n",
        "  inputs_ASII_4 = inputs_ASII_4.reshape(-1,1)\n",
        "\n",
        "# BMRI\n",
        "real_BMRI_4_return = BMRI_4_test.iloc[:, 4:5].values\n",
        "real_BMRI_4_return = real_BMRI_4_return[:days_predict]\n",
        "BMRI_4_total = BMRI_4['Close'].copy(deep=True)\n",
        "inputs_BMRI_4 = BMRI_4_total[len(BMRI_4) - days_period: len(BMRI_4)].values\n",
        "inputs_BMRI_4 = inputs_BMRI_4.reshape(-1,1)\n",
        "inputs_BMRI_4 = sc.transform(inputs_BMRI_4)\n",
        "predicted_BMRI_4_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BMRI_4_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BMRI_4_test.append(inputs_BMRI_4[i:i+days_period, 0])\n",
        "  X_BMRI_4_test = np.array(X_BMRI_4_test)\n",
        "  X_BMRI_4_test = np.reshape(X_BMRI_4_test, (X_BMRI_4_test.shape[0], X_BMRI_4_test.shape[1], 1))\n",
        "  predicted_BMRI_4_return[j] = model_BMRI_4.predict(X_BMRI_4_test)\n",
        "  inputs_BMRI_4 += (predicted_BMRI_4_return[j])\n",
        "  inputs_BMRI_4 = inputs_BMRI_4.reshape(-1,1)\n",
        "\n",
        "# BBRI\n",
        "real_BBRI_4_return = BBRI_4_test.iloc[:, 4:5].values\n",
        "real_BBRI_4_return = real_BBRI_4_return[:days_predict]\n",
        "BBRI_4_total = BBRI_4['Close'].copy(deep=True)\n",
        "inputs_BBRI_4 = BBRI_4_total[len(BBRI_4) - days_period: len(BBRI_4)].values\n",
        "inputs_BBRI_4 = inputs_BBRI_4.reshape(-1,1)\n",
        "inputs_BBRI_4 = sc.transform(inputs_BBRI_4)\n",
        "predicted_BBRI_4_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBRI_4_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBRI_4_test.append(inputs_BBRI_4[i:i+days_period, 0])\n",
        "  X_BBRI_4_test = np.array(X_BBRI_4_test)\n",
        "  X_BBRI_4_test = np.reshape(X_BBRI_4_test, (X_BBRI_4_test.shape[0], X_BBRI_4_test.shape[1], 1))\n",
        "  predicted_BBRI_4_return[j] = model_BBRI_4.predict(X_BBRI_4_test)\n",
        "  inputs_BBRI_4 += (predicted_BBRI_4_return[j])\n",
        "  inputs_BBRI_4 = inputs_BBRI_4.reshape(-1,1)\n",
        "\n",
        "# BBTN\n",
        "real_BBTN_4_return = BBTN_4_test.iloc[:, 4:5].values\n",
        "real_BBTN_4_return = real_BBTN_4_return[:days_predict]\n",
        "BBTN_4_total = BBTN_4['Close'].copy(deep=True)\n",
        "inputs_BBTN_4 = BBTN_4_total[len(BBTN_4) - days_period: len(BBTN_4)].values\n",
        "inputs_BBTN_4 = inputs_BBTN_4.reshape(-1,1)\n",
        "inputs_BBTN_4 = sc.transform(inputs_BBTN_4)\n",
        "predicted_BBTN_4_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBTN_4_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBTN_4_test.append(inputs_BBTN_4[i:i+days_period, 0])\n",
        "  X_BBTN_4_test = np.array(X_BBTN_4_test)\n",
        "  X_BBTN_4_test = np.reshape(X_BBTN_4_test, (X_BBTN_4_test.shape[0], X_BBTN_4_test.shape[1], 1))\n",
        "  predicted_BBTN_4_return[j] = model_BBTN_4.predict(X_BBTN_4_test)\n",
        "  inputs_BBTN_4 += (predicted_BBTN_4_return[j])\n",
        "  inputs_BBTN_4 = inputs_BBTN_4.reshape(-1,1)\n",
        "\n",
        "# BUMI\n",
        "real_BUMI_4_return = BUMI_4_test.iloc[:, 4:5].values\n",
        "real_BUMI_4_return = real_BUMI_4_return[:days_predict]\n",
        "BUMI_4_total = BUMI_4['Close'].copy(deep=True)\n",
        "inputs_BUMI_4 = BUMI_4_total[len(BUMI_4) - days_period: len(BUMI_4)].values\n",
        "inputs_BUMI_4 = inputs_BUMI_4.reshape(-1,1)\n",
        "inputs_BUMI_4 = sc.transform(inputs_BUMI_4)\n",
        "predicted_BUMI_4_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BUMI_4_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BUMI_4_test.append(inputs_BUMI_4[i:i+days_period, 0])\n",
        "  X_BUMI_4_test = np.array(X_BUMI_4_test)\n",
        "  X_BUMI_4_test = np.reshape(X_BUMI_4_test, (X_BUMI_4_test.shape[0], X_BUMI_4_test.shape[1], 1))\n",
        "  predicted_BUMI_4_return[j] = model_BUMI_4.predict(X_BUMI_4_test)\n",
        "  inputs_BUMI_4 += (predicted_BUMI_4_return[j])\n",
        "  inputs_BUMI_4 = inputs_BUMI_4.reshape(-1,1)\n",
        "\n",
        "# MFIN\n",
        "real_MFIN_4_return = MFIN_4_test.iloc[:, 4:5].values\n",
        "real_MFIN_4_return = real_MFIN_4_return[:days_predict]\n",
        "MFIN_4_total = MFIN_4['Close'].copy(deep=True)\n",
        "inputs_MFIN_4 = MFIN_4_total[len(MFIN_4) - days_period: len(MFIN_4)].values\n",
        "inputs_MFIN_4 = inputs_MFIN_4.reshape(-1,1)\n",
        "inputs_MFIN_4 = sc.transform(inputs_MFIN_4)\n",
        "predicted_MFIN_4_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_MFIN_4_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_MFIN_4_test.append(inputs_MFIN_4[i:i+days_period, 0])\n",
        "  X_MFIN_4_test = np.array(X_MFIN_4_test)\n",
        "  X_MFIN_4_test = np.reshape(X_MFIN_4_test, (X_MFIN_4_test.shape[0], X_MFIN_4_test.shape[1], 1))\n",
        "  predicted_MFIN_4_return[j] = model_MFIN_4.predict(X_MFIN_4_test)\n",
        "  inputs_MFIN_4 += (predicted_MFIN_4_return[j])\n",
        "  inputs_MFIN_4 = inputs_MFIN_4.reshape(-1,1)\n",
        "\n",
        "# EXCL\n",
        "real_EXCL_4_return = EXCL_4_test.iloc[:, 4:5].values\n",
        "real_EXCL_4_return = real_EXCL_4_return[:days_predict]\n",
        "EXCL_4_total = EXCL_4['Close'].copy(deep=True)\n",
        "inputs_EXCL_4 = EXCL_4_total[len(EXCL_4) - days_period: len(EXCL_4)].values\n",
        "inputs_EXCL_4 = inputs_EXCL_4.reshape(-1,1)\n",
        "inputs_EXCL_4 = sc.transform(inputs_EXCL_4)\n",
        "predicted_EXCL_4_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_EXCL_4_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_EXCL_4_test.append(inputs_EXCL_4[i:i+days_period, 0])\n",
        "  X_EXCL_4_test = np.array(X_EXCL_4_test)\n",
        "  X_EXCL_4_test = np.reshape(X_EXCL_4_test, (X_EXCL_4_test.shape[0], X_EXCL_4_test.shape[1], 1))\n",
        "  predicted_EXCL_4_return[j] = model_EXCL_4.predict(X_EXCL_4_test)\n",
        "  inputs_EXCL_4 += (predicted_EXCL_4_return[j])\n",
        "  inputs_EXCL_4 = inputs_EXCL_4.reshape(-1,1)\n",
        "\n",
        "# PGAS\n",
        "real_PGAS_4_return = PGAS_4_test.iloc[:, 4:5].values\n",
        "real_PGAS_4_return = real_PGAS_4_return[:days_predict]\n",
        "PGAS_4_total = PGAS_4['Close'].copy(deep=True)\n",
        "inputs_PGAS_4 = PGAS_4_total[len(PGAS_4) - days_period: len(PGAS_4)].values\n",
        "inputs_PGAS_4 = inputs_PGAS_4.reshape(-1,1)\n",
        "inputs_PGAS_4 = sc.transform(inputs_PGAS_4)\n",
        "predicted_PGAS_4_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_PGAS_4_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_PGAS_4_test.append(inputs_PGAS_4[i:i+days_period, 0])\n",
        "  X_PGAS_4_test = np.array(X_PGAS_4_test)\n",
        "  X_PGAS_4_test = np.reshape(X_PGAS_4_test, (X_PGAS_4_test.shape[0], X_PGAS_4_test.shape[1], 1))\n",
        "  predicted_PGAS_4_return[j] = model_PGAS_4.predict(X_PGAS_4_test)\n",
        "  inputs_PGAS_4 += (predicted_PGAS_4_return[j])\n",
        "  inputs_PGAS_4 = inputs_PGAS_4.reshape(-1,1)\n",
        "\n",
        "# TLKM\n",
        "real_TLKM_4_return = TLKM_4_test.iloc[:, 4:5].values\n",
        "real_TLKM_4_return = real_TLKM_4_return[:days_predict]\n",
        "TLKM_4_total = TLKM_4['Close'].copy(deep=True)\n",
        "inputs_TLKM_4 = TLKM_4_total[len(TLKM_4) - days_period: len(TLKM_4)].values\n",
        "inputs_TLKM_4 = inputs_TLKM_4.reshape(-1,1)\n",
        "inputs_TLKM_4 = sc.transform(inputs_TLKM_4)\n",
        "predicted_TLKM_4_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_TLKM_4_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_TLKM_4_test.append(inputs_TLKM_4[i:i+days_period, 0])\n",
        "  X_TLKM_4_test = np.array(X_TLKM_4_test)\n",
        "  X_TLKM_4_test = np.reshape(X_TLKM_4_test, (X_TLKM_4_test.shape[0], X_TLKM_4_test.shape[1], 1))\n",
        "  predicted_TLKM_4_return[j] = model_TLKM_4.predict(X_TLKM_4_test)\n",
        "  inputs_TLKM_4 += (predicted_TLKM_4_return[j])\n",
        "  inputs_TLKM_4 = inputs_TLKM_4.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ulUXf4RG0Fo"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "predicted_ADRO_4_return = np.squeeze(np.asarray(predicted_ADRO_4_return))\n",
        "predicted_ADRO_4_return = predicted_ADRO_4_return.reshape(-1,1)\n",
        "predicted_ADRO_4_return = sc.inverse_transform(predicted_ADRO_4_return)\n",
        "# ASII\n",
        "predicted_ASII_4_return = np.squeeze(np.asarray(predicted_ASII_4_return))\n",
        "predicted_ASII_4_return = predicted_ASII_4_return.reshape(-1,1)\n",
        "predicted_ASII_4_return = sc.inverse_transform(predicted_ASII_4_return)\n",
        "# BMRI\n",
        "predicted_BMRI_4_return = np.squeeze(np.asarray(predicted_BMRI_4_return))\n",
        "predicted_BMRI_4_return = predicted_BMRI_4_return.reshape(-1,1)\n",
        "predicted_BMRI_4_return = sc.inverse_transform(predicted_BMRI_4_return)\n",
        "# BBRI\n",
        "predicted_BBRI_4_return = np.squeeze(np.asarray(predicted_BBRI_4_return))\n",
        "predicted_BBRI_4_return = predicted_BBRI_4_return.reshape(-1,1)\n",
        "predicted_BBRI_4_return = sc.inverse_transform(predicted_BBRI_4_return)\n",
        "# BBTN\n",
        "predicted_BBTN_4_return = np.squeeze(np.asarray(predicted_BBTN_4_return))\n",
        "predicted_BBTN_4_return = predicted_BBTN_4_return.reshape(-1,1)\n",
        "predicted_BBTN_4_return = sc.inverse_transform(predicted_BBTN_4_return)\n",
        "# BUMI\n",
        "predicted_BUMI_4_return = np.squeeze(np.asarray(predicted_BUMI_4_return))\n",
        "predicted_BUMI_4_return = predicted_BUMI_4_return.reshape(-1,1)\n",
        "predicted_BUMI_4_return = sc.inverse_transform(predicted_BUMI_4_return)\n",
        "# MFIN\n",
        "predicted_MFIN_4_return = np.squeeze(np.asarray(predicted_MFIN_4_return))\n",
        "predicted_MFIN_4_return = predicted_MFIN_4_return.reshape(-1,1)\n",
        "predicted_MFIN_4_return = sc.inverse_transform(predicted_MFIN_4_return)\n",
        "# EXCL\n",
        "predicted_EXCL_4_return = np.squeeze(np.asarray(predicted_EXCL_4_return))\n",
        "predicted_EXCL_4_return = predicted_EXCL_4_return.reshape(-1,1)\n",
        "predicted_EXCL_4_return = sc.inverse_transform(predicted_EXCL_4_return)\n",
        "# PGAS\n",
        "predicted_PGAS_4_return = np.squeeze(np.asarray(predicted_PGAS_4_return))\n",
        "predicted_PGAS_4_return = predicted_PGAS_4_return.reshape(-1,1)\n",
        "predicted_PGAS_4_return = sc.inverse_transform(predicted_PGAS_4_return)\n",
        "# TLKM\n",
        "predicted_TLKM_4_return = np.squeeze(np.asarray(predicted_TLKM_4_return))\n",
        "predicted_TLKM_4_return = predicted_TLKM_4_return.reshape(-1,1)\n",
        "predicted_TLKM_4_return = sc.inverse_transform(predicted_TLKM_4_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riiCsVhqG0Fp"
      },
      "outputs": [],
      "source": [
        "predicted4 = pd.DataFrame(predicted_ADRO_4_return)\n",
        "predicted4.rename(columns={0:'ADRO'}, inplace=True)\n",
        "predicted4.insert(1,\"ASII\", predicted_ASII_4_return)\n",
        "predicted4.insert(2,\"BBRI\", predicted_BBRI_4_return)\n",
        "predicted4.insert(3,\"BBTN\", predicted_BBTN_4_return)\n",
        "predicted4.insert(4,\"BMRI\", predicted_BMRI_4_return)\n",
        "predicted4.insert(5,\"BUMI\", predicted_BUMI_4_return)\n",
        "predicted4.insert(6,\"EXCL\", predicted_EXCL_4_return)\n",
        "predicted4.insert(7,\"MFIN\", predicted_MFIN_4_return)\n",
        "predicted4.insert(8,\"PGAS\", predicted_PGAS_4_return)\n",
        "predicted4.insert(9,\"TLKM\", predicted_TLKM_4_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "yfIvtNL3P7bz",
        "outputId": "608217f9-44f4-42dc-eae6-030fa5f081bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADRO      ASII      BBRI      BBTN      BMRI      BUMI      EXCL  \\\n",
              "0  0.004435  0.034459  0.032008  0.016485  0.038098  0.013251  0.015135   \n",
              "1  0.003262  0.033558  0.030952  0.015177  0.037058  0.012349  0.013801   \n",
              "2  0.001894  0.032428  0.029663  0.013631  0.035791  0.011229  0.012235   \n",
              "3  0.000305  0.031021  0.028094  0.011817  0.034251  0.009846  0.010405   \n",
              "4 -0.001533  0.029276  0.026192  0.009696  0.032383  0.008150  0.008277   \n",
              "5 -0.003647  0.027124  0.023896  0.007222  0.030123  0.006078  0.005815   \n",
              "6 -0.006066  0.024486  0.021140  0.004362  0.027398  0.003572  0.002986   \n",
              "7 -0.008815  0.021277  0.017850  0.001089  0.024126  0.000571 -0.000244   \n",
              "8 -0.011915  0.017406  0.013955 -0.002645  0.020221 -0.002981 -0.003902   \n",
              "9 -0.015381  0.012781  0.009384 -0.006858  0.015593 -0.007129 -0.008008   \n",
              "\n",
              "       MFIN      PGAS      TLKM  \n",
              "0 -0.017194 -0.006528  0.062978  \n",
              "1 -0.017694 -0.006998  0.061941  \n",
              "2 -0.018297 -0.007596  0.060643  \n",
              "3 -0.019023 -0.008348  0.059022  \n",
              "4 -0.019892 -0.009288  0.057006  \n",
              "5 -0.020933 -0.010452  0.054509  \n",
              "6 -0.022174 -0.011880  0.051432  \n",
              "7 -0.023647 -0.013615  0.047663  \n",
              "8 -0.025385 -0.015701  0.043081  \n",
              "9 -0.027419 -0.018181  0.037560  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1754646-e609-43fe-bd27-dd7a5862fde2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADRO</th>\n",
              "      <th>ASII</th>\n",
              "      <th>BBRI</th>\n",
              "      <th>BBTN</th>\n",
              "      <th>BMRI</th>\n",
              "      <th>BUMI</th>\n",
              "      <th>EXCL</th>\n",
              "      <th>MFIN</th>\n",
              "      <th>PGAS</th>\n",
              "      <th>TLKM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.004435</td>\n",
              "      <td>0.034459</td>\n",
              "      <td>0.032008</td>\n",
              "      <td>0.016485</td>\n",
              "      <td>0.038098</td>\n",
              "      <td>0.013251</td>\n",
              "      <td>0.015135</td>\n",
              "      <td>-0.017194</td>\n",
              "      <td>-0.006528</td>\n",
              "      <td>0.062978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003262</td>\n",
              "      <td>0.033558</td>\n",
              "      <td>0.030952</td>\n",
              "      <td>0.015177</td>\n",
              "      <td>0.037058</td>\n",
              "      <td>0.012349</td>\n",
              "      <td>0.013801</td>\n",
              "      <td>-0.017694</td>\n",
              "      <td>-0.006998</td>\n",
              "      <td>0.061941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001894</td>\n",
              "      <td>0.032428</td>\n",
              "      <td>0.029663</td>\n",
              "      <td>0.013631</td>\n",
              "      <td>0.035791</td>\n",
              "      <td>0.011229</td>\n",
              "      <td>0.012235</td>\n",
              "      <td>-0.018297</td>\n",
              "      <td>-0.007596</td>\n",
              "      <td>0.060643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.031021</td>\n",
              "      <td>0.028094</td>\n",
              "      <td>0.011817</td>\n",
              "      <td>0.034251</td>\n",
              "      <td>0.009846</td>\n",
              "      <td>0.010405</td>\n",
              "      <td>-0.019023</td>\n",
              "      <td>-0.008348</td>\n",
              "      <td>0.059022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.001533</td>\n",
              "      <td>0.029276</td>\n",
              "      <td>0.026192</td>\n",
              "      <td>0.009696</td>\n",
              "      <td>0.032383</td>\n",
              "      <td>0.008150</td>\n",
              "      <td>0.008277</td>\n",
              "      <td>-0.019892</td>\n",
              "      <td>-0.009288</td>\n",
              "      <td>0.057006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.003647</td>\n",
              "      <td>0.027124</td>\n",
              "      <td>0.023896</td>\n",
              "      <td>0.007222</td>\n",
              "      <td>0.030123</td>\n",
              "      <td>0.006078</td>\n",
              "      <td>0.005815</td>\n",
              "      <td>-0.020933</td>\n",
              "      <td>-0.010452</td>\n",
              "      <td>0.054509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.006066</td>\n",
              "      <td>0.024486</td>\n",
              "      <td>0.021140</td>\n",
              "      <td>0.004362</td>\n",
              "      <td>0.027398</td>\n",
              "      <td>0.003572</td>\n",
              "      <td>0.002986</td>\n",
              "      <td>-0.022174</td>\n",
              "      <td>-0.011880</td>\n",
              "      <td>0.051432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.008815</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.017850</td>\n",
              "      <td>0.001089</td>\n",
              "      <td>0.024126</td>\n",
              "      <td>0.000571</td>\n",
              "      <td>-0.000244</td>\n",
              "      <td>-0.023647</td>\n",
              "      <td>-0.013615</td>\n",
              "      <td>0.047663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.011915</td>\n",
              "      <td>0.017406</td>\n",
              "      <td>0.013955</td>\n",
              "      <td>-0.002645</td>\n",
              "      <td>0.020221</td>\n",
              "      <td>-0.002981</td>\n",
              "      <td>-0.003902</td>\n",
              "      <td>-0.025385</td>\n",
              "      <td>-0.015701</td>\n",
              "      <td>0.043081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.015381</td>\n",
              "      <td>0.012781</td>\n",
              "      <td>0.009384</td>\n",
              "      <td>-0.006858</td>\n",
              "      <td>0.015593</td>\n",
              "      <td>-0.007129</td>\n",
              "      <td>-0.008008</td>\n",
              "      <td>-0.027419</td>\n",
              "      <td>-0.018181</td>\n",
              "      <td>0.037560</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1754646-e609-43fe-bd27-dd7a5862fde2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1754646-e609-43fe-bd27-dd7a5862fde2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1754646-e609-43fe-bd27-dd7a5862fde2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNrs-XcLcgJ7"
      },
      "source": [
        "## Data Preparation 5\n",
        "1st of January 2018 - 9th of October 2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAHQXNy9G14m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b0c772-e430-468b-eca8-a3787439e29b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 43ms/step - loss: 0.1922\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0587\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0518\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0497\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.0509\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0530\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0526\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0520\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 0.0544\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0521\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 8s 43ms/step - loss: 0.1498\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0302\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0245\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0261\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 61ms/step - loss: 0.0272\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0225\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 0.0214\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 0.0194\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 0.0246\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 0.0231\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 8s 44ms/step - loss: 0.1170\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0334\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0271\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0119\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 72ms/step - loss: 0.0180\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 0.0133\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0146\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.0168\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 0.0192\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 0.0144\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 8s 40ms/step - loss: 0.2025\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0449\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0372\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0223\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 0.0306\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 0.0207\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 0.0202\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0201\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 0.0210\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.0213\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 14s 43ms/step - loss: 0.2019\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0393\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0305\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0205\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0244\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0231\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0253\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0201\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0240\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0285\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 44ms/step - loss: 0.0579\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0346\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0355\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0359\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0333\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0341\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0328\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0322\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0328\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0316\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 44ms/step - loss: 0.1210\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0221\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0176\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0169\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0160\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0182\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0154\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0210\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0194\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0175\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 42ms/step - loss: 0.0971\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0497\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0447\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0333\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0339\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0303\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0294\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0323\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0300\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0329\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 11s 40ms/step - loss: 0.0966\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0493\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0391\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0343\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0401\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0384\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0376\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0352\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0376\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0385\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 44ms/step - loss: 0.2093\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0368\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0328\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0282\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0276\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0327\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0235\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0259\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0280\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0258\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1d1123a710>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Period parameters\n",
        "days_period = 20\n",
        "days_predict = 10\n",
        "\n",
        "# ADRO\n",
        "ADRO_5 = yf.download(\"ADRO.JK\", start=\"2022-04-10\", end=\"2022-10-10\")\n",
        "ADRO_5.insert(4,\"Return\", ADRO_5['Close'].pct_change())\n",
        "ADRO_5 = ADRO_5.dropna()\n",
        "ADRO_5_test = yf.download(\"ADRO.JK\", start=\"2022-10-09\", end=\"2022-11-10\")\n",
        "ADRO_5_test.insert(4,\"Return\", ADRO_5_test['Close'].pct_change())\n",
        "ADRO_5_test = ADRO_5_test.dropna()\n",
        "training_ADRO_5 = ADRO_5.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ADRO_5_scaled = sc.fit_transform(training_ADRO_5)\n",
        "X_ADRO_5_train = []\n",
        "y_ADRO_5_train = []\n",
        "for i in range(days_period, len(ADRO_5)-1):\n",
        "    X_ADRO_5_train.append(training_ADRO_5_scaled[i-days_period:i, 0])\n",
        "    y_ADRO_5_train.append(training_ADRO_5_scaled[i, 0])\n",
        "X_ADRO_5_train, y_ADRO_5_train = np.array(X_ADRO_5_train), np.array(y_ADRO_5_train)\n",
        "X_ADRO_5_train = np.reshape(X_ADRO_5_train, (X_ADRO_5_train.shape[0], X_ADRO_5_train.shape[1], 1))\n",
        "model_ADRO_5 = Sequential()\n",
        "model_ADRO_5.add(LSTM(units=50,return_sequences=True,input_shape=(X_ADRO_5_train.shape[1], 1)))\n",
        "model_ADRO_5.add(Dropout(0.2))\n",
        "model_ADRO_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_5.add(Dropout(0.2))\n",
        "model_ADRO_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_5.add(Dropout(0.2))\n",
        "model_ADRO_5.add(LSTM(units=50))\n",
        "model_ADRO_5.add(Dropout(0.2))\n",
        "model_ADRO_5.add(Dense(units=1))\n",
        "model_ADRO_5.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ADRO_5.fit(X_ADRO_5_train,y_ADRO_5_train,epochs=10,batch_size=16)\n",
        "\n",
        "# ASII\n",
        "ASII_5 = yf.download(\"ASII.JK\", start=\"2022-04-10\", end=\"2022-10-10\")\n",
        "ASII_5.insert(4,\"Return\", ASII_5['Close'].pct_change())\n",
        "ASII_5 = ASII_5.dropna()\n",
        "ASII_5_test = yf.download(\"ASII.JK\", start=\"2022-10-09\", end=\"2022-11-10\")\n",
        "ASII_5_test.insert(4,\"Return\", ASII_5_test['Close'].pct_change())\n",
        "ASII_5_test = ASII_5_test.dropna()\n",
        "training_ASII_5 = ASII_5.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ASII_5_scaled = sc.fit_transform(training_ASII_5)\n",
        "X_ASII_5_train = []\n",
        "y_ASII_5_train = []\n",
        "for i in range(days_period, len(ASII_5)-1):\n",
        "    X_ASII_5_train.append(training_ASII_5_scaled[i-days_period:i, 0])\n",
        "    y_ASII_5_train.append(training_ASII_5_scaled[i, 0])\n",
        "X_ASII_5_train, y_ASII_5_train = np.array(X_ASII_5_train), np.array(y_ASII_5_train)\n",
        "X_ASII_5_train = np.reshape(X_ASII_5_train, (X_ASII_5_train.shape[0], X_ASII_5_train.shape[1], 1))\n",
        "model_ASII_5 = Sequential()\n",
        "model_ASII_5.add(LSTM(units=50,return_sequences=True,input_shape=(X_ASII_5_train.shape[1], 1)))\n",
        "model_ASII_5.add(Dropout(0.2))\n",
        "model_ASII_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_5.add(Dropout(0.2))\n",
        "model_ASII_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_5.add(Dropout(0.2))\n",
        "model_ASII_5.add(LSTM(units=50))\n",
        "model_ASII_5.add(Dropout(0.2))\n",
        "model_ASII_5.add(Dense(units=1))\n",
        "model_ASII_5.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ASII_5.fit(X_ASII_5_train,y_ASII_5_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BMRI\n",
        "BMRI_5 = yf.download(\"BMRI.JK\", start=\"2022-04-10\", end=\"2022-10-10\")\n",
        "BMRI_5.insert(4,\"Return\", BMRI_5['Close'].pct_change())\n",
        "BMRI_5 = BMRI_5.dropna()\n",
        "BMRI_5_test = yf.download(\"BMRI.JK\", start=\"2022-10-09\", end=\"2022-11-10\")\n",
        "BMRI_5_test.insert(4,\"Return\", BMRI_5_test['Close'].pct_change())\n",
        "BMRI_5_test = BMRI_5_test.dropna()\n",
        "training_BMRI_5 = BMRI_5.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BMRI_5_scaled = sc.fit_transform(training_BMRI_5)\n",
        "X_BMRI_5_train = []\n",
        "y_BMRI_5_train = []\n",
        "for i in range(days_period, len(BMRI_5)-1):\n",
        "    X_BMRI_5_train.append(training_BMRI_5_scaled[i-days_period:i, 0])\n",
        "    y_BMRI_5_train.append(training_BMRI_5_scaled[i, 0])\n",
        "X_BMRI_5_train, y_BMRI_5_train = np.array(X_BMRI_5_train), np.array(y_BMRI_5_train)\n",
        "X_BMRI_5_train = np.reshape(X_BMRI_5_train, (X_BMRI_5_train.shape[0], X_BMRI_5_train.shape[1], 1))\n",
        "model_BMRI_5 = Sequential()\n",
        "model_BMRI_5.add(LSTM(units=50,return_sequences=True,input_shape=(X_BMRI_5_train.shape[1], 1)))\n",
        "model_BMRI_5.add(Dropout(0.2))\n",
        "model_BMRI_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_5.add(Dropout(0.2))\n",
        "model_BMRI_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_5.add(Dropout(0.2))\n",
        "model_BMRI_5.add(LSTM(units=50))\n",
        "model_BMRI_5.add(Dropout(0.2))\n",
        "model_BMRI_5.add(Dense(units=1))\n",
        "model_BMRI_5.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BMRI_5.fit(X_BMRI_5_train,y_BMRI_5_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBRI\n",
        "BBRI_5 = yf.download(\"BBRI.JK\", start=\"2022-04-10\", end=\"2022-10-10\")\n",
        "BBRI_5.insert(4,\"Return\", BBRI_5['Close'].pct_change())\n",
        "BBRI_5 = BBRI_5.dropna()\n",
        "BBRI_5_test = yf.download(\"BBRI.JK\", start=\"2022-10-09\", end=\"2022-11-10\")\n",
        "BBRI_5_test.insert(4,\"Return\", BBRI_5_test['Close'].pct_change())\n",
        "BBRI_5_test = BBRI_5_test.dropna()\n",
        "training_BBRI_5 = BBRI_5.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBRI_5_scaled = sc.fit_transform(training_BBRI_5)\n",
        "X_BBRI_5_train = []\n",
        "y_BBRI_5_train = []\n",
        "for i in range(days_period, len(BBRI_5)-1):\n",
        "    X_BBRI_5_train.append(training_BBRI_5_scaled[i-days_period:i, 0])\n",
        "    y_BBRI_5_train.append(training_BBRI_5_scaled[i, 0])\n",
        "X_BBRI_5_train, y_BBRI_5_train = np.array(X_BBRI_5_train), np.array(y_BBRI_5_train)\n",
        "X_BBRI_5_train = np.reshape(X_BBRI_5_train, (X_BBRI_5_train.shape[0], X_BBRI_5_train.shape[1], 1))\n",
        "model_BBRI_5 = Sequential()\n",
        "model_BBRI_5.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBRI_5_train.shape[1], 1)))\n",
        "model_BBRI_5.add(Dropout(0.2))\n",
        "model_BBRI_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_5.add(Dropout(0.2))\n",
        "model_BBRI_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_5.add(Dropout(0.2))\n",
        "model_BBRI_5.add(LSTM(units=50))\n",
        "model_BBRI_5.add(Dropout(0.2))\n",
        "model_BBRI_5.add(Dense(units=1))\n",
        "model_BBRI_5.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBRI_5.fit(X_BBRI_5_train,y_BBRI_5_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBTN\n",
        "BBTN_5 = yf.download(\"BBTN.JK\", start=\"2022-04-10\", end=\"2022-10-10\")\n",
        "BBTN_5.insert(4,\"Return\", BBTN_5['Close'].pct_change())\n",
        "BBTN_5 = BBTN_5.dropna()\n",
        "BBTN_5_test = yf.download(\"BBTN.JK\", start=\"2022-10-09\", end=\"2022-11-10\")\n",
        "BBTN_5_test.insert(4,\"Return\", BBTN_5_test['Close'].pct_change())\n",
        "BBTN_5_test = BBTN_5_test.dropna()\n",
        "training_BBTN_5 = BBTN_5.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBTN_5_scaled = sc.fit_transform(training_BBTN_5)\n",
        "X_BBTN_5_train = []\n",
        "y_BBTN_5_train = []\n",
        "for i in range(days_period, len(BBTN_5)-1):\n",
        "    X_BBTN_5_train.append(training_BBTN_5_scaled[i-days_period:i, 0])\n",
        "    y_BBTN_5_train.append(training_BBTN_5_scaled[i, 0])\n",
        "X_BBTN_5_train, y_BBTN_5_train = np.array(X_BBTN_5_train), np.array(y_BBTN_5_train)\n",
        "X_BBTN_5_train = np.reshape(X_BBTN_5_train, (X_BBTN_5_train.shape[0], X_BBTN_5_train.shape[1], 1))\n",
        "model_BBTN_5 = Sequential()\n",
        "model_BBTN_5.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBTN_5_train.shape[1], 1)))\n",
        "model_BBTN_5.add(Dropout(0.2))\n",
        "model_BBTN_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_5.add(Dropout(0.2))\n",
        "model_BBTN_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_5.add(Dropout(0.2))\n",
        "model_BBTN_5.add(LSTM(units=50))\n",
        "model_BBTN_5.add(Dropout(0.2))\n",
        "model_BBTN_5.add(Dense(units=1))\n",
        "model_BBTN_5.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBTN_5.fit(X_BBTN_5_train,y_BBTN_5_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BUMI\n",
        "BUMI_5 = yf.download(\"BUMI.JK\", start=\"2022-04-10\", end=\"2022-10-10\")\n",
        "BUMI_5.insert(4,\"Return\", BUMI_5['Close'].pct_change())\n",
        "BUMI_5 = BUMI_5.dropna()\n",
        "BUMI_5_test = yf.download(\"BUMI.JK\", start=\"2022-10-09\", end=\"2022-11-10\")\n",
        "BUMI_5_test.insert(4,\"Return\", BUMI_5_test['Close'].pct_change())\n",
        "BUMI_5_test = BUMI_5_test.dropna()\n",
        "training_BUMI_5 = BUMI_5.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BUMI_5_scaled = sc.fit_transform(training_BUMI_5)\n",
        "X_BUMI_5_train = []\n",
        "y_BUMI_5_train = []\n",
        "for i in range(days_period, len(BUMI_5)-1):\n",
        "    X_BUMI_5_train.append(training_BUMI_5_scaled[i-days_period:i, 0])\n",
        "    y_BUMI_5_train.append(training_BUMI_5_scaled[i, 0])\n",
        "X_BUMI_5_train, y_BUMI_5_train = np.array(X_BUMI_5_train), np.array(y_BUMI_5_train)\n",
        "X_BUMI_5_train = np.reshape(X_BUMI_5_train, (X_BUMI_5_train.shape[0], X_BUMI_5_train.shape[1], 1))\n",
        "model_BUMI_5 = Sequential()\n",
        "model_BUMI_5.add(LSTM(units=50,return_sequences=True,input_shape=(X_BUMI_5_train.shape[1], 1)))\n",
        "model_BUMI_5.add(Dropout(0.2))\n",
        "model_BUMI_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_5.add(Dropout(0.2))\n",
        "model_BUMI_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_5.add(Dropout(0.2))\n",
        "model_BUMI_5.add(LSTM(units=50))\n",
        "model_BUMI_5.add(Dropout(0.2))\n",
        "model_BUMI_5.add(Dense(units=1))\n",
        "model_BUMI_5.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BUMI_5.fit(X_BUMI_5_train,y_BUMI_5_train,epochs=10,batch_size=16)\n",
        "\n",
        "# MFIN\n",
        "MFIN_5 = yf.download(\"MFIN.JK\", start=\"2022-04-10\", end=\"2022-10-10\")\n",
        "MFIN_5.insert(4,\"Return\", MFIN_5['Close'].pct_change())\n",
        "MFIN_5 = MFIN_5.dropna()\n",
        "MFIN_5_test = yf.download(\"MFIN.JK\", start=\"2022-10-09\", end=\"2022-11-10\")\n",
        "MFIN_5_test.insert(4,\"Return\", MFIN_5_test['Close'].pct_change())\n",
        "MFIN_5_test = MFIN_5_test.dropna()\n",
        "training_MFIN_5 = MFIN_5.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_MFIN_5_scaled = sc.fit_transform(training_MFIN_5)\n",
        "X_MFIN_5_train = []\n",
        "y_MFIN_5_train = []\n",
        "for i in range(days_period, len(MFIN_5)-1):\n",
        "    X_MFIN_5_train.append(training_MFIN_5_scaled[i-days_period:i, 0])\n",
        "    y_MFIN_5_train.append(training_MFIN_5_scaled[i, 0])\n",
        "X_MFIN_5_train, y_MFIN_5_train = np.array(X_MFIN_5_train), np.array(y_MFIN_5_train)\n",
        "X_MFIN_5_train = np.reshape(X_MFIN_5_train, (X_MFIN_5_train.shape[0], X_MFIN_5_train.shape[1], 1))\n",
        "model_MFIN_5 = Sequential()\n",
        "model_MFIN_5.add(LSTM(units=50,return_sequences=True,input_shape=(X_MFIN_5_train.shape[1], 1)))\n",
        "model_MFIN_5.add(Dropout(0.2))\n",
        "model_MFIN_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_5.add(Dropout(0.2))\n",
        "model_MFIN_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_5.add(Dropout(0.2))\n",
        "model_MFIN_5.add(LSTM(units=50))\n",
        "model_MFIN_5.add(Dropout(0.2))\n",
        "model_MFIN_5.add(Dense(units=1))\n",
        "model_MFIN_5.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_MFIN_5.fit(X_MFIN_5_train,y_MFIN_5_train,epochs=10,batch_size=16)\n",
        "\n",
        "# EXCL\n",
        "EXCL_5 = yf.download(\"EXCL.JK\", start=\"2022-04-10\", end=\"2022-10-10\")\n",
        "EXCL_5.insert(4,\"Return\", EXCL_5['Close'].pct_change())\n",
        "EXCL_5 = EXCL_5.dropna()\n",
        "EXCL_5_test = yf.download(\"EXCL.JK\", start=\"2022-10-09\", end=\"2022-11-10\")\n",
        "EXCL_5_test.insert(4,\"Return\", EXCL_5_test['Close'].pct_change())\n",
        "EXCL_5_test = EXCL_5_test.dropna()\n",
        "training_EXCL_5 = EXCL_5.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_EXCL_5_scaled = sc.fit_transform(training_EXCL_5)\n",
        "X_EXCL_5_train = []\n",
        "y_EXCL_5_train = []\n",
        "for i in range(days_period, len(EXCL_5)-1):\n",
        "    X_EXCL_5_train.append(training_EXCL_5_scaled[i-days_period:i, 0])\n",
        "    y_EXCL_5_train.append(training_EXCL_5_scaled[i, 0])\n",
        "X_EXCL_5_train, y_EXCL_5_train = np.array(X_EXCL_5_train), np.array(y_EXCL_5_train)\n",
        "X_EXCL_5_train = np.reshape(X_EXCL_5_train, (X_EXCL_5_train.shape[0], X_EXCL_5_train.shape[1], 1))\n",
        "model_EXCL_5 = Sequential()\n",
        "model_EXCL_5.add(LSTM(units=50,return_sequences=True,input_shape=(X_EXCL_5_train.shape[1], 1)))\n",
        "model_EXCL_5.add(Dropout(0.2))\n",
        "model_EXCL_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_5.add(Dropout(0.2))\n",
        "model_EXCL_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_5.add(Dropout(0.2))\n",
        "model_EXCL_5.add(LSTM(units=50))\n",
        "model_EXCL_5.add(Dropout(0.2))\n",
        "model_EXCL_5.add(Dense(units=1))\n",
        "model_EXCL_5.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_EXCL_5.fit(X_EXCL_5_train,y_EXCL_5_train,epochs=10,batch_size=16)\n",
        "\n",
        "# PGAS\n",
        "PGAS_5 = yf.download(\"PGAS.JK\", start=\"2022-04-10\", end=\"2022-10-10\")\n",
        "PGAS_5.insert(4,\"Return\", PGAS_5['Close'].pct_change())\n",
        "PGAS_5 = PGAS_5.dropna()\n",
        "PGAS_5_test = yf.download(\"PGAS.JK\", start=\"2022-10-09\", end=\"2022-11-10\")\n",
        "PGAS_5_test.insert(4,\"Return\", PGAS_5_test['Close'].pct_change())\n",
        "PGAS_5_test = PGAS_5_test.dropna()\n",
        "training_PGAS_5 = PGAS_5.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_PGAS_5_scaled = sc.fit_transform(training_PGAS_5)\n",
        "X_PGAS_5_train = []\n",
        "y_PGAS_5_train = []\n",
        "for i in range(days_period, len(PGAS_5)-1):\n",
        "    X_PGAS_5_train.append(training_PGAS_5_scaled[i-days_period:i, 0])\n",
        "    y_PGAS_5_train.append(training_PGAS_5_scaled[i, 0])\n",
        "X_PGAS_5_train, y_PGAS_5_train = np.array(X_PGAS_5_train), np.array(y_PGAS_5_train)\n",
        "X_PGAS_5_train = np.reshape(X_PGAS_5_train, (X_PGAS_5_train.shape[0], X_PGAS_5_train.shape[1], 1))\n",
        "model_PGAS_5 = Sequential()\n",
        "model_PGAS_5.add(LSTM(units=50,return_sequences=True,input_shape=(X_PGAS_5_train.shape[1], 1)))\n",
        "model_PGAS_5.add(Dropout(0.2))\n",
        "model_PGAS_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_5.add(Dropout(0.2))\n",
        "model_PGAS_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_5.add(Dropout(0.2))\n",
        "model_PGAS_5.add(LSTM(units=50))\n",
        "model_PGAS_5.add(Dropout(0.2))\n",
        "model_PGAS_5.add(Dense(units=1))\n",
        "model_PGAS_5.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_PGAS_5.fit(X_PGAS_5_train,y_PGAS_5_train,epochs=10,batch_size=16)\n",
        "\n",
        "# TLKM\n",
        "TLKM_5 = yf.download(\"TLKM.JK\", start=\"2022-04-10\", end=\"2022-10-10\")\n",
        "TLKM_5.insert(4,\"Return\", TLKM_5['Close'].pct_change())\n",
        "TLKM_5 = TLKM_5.dropna()\n",
        "TLKM_5_test = yf.download(\"TLKM.JK\", start=\"2022-10-09\", end=\"2022-11-10\")\n",
        "TLKM_5_test.insert(4,\"Return\", TLKM_5_test['Close'].pct_change())\n",
        "TLKM_5_test = TLKM_5_test.dropna()\n",
        "training_TLKM_5 = TLKM_5.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_TLKM_5_scaled = sc.fit_transform(training_TLKM_5)\n",
        "X_TLKM_5_train = []\n",
        "y_TLKM_5_train = []\n",
        "for i in range(days_period, len(TLKM_5)-1):\n",
        "    X_TLKM_5_train.append(training_TLKM_5_scaled[i-days_period:i, 0])\n",
        "    y_TLKM_5_train.append(training_TLKM_5_scaled[i, 0])\n",
        "X_TLKM_5_train, y_TLKM_5_train = np.array(X_TLKM_5_train), np.array(y_TLKM_5_train)\n",
        "X_TLKM_5_train = np.reshape(X_TLKM_5_train, (X_TLKM_5_train.shape[0], X_TLKM_5_train.shape[1], 1))\n",
        "model_TLKM_5 = Sequential()\n",
        "model_TLKM_5.add(LSTM(units=50,return_sequences=True,input_shape=(X_TLKM_5_train.shape[1], 1)))\n",
        "model_TLKM_5.add(Dropout(0.2))\n",
        "model_TLKM_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_5.add(Dropout(0.2))\n",
        "model_TLKM_5.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_5.add(Dropout(0.2))\n",
        "model_TLKM_5.add(LSTM(units=50))\n",
        "model_TLKM_5.add(Dropout(0.2))\n",
        "model_TLKM_5.add(Dense(units=1))\n",
        "model_TLKM_5.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_TLKM_5.fit(X_TLKM_5_train,y_TLKM_5_train,epochs=10,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcxseZiVG14o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed620d5c-caee-467b-d680-5b353af9053c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n"
          ]
        }
      ],
      "source": [
        "# ADRO\n",
        "real_ADRO_5_return = ADRO_5_test.iloc[:, 4:5].values\n",
        "real_ADRO_5_return = real_ADRO_5_return[:days_predict]\n",
        "ADRO_5_total = ADRO_5['Close'].copy(deep=True)\n",
        "inputs_ADRO_5 = ADRO_5_total[len(ADRO_5) - days_period: len(ADRO_5)].values\n",
        "inputs_ADRO_5 = inputs_ADRO_5.reshape(-1,1)\n",
        "inputs_ADRO_5 = sc.transform(inputs_ADRO_5)\n",
        "predicted_ADRO_5_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ADRO_5_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ADRO_5_test.append(inputs_ADRO_5[i:i+days_period, 0])\n",
        "  X_ADRO_5_test = np.array(X_ADRO_5_test)\n",
        "  X_ADRO_5_test = np.reshape(X_ADRO_5_test, (X_ADRO_5_test.shape[0], X_ADRO_5_test.shape[1], 1))\n",
        "  predicted_ADRO_5_return[j] = model_ADRO_5.predict(X_ADRO_5_test)\n",
        "  inputs_ADRO_5 += (predicted_ADRO_5_return[j])\n",
        "  inputs_ADRO_5 = inputs_ADRO_5.reshape(-1,1)\n",
        "\n",
        "# ASII\n",
        "real_ASII_5_return = ASII_5_test.iloc[:, 4:5].values\n",
        "real_ASII_5_return = real_ASII_5_return[:days_predict]\n",
        "ASII_5_total = ASII_5['Close'].copy(deep=True)\n",
        "inputs_ASII_5 = ASII_5_total[len(ASII_5) - days_period: len(ASII_5)].values\n",
        "inputs_ASII_5 = inputs_ASII_5.reshape(-1,1)\n",
        "inputs_ASII_5 = sc.transform(inputs_ASII_5)\n",
        "predicted_ASII_5_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ASII_5_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ASII_5_test.append(inputs_ASII_5[i:i+days_period, 0])\n",
        "  X_ASII_5_test = np.array(X_ASII_5_test)\n",
        "  X_ASII_5_test = np.reshape(X_ASII_5_test, (X_ASII_5_test.shape[0], X_ASII_5_test.shape[1], 1))\n",
        "  predicted_ASII_5_return[j] = model_ASII_5.predict(X_ASII_5_test)\n",
        "  inputs_ASII_5 += (predicted_ASII_5_return[j])\n",
        "  inputs_ASII_5 = inputs_ASII_5.reshape(-1,1)\n",
        "\n",
        "# BMRI\n",
        "real_BMRI_5_return = BMRI_5_test.iloc[:, 4:5].values\n",
        "real_BMRI_5_return = real_BMRI_5_return[:days_predict]\n",
        "BMRI_5_total = BMRI_5['Close'].copy(deep=True)\n",
        "inputs_BMRI_5 = BMRI_5_total[len(BMRI_5) - days_period: len(BMRI_5)].values\n",
        "inputs_BMRI_5 = inputs_BMRI_5.reshape(-1,1)\n",
        "inputs_BMRI_5 = sc.transform(inputs_BMRI_5)\n",
        "predicted_BMRI_5_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BMRI_5_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BMRI_5_test.append(inputs_BMRI_5[i:i+days_period, 0])\n",
        "  X_BMRI_5_test = np.array(X_BMRI_5_test)\n",
        "  X_BMRI_5_test = np.reshape(X_BMRI_5_test, (X_BMRI_5_test.shape[0], X_BMRI_5_test.shape[1], 1))\n",
        "  predicted_BMRI_5_return[j] = model_BMRI_5.predict(X_BMRI_5_test)\n",
        "  inputs_BMRI_5 += (predicted_BMRI_5_return[j])\n",
        "  inputs_BMRI_5 = inputs_BMRI_5.reshape(-1,1)\n",
        "\n",
        "# BBRI\n",
        "real_BBRI_5_return = BBRI_5_test.iloc[:, 4:5].values\n",
        "real_BBRI_5_return = real_BBRI_5_return[:days_predict]\n",
        "BBRI_5_total = BBRI_5['Close'].copy(deep=True)\n",
        "inputs_BBRI_5 = BBRI_5_total[len(BBRI_5) - days_period: len(BBRI_5)].values\n",
        "inputs_BBRI_5 = inputs_BBRI_5.reshape(-1,1)\n",
        "inputs_BBRI_5 = sc.transform(inputs_BBRI_5)\n",
        "predicted_BBRI_5_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBRI_5_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBRI_5_test.append(inputs_BBRI_5[i:i+days_period, 0])\n",
        "  X_BBRI_5_test = np.array(X_BBRI_5_test)\n",
        "  X_BBRI_5_test = np.reshape(X_BBRI_5_test, (X_BBRI_5_test.shape[0], X_BBRI_5_test.shape[1], 1))\n",
        "  predicted_BBRI_5_return[j] = model_BBRI_5.predict(X_BBRI_5_test)\n",
        "  inputs_BBRI_5 += (predicted_BBRI_5_return[j])\n",
        "  inputs_BBRI_5 = inputs_BBRI_5.reshape(-1,1)\n",
        "\n",
        "# BBTN\n",
        "real_BBTN_5_return = BBTN_5_test.iloc[:, 4:5].values\n",
        "real_BBTN_5_return = real_BBTN_5_return[:days_predict]\n",
        "BBTN_5_total = BBTN_5['Close'].copy(deep=True)\n",
        "inputs_BBTN_5 = BBTN_5_total[len(BBTN_5) - days_period: len(BBTN_5)].values\n",
        "inputs_BBTN_5 = inputs_BBTN_5.reshape(-1,1)\n",
        "inputs_BBTN_5 = sc.transform(inputs_BBTN_5)\n",
        "predicted_BBTN_5_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBTN_5_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBTN_5_test.append(inputs_BBTN_5[i:i+days_period, 0])\n",
        "  X_BBTN_5_test = np.array(X_BBTN_5_test)\n",
        "  X_BBTN_5_test = np.reshape(X_BBTN_5_test, (X_BBTN_5_test.shape[0], X_BBTN_5_test.shape[1], 1))\n",
        "  predicted_BBTN_5_return[j] = model_BBTN_5.predict(X_BBTN_5_test)\n",
        "  inputs_BBTN_5 += (predicted_BBTN_5_return[j])\n",
        "  inputs_BBTN_5 = inputs_BBTN_5.reshape(-1,1)\n",
        "\n",
        "# BUMI\n",
        "real_BUMI_5_return = BUMI_5_test.iloc[:, 4:5].values\n",
        "real_BUMI_5_return = real_BUMI_5_return[:days_predict]\n",
        "BUMI_5_total = BUMI_5['Close'].copy(deep=True)\n",
        "inputs_BUMI_5 = BUMI_5_total[len(BUMI_5) - days_period: len(BUMI_5)].values\n",
        "inputs_BUMI_5 = inputs_BUMI_5.reshape(-1,1)\n",
        "inputs_BUMI_5 = sc.transform(inputs_BUMI_5)\n",
        "predicted_BUMI_5_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BUMI_5_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BUMI_5_test.append(inputs_BUMI_5[i:i+days_period, 0])\n",
        "  X_BUMI_5_test = np.array(X_BUMI_5_test)\n",
        "  X_BUMI_5_test = np.reshape(X_BUMI_5_test, (X_BUMI_5_test.shape[0], X_BUMI_5_test.shape[1], 1))\n",
        "  predicted_BUMI_5_return[j] = model_BUMI_5.predict(X_BUMI_5_test)\n",
        "  inputs_BUMI_5 += (predicted_BUMI_5_return[j])\n",
        "  inputs_BUMI_5 = inputs_BUMI_5.reshape(-1,1)\n",
        "\n",
        "# MFIN\n",
        "real_MFIN_5_return = MFIN_5_test.iloc[:, 4:5].values\n",
        "real_MFIN_5_return = real_MFIN_5_return[:days_predict]\n",
        "MFIN_5_total = MFIN_5['Close'].copy(deep=True)\n",
        "inputs_MFIN_5 = MFIN_5_total[len(MFIN_5) - days_period: len(MFIN_5)].values\n",
        "inputs_MFIN_5 = inputs_MFIN_5.reshape(-1,1)\n",
        "inputs_MFIN_5 = sc.transform(inputs_MFIN_5)\n",
        "predicted_MFIN_5_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_MFIN_5_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_MFIN_5_test.append(inputs_MFIN_5[i:i+days_period, 0])\n",
        "  X_MFIN_5_test = np.array(X_MFIN_5_test)\n",
        "  X_MFIN_5_test = np.reshape(X_MFIN_5_test, (X_MFIN_5_test.shape[0], X_MFIN_5_test.shape[1], 1))\n",
        "  predicted_MFIN_5_return[j] = model_MFIN_5.predict(X_MFIN_5_test)\n",
        "  inputs_MFIN_5 += (predicted_MFIN_5_return[j])\n",
        "  inputs_MFIN_5 = inputs_MFIN_5.reshape(-1,1)\n",
        "\n",
        "# EXCL\n",
        "real_EXCL_5_return = EXCL_5_test.iloc[:, 4:5].values\n",
        "real_EXCL_5_return = real_EXCL_5_return[:days_predict]\n",
        "EXCL_5_total = EXCL_5['Close'].copy(deep=True)\n",
        "inputs_EXCL_5 = EXCL_5_total[len(EXCL_5) - days_period: len(EXCL_5)].values\n",
        "inputs_EXCL_5 = inputs_EXCL_5.reshape(-1,1)\n",
        "inputs_EXCL_5 = sc.transform(inputs_EXCL_5)\n",
        "predicted_EXCL_5_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_EXCL_5_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_EXCL_5_test.append(inputs_EXCL_5[i:i+days_period, 0])\n",
        "  X_EXCL_5_test = np.array(X_EXCL_5_test)\n",
        "  X_EXCL_5_test = np.reshape(X_EXCL_5_test, (X_EXCL_5_test.shape[0], X_EXCL_5_test.shape[1], 1))\n",
        "  predicted_EXCL_5_return[j] = model_EXCL_5.predict(X_EXCL_5_test)\n",
        "  inputs_EXCL_5 += (predicted_EXCL_5_return[j])\n",
        "  inputs_EXCL_5 = inputs_EXCL_5.reshape(-1,1)\n",
        "\n",
        "# PGAS\n",
        "real_PGAS_5_return = PGAS_5_test.iloc[:, 4:5].values\n",
        "real_PGAS_5_return = real_PGAS_5_return[:days_predict]\n",
        "PGAS_5_total = PGAS_5['Close'].copy(deep=True)\n",
        "inputs_PGAS_5 = PGAS_5_total[len(PGAS_5) - days_period: len(PGAS_5)].values\n",
        "inputs_PGAS_5 = inputs_PGAS_5.reshape(-1,1)\n",
        "inputs_PGAS_5 = sc.transform(inputs_PGAS_5)\n",
        "predicted_PGAS_5_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_PGAS_5_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_PGAS_5_test.append(inputs_PGAS_5[i:i+days_period, 0])\n",
        "  X_PGAS_5_test = np.array(X_PGAS_5_test)\n",
        "  X_PGAS_5_test = np.reshape(X_PGAS_5_test, (X_PGAS_5_test.shape[0], X_PGAS_5_test.shape[1], 1))\n",
        "  predicted_PGAS_5_return[j] = model_PGAS_5.predict(X_PGAS_5_test)\n",
        "  inputs_PGAS_5 += (predicted_PGAS_5_return[j])\n",
        "  inputs_PGAS_5 = inputs_PGAS_5.reshape(-1,1)\n",
        "\n",
        "# TLKM\n",
        "real_TLKM_5_return = TLKM_5_test.iloc[:, 4:5].values\n",
        "real_TLKM_5_return = real_TLKM_5_return[:days_predict]\n",
        "TLKM_5_total = TLKM_5['Close'].copy(deep=True)\n",
        "inputs_TLKM_5 = TLKM_5_total[len(TLKM_5) - days_period: len(TLKM_5)].values\n",
        "inputs_TLKM_5 = inputs_TLKM_5.reshape(-1,1)\n",
        "inputs_TLKM_5 = sc.transform(inputs_TLKM_5)\n",
        "predicted_TLKM_5_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_TLKM_5_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_TLKM_5_test.append(inputs_TLKM_5[i:i+days_period, 0])\n",
        "  X_TLKM_5_test = np.array(X_TLKM_5_test)\n",
        "  X_TLKM_5_test = np.reshape(X_TLKM_5_test, (X_TLKM_5_test.shape[0], X_TLKM_5_test.shape[1], 1))\n",
        "  predicted_TLKM_5_return[j] = model_TLKM_5.predict(X_TLKM_5_test)\n",
        "  inputs_TLKM_5 += (predicted_TLKM_5_return[j])\n",
        "  inputs_TLKM_5 = inputs_TLKM_5.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0mN79GBG14p"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "predicted_ADRO_5_return = np.squeeze(np.asarray(predicted_ADRO_5_return))\n",
        "predicted_ADRO_5_return = predicted_ADRO_5_return.reshape(-1,1)\n",
        "predicted_ADRO_5_return = sc.inverse_transform(predicted_ADRO_5_return)\n",
        "# ASII\n",
        "predicted_ASII_5_return = np.squeeze(np.asarray(predicted_ASII_5_return))\n",
        "predicted_ASII_5_return = predicted_ASII_5_return.reshape(-1,1)\n",
        "predicted_ASII_5_return = sc.inverse_transform(predicted_ASII_5_return)\n",
        "# BMRI\n",
        "predicted_BMRI_5_return = np.squeeze(np.asarray(predicted_BMRI_5_return))\n",
        "predicted_BMRI_5_return = predicted_BMRI_5_return.reshape(-1,1)\n",
        "predicted_BMRI_5_return = sc.inverse_transform(predicted_BMRI_5_return)\n",
        "# BBRI\n",
        "predicted_BBRI_5_return = np.squeeze(np.asarray(predicted_BBRI_5_return))\n",
        "predicted_BBRI_5_return = predicted_BBRI_5_return.reshape(-1,1)\n",
        "predicted_BBRI_5_return = sc.inverse_transform(predicted_BBRI_5_return)\n",
        "# BBTN\n",
        "predicted_BBTN_5_return = np.squeeze(np.asarray(predicted_BBTN_5_return))\n",
        "predicted_BBTN_5_return = predicted_BBTN_5_return.reshape(-1,1)\n",
        "predicted_BBTN_5_return = sc.inverse_transform(predicted_BBTN_5_return)\n",
        "# BUMI\n",
        "predicted_BUMI_5_return = np.squeeze(np.asarray(predicted_BUMI_5_return))\n",
        "predicted_BUMI_5_return = predicted_BUMI_5_return.reshape(-1,1)\n",
        "predicted_BUMI_5_return = sc.inverse_transform(predicted_BUMI_5_return)\n",
        "# MFIN\n",
        "predicted_MFIN_5_return = np.squeeze(np.asarray(predicted_MFIN_5_return))\n",
        "predicted_MFIN_5_return = predicted_MFIN_5_return.reshape(-1,1)\n",
        "predicted_MFIN_5_return = sc.inverse_transform(predicted_MFIN_5_return)\n",
        "# EXCL\n",
        "predicted_EXCL_5_return = np.squeeze(np.asarray(predicted_EXCL_5_return))\n",
        "predicted_EXCL_5_return = predicted_EXCL_5_return.reshape(-1,1)\n",
        "predicted_EXCL_5_return = sc.inverse_transform(predicted_EXCL_5_return)\n",
        "# PGAS\n",
        "predicted_PGAS_5_return = np.squeeze(np.asarray(predicted_PGAS_5_return))\n",
        "predicted_PGAS_5_return = predicted_PGAS_5_return.reshape(-1,1)\n",
        "predicted_PGAS_5_return = sc.inverse_transform(predicted_PGAS_5_return)\n",
        "# TLKM\n",
        "predicted_TLKM_5_return = np.squeeze(np.asarray(predicted_TLKM_5_return))\n",
        "predicted_TLKM_5_return = predicted_TLKM_5_return.reshape(-1,1)\n",
        "predicted_TLKM_5_return = sc.inverse_transform(predicted_TLKM_5_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itO1edr4G14p"
      },
      "outputs": [],
      "source": [
        "predicted5 = pd.DataFrame(predicted_ADRO_5_return)\n",
        "predicted5.rename(columns={0:'ADRO'}, inplace=True)\n",
        "predicted5.insert(1,\"ASII\", predicted_ASII_5_return)\n",
        "predicted5.insert(2,\"BBRI\", predicted_BBRI_5_return)\n",
        "predicted5.insert(3,\"BBTN\", predicted_BBTN_5_return)\n",
        "predicted5.insert(4,\"BMRI\", predicted_BMRI_5_return)\n",
        "predicted5.insert(5,\"BUMI\", predicted_BUMI_5_return)\n",
        "predicted5.insert(6,\"EXCL\", predicted_EXCL_5_return)\n",
        "predicted5.insert(7,\"MFIN\", predicted_MFIN_5_return)\n",
        "predicted5.insert(8,\"PGAS\", predicted_PGAS_5_return)\n",
        "predicted5.insert(9,\"TLKM\", predicted_TLKM_5_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpLIO98kQjng",
        "outputId": "09dccc29-ecba-4b0c-d063-57aec4ed5977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADRO      ASII      BBRI      BBTN      BMRI      BUMI      EXCL  \\\n",
              "0  0.027664  0.026990  0.033100  0.018129  0.024689 -0.007650 -0.005846   \n",
              "1  0.026647  0.026114  0.031979  0.017590  0.023589 -0.008391 -0.006676   \n",
              "2  0.025388  0.025004  0.030639  0.016894  0.022249 -0.009313 -0.007656   \n",
              "3  0.023836  0.023610  0.029041  0.016003  0.020624 -0.010446 -0.008811   \n",
              "4  0.021935  0.021877  0.027139  0.014867  0.018662 -0.011823 -0.010169   \n",
              "5  0.019620  0.019744  0.024880  0.013431  0.016309 -0.013478 -0.011763   \n",
              "6  0.016822  0.017142  0.022206  0.011628  0.013507 -0.015444 -0.013624   \n",
              "7  0.013470  0.014001  0.019052  0.009386  0.010197 -0.017750 -0.015789   \n",
              "8  0.009493  0.010247  0.015350  0.006625  0.006325 -0.020422 -0.018288   \n",
              "9  0.004831  0.005813  0.011032  0.003260  0.001845 -0.023473 -0.021151   \n",
              "\n",
              "       MFIN      PGAS      TLKM  \n",
              "0  0.016606  0.006788  0.073100  \n",
              "1  0.015339  0.005713  0.071419  \n",
              "2  0.013836  0.004438  0.069380  \n",
              "3  0.012062  0.002925  0.066914  \n",
              "4  0.009981  0.001145  0.063943  \n",
              "5  0.007556 -0.000944  0.060377  \n",
              "6  0.004750 -0.003380  0.056120  \n",
              "7  0.001530 -0.006213  0.051069  \n",
              "8 -0.002132 -0.009453  0.045121  \n",
              "9 -0.006257 -0.013123  0.038180  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2fc7274-0087-4378-9e19-2478ba168d52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADRO</th>\n",
              "      <th>ASII</th>\n",
              "      <th>BBRI</th>\n",
              "      <th>BBTN</th>\n",
              "      <th>BMRI</th>\n",
              "      <th>BUMI</th>\n",
              "      <th>EXCL</th>\n",
              "      <th>MFIN</th>\n",
              "      <th>PGAS</th>\n",
              "      <th>TLKM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.027664</td>\n",
              "      <td>0.026990</td>\n",
              "      <td>0.033100</td>\n",
              "      <td>0.018129</td>\n",
              "      <td>0.024689</td>\n",
              "      <td>-0.007650</td>\n",
              "      <td>-0.005846</td>\n",
              "      <td>0.016606</td>\n",
              "      <td>0.006788</td>\n",
              "      <td>0.073100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.026647</td>\n",
              "      <td>0.026114</td>\n",
              "      <td>0.031979</td>\n",
              "      <td>0.017590</td>\n",
              "      <td>0.023589</td>\n",
              "      <td>-0.008391</td>\n",
              "      <td>-0.006676</td>\n",
              "      <td>0.015339</td>\n",
              "      <td>0.005713</td>\n",
              "      <td>0.071419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.025388</td>\n",
              "      <td>0.025004</td>\n",
              "      <td>0.030639</td>\n",
              "      <td>0.016894</td>\n",
              "      <td>0.022249</td>\n",
              "      <td>-0.009313</td>\n",
              "      <td>-0.007656</td>\n",
              "      <td>0.013836</td>\n",
              "      <td>0.004438</td>\n",
              "      <td>0.069380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.023836</td>\n",
              "      <td>0.023610</td>\n",
              "      <td>0.029041</td>\n",
              "      <td>0.016003</td>\n",
              "      <td>0.020624</td>\n",
              "      <td>-0.010446</td>\n",
              "      <td>-0.008811</td>\n",
              "      <td>0.012062</td>\n",
              "      <td>0.002925</td>\n",
              "      <td>0.066914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.021935</td>\n",
              "      <td>0.021877</td>\n",
              "      <td>0.027139</td>\n",
              "      <td>0.014867</td>\n",
              "      <td>0.018662</td>\n",
              "      <td>-0.011823</td>\n",
              "      <td>-0.010169</td>\n",
              "      <td>0.009981</td>\n",
              "      <td>0.001145</td>\n",
              "      <td>0.063943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.019620</td>\n",
              "      <td>0.019744</td>\n",
              "      <td>0.024880</td>\n",
              "      <td>0.013431</td>\n",
              "      <td>0.016309</td>\n",
              "      <td>-0.013478</td>\n",
              "      <td>-0.011763</td>\n",
              "      <td>0.007556</td>\n",
              "      <td>-0.000944</td>\n",
              "      <td>0.060377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.016822</td>\n",
              "      <td>0.017142</td>\n",
              "      <td>0.022206</td>\n",
              "      <td>0.011628</td>\n",
              "      <td>0.013507</td>\n",
              "      <td>-0.015444</td>\n",
              "      <td>-0.013624</td>\n",
              "      <td>0.004750</td>\n",
              "      <td>-0.003380</td>\n",
              "      <td>0.056120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.013470</td>\n",
              "      <td>0.014001</td>\n",
              "      <td>0.019052</td>\n",
              "      <td>0.009386</td>\n",
              "      <td>0.010197</td>\n",
              "      <td>-0.017750</td>\n",
              "      <td>-0.015789</td>\n",
              "      <td>0.001530</td>\n",
              "      <td>-0.006213</td>\n",
              "      <td>0.051069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.009493</td>\n",
              "      <td>0.010247</td>\n",
              "      <td>0.015350</td>\n",
              "      <td>0.006625</td>\n",
              "      <td>0.006325</td>\n",
              "      <td>-0.020422</td>\n",
              "      <td>-0.018288</td>\n",
              "      <td>-0.002132</td>\n",
              "      <td>-0.009453</td>\n",
              "      <td>0.045121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.004831</td>\n",
              "      <td>0.005813</td>\n",
              "      <td>0.011032</td>\n",
              "      <td>0.003260</td>\n",
              "      <td>0.001845</td>\n",
              "      <td>-0.023473</td>\n",
              "      <td>-0.021151</td>\n",
              "      <td>-0.006257</td>\n",
              "      <td>-0.013123</td>\n",
              "      <td>0.038180</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2fc7274-0087-4378-9e19-2478ba168d52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2fc7274-0087-4378-9e19-2478ba168d52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2fc7274-0087-4378-9e19-2478ba168d52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR901b1icghZ"
      },
      "source": [
        "## Data Preparation 6\n",
        "1st of January 2018 - 9th of November 2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WqCCHpyG3hQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ffd9686-1b70-4b77-ee7c-7e9d75105e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 18s 84ms/step - loss: 0.1693\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 82ms/step - loss: 0.0551\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0486\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.0413\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 0.0409\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 0.0413\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 82ms/step - loss: 0.0412\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 92ms/step - loss: 0.0413\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 0.0394\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 106ms/step - loss: 0.0385\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 15s 69ms/step - loss: 0.1532\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 0.0547\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0475\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 0.0409\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.0396\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 71ms/step - loss: 0.0390\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 0.0414\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0418\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0399\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.0405\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "\n",
            "1 Failed download:\n",
            "- BMRI.JK: No data found for this date range, symbol may be delisted\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 16s 105ms/step - loss: 0.0978\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 91ms/step - loss: 0.0419\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0346\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0278\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 0.0304\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.0298\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.0296\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.0283\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.0279\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0284\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 15s 78ms/step - loss: 0.1310\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 0.0376\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 103ms/step - loss: 0.0328\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 127ms/step - loss: 0.0285\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 93ms/step - loss: 0.0315\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 107ms/step - loss: 0.0276\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 0.0288\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 0.0297\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0283\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0294\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 17s 79ms/step - loss: 0.1595\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0471\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0323\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0296\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 0.0234\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0238\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 106ms/step - loss: 0.0254\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 0.0252\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 116ms/step - loss: 0.0237\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 106ms/step - loss: 0.0233\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 16s 78ms/step - loss: 0.0643\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0376\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 0.0334\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0340\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 0.0364\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 82ms/step - loss: 0.0342\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0327\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0336\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0325\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0312\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 14s 83ms/step - loss: 0.0717\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 0.0247\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0190\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0150\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0116\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0107\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0107\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.0096\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.0100\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 72ms/step - loss: 0.0101\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 16s 81ms/step - loss: 0.1102\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0520\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 0.0366\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0344\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0370\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0323\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0312\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0304\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0336\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 82ms/step - loss: 0.0362\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 17s 81ms/step - loss: 0.0884\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 61ms/step - loss: 0.0458\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0442\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0307\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0338\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0306\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0329\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0290\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0310\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0313\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 10s 43ms/step - loss: 0.1548\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0733\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0472\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0390\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0361\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0460\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.0426\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.0318\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.0422\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0367\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efb9e82b670>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Period parameters\n",
        "days_period = 20\n",
        "days_predict = 10\n",
        "\n",
        "# ADRO\n",
        "ADRO_6 = yf.download(\"ADRO.JK\", start=\"2022-05-10\", end=\"2022-11-10\")\n",
        "ADRO_6.insert(4,\"Return\", ADRO_6['Close'].pct_change())\n",
        "ADRO_6 = ADRO_6.dropna()\n",
        "ADRO_6_test = yf.download(\"ADRO.JK\", start=\"2022-11-09\", end=\"2022-12-10\")\n",
        "ADRO_6_test.insert(4,\"Return\", ADRO_6_test['Close'].pct_change())\n",
        "ADRO_6_test = ADRO_6_test.dropna()\n",
        "training_ADRO_6 = ADRO_6.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ADRO_6_scaled = sc.fit_transform(training_ADRO_6)\n",
        "X_ADRO_6_train = []\n",
        "y_ADRO_6_train = []\n",
        "for i in range(days_period, len(ADRO_6)-1):\n",
        "    X_ADRO_6_train.append(training_ADRO_6_scaled[i-days_period:i, 0])\n",
        "    y_ADRO_6_train.append(training_ADRO_6_scaled[i, 0])\n",
        "X_ADRO_6_train, y_ADRO_6_train = np.array(X_ADRO_6_train), np.array(y_ADRO_6_train)\n",
        "X_ADRO_6_train = np.reshape(X_ADRO_6_train, (X_ADRO_6_train.shape[0], X_ADRO_6_train.shape[1], 1))\n",
        "model_ADRO_6 = Sequential()\n",
        "model_ADRO_6.add(LSTM(units=50,return_sequences=True,input_shape=(X_ADRO_6_train.shape[1], 1)))\n",
        "model_ADRO_6.add(Dropout(0.2))\n",
        "model_ADRO_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_6.add(Dropout(0.2))\n",
        "model_ADRO_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_6.add(Dropout(0.2))\n",
        "model_ADRO_6.add(LSTM(units=50))\n",
        "model_ADRO_6.add(Dropout(0.2))\n",
        "model_ADRO_6.add(Dense(units=1))\n",
        "model_ADRO_6.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ADRO_6.fit(X_ADRO_6_train,y_ADRO_6_train,epochs=10,batch_size=16)\n",
        "\n",
        "# ASII\n",
        "ASII_6 = yf.download(\"ASII.JK\", start=\"2022-05-10\", end=\"2022-11-10\")\n",
        "ASII_6.insert(4,\"Return\", ASII_6['Close'].pct_change())\n",
        "ASII_6 = ASII_6.dropna()\n",
        "ASII_6_test = yf.download(\"ASII.JK\", start=\"2022-11-09\", end=\"2022-12-10\")\n",
        "ASII_6_test.insert(4,\"Return\", ASII_6_test['Close'].pct_change())\n",
        "ASII_6_test = ASII_6_test.dropna()\n",
        "training_ASII_6 = ASII_6.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ASII_6_scaled = sc.fit_transform(training_ASII_6)\n",
        "X_ASII_6_train = []\n",
        "y_ASII_6_train = []\n",
        "for i in range(days_period, len(ASII_6)-1):\n",
        "    X_ASII_6_train.append(training_ASII_6_scaled[i-days_period:i, 0])\n",
        "    y_ASII_6_train.append(training_ASII_6_scaled[i, 0])\n",
        "X_ASII_6_train, y_ASII_6_train = np.array(X_ASII_6_train), np.array(y_ASII_6_train)\n",
        "X_ASII_6_train = np.reshape(X_ASII_6_train, (X_ASII_6_train.shape[0], X_ASII_6_train.shape[1], 1))\n",
        "model_ASII_6 = Sequential()\n",
        "model_ASII_6.add(LSTM(units=50,return_sequences=True,input_shape=(X_ASII_6_train.shape[1], 1)))\n",
        "model_ASII_6.add(Dropout(0.2))\n",
        "model_ASII_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_6.add(Dropout(0.2))\n",
        "model_ASII_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_6.add(Dropout(0.2))\n",
        "model_ASII_6.add(LSTM(units=50))\n",
        "model_ASII_6.add(Dropout(0.2))\n",
        "model_ASII_6.add(Dense(units=1))\n",
        "model_ASII_6.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ASII_6.fit(X_ASII_6_train,y_ASII_6_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BMRI\n",
        "BMRI_6 = yf.download(\"BMRI.JK\", start=\"2022-05-10\", end=\"2022-11-10\")\n",
        "BMRI_6.insert(4,\"Return\", BMRI_6['Close'].pct_change())\n",
        "BMRI_6 = BMRI_6.dropna()\n",
        "BMRI_6_test = yf.download(\"BMRI.JK\", start=\"2022-11-09\", end=\"2022-12-10\")\n",
        "BMRI_6_test.insert(4,\"Return\", BMRI_6_test['Close'].pct_change())\n",
        "BMRI_6_test = BMRI_6_test.dropna()\n",
        "training_BMRI_6 = BMRI_6.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BMRI_6_scaled = sc.fit_transform(training_BMRI_6)\n",
        "X_BMRI_6_train = []\n",
        "y_BMRI_6_train = []\n",
        "for i in range(days_period, len(BMRI_6)-1):\n",
        "    X_BMRI_6_train.append(training_BMRI_6_scaled[i-days_period:i, 0])\n",
        "    y_BMRI_6_train.append(training_BMRI_6_scaled[i, 0])\n",
        "X_BMRI_6_train, y_BMRI_6_train = np.array(X_BMRI_6_train), np.array(y_BMRI_6_train)\n",
        "X_BMRI_6_train = np.reshape(X_BMRI_6_train, (X_BMRI_6_train.shape[0], X_BMRI_6_train.shape[1], 1))\n",
        "model_BMRI_6 = Sequential()\n",
        "model_BMRI_6.add(LSTM(units=50,return_sequences=True,input_shape=(X_BMRI_6_train.shape[1], 1)))\n",
        "model_BMRI_6.add(Dropout(0.2))\n",
        "model_BMRI_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_6.add(Dropout(0.2))\n",
        "model_BMRI_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_6.add(Dropout(0.2))\n",
        "model_BMRI_6.add(LSTM(units=50))\n",
        "model_BMRI_6.add(Dropout(0.2))\n",
        "model_BMRI_6.add(Dense(units=1))\n",
        "model_BMRI_6.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BMRI_6.fit(X_BMRI_6_train,y_BMRI_6_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBRI\n",
        "BBRI_6 = yf.download(\"BBRI.JK\", start=\"2022-05-10\", end=\"2022-11-10\")\n",
        "BBRI_6.insert(4,\"Return\", BBRI_6['Close'].pct_change())\n",
        "BBRI_6 = BBRI_6.dropna()\n",
        "BBRI_6_test = yf.download(\"BBRI.JK\", start=\"2022-11-09\", end=\"2022-12-10\")\n",
        "BBRI_6_test.insert(4,\"Return\", BBRI_6_test['Close'].pct_change())\n",
        "BBRI_6_test = BBRI_6_test.dropna()\n",
        "training_BBRI_6 = BBRI_6.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBRI_6_scaled = sc.fit_transform(training_BBRI_6)\n",
        "X_BBRI_6_train = []\n",
        "y_BBRI_6_train = []\n",
        "for i in range(days_period, len(BBRI_6)-1):\n",
        "    X_BBRI_6_train.append(training_BBRI_6_scaled[i-days_period:i, 0])\n",
        "    y_BBRI_6_train.append(training_BBRI_6_scaled[i, 0])\n",
        "X_BBRI_6_train, y_BBRI_6_train = np.array(X_BBRI_6_train), np.array(y_BBRI_6_train)\n",
        "X_BBRI_6_train = np.reshape(X_BBRI_6_train, (X_BBRI_6_train.shape[0], X_BBRI_6_train.shape[1], 1))\n",
        "model_BBRI_6 = Sequential()\n",
        "model_BBRI_6.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBRI_6_train.shape[1], 1)))\n",
        "model_BBRI_6.add(Dropout(0.2))\n",
        "model_BBRI_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_6.add(Dropout(0.2))\n",
        "model_BBRI_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_6.add(Dropout(0.2))\n",
        "model_BBRI_6.add(LSTM(units=50))\n",
        "model_BBRI_6.add(Dropout(0.2))\n",
        "model_BBRI_6.add(Dense(units=1))\n",
        "model_BBRI_6.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBRI_6.fit(X_BBRI_6_train,y_BBRI_6_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBTN\n",
        "BBTN_6 = yf.download(\"BBTN.JK\", start=\"2022-05-10\", end=\"2022-11-10\")\n",
        "BBTN_6.insert(4,\"Return\", BBTN_6['Close'].pct_change())\n",
        "BBTN_6 = BBTN_6.dropna()\n",
        "BBTN_6_test = yf.download(\"BBTN.JK\", start=\"2022-11-09\", end=\"2022-12-10\")\n",
        "BBTN_6_test.insert(4,\"Return\", BBTN_6_test['Close'].pct_change())\n",
        "BBTN_6_test = BBTN_6_test.dropna()\n",
        "training_BBTN_6 = BBTN_6.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBTN_6_scaled = sc.fit_transform(training_BBTN_6)\n",
        "X_BBTN_6_train = []\n",
        "y_BBTN_6_train = []\n",
        "for i in range(days_period, len(BBTN_6)-1):\n",
        "    X_BBTN_6_train.append(training_BBTN_6_scaled[i-days_period:i, 0])\n",
        "    y_BBTN_6_train.append(training_BBTN_6_scaled[i, 0])\n",
        "X_BBTN_6_train, y_BBTN_6_train = np.array(X_BBTN_6_train), np.array(y_BBTN_6_train)\n",
        "X_BBTN_6_train = np.reshape(X_BBTN_6_train, (X_BBTN_6_train.shape[0], X_BBTN_6_train.shape[1], 1))\n",
        "model_BBTN_6 = Sequential()\n",
        "model_BBTN_6.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBTN_6_train.shape[1], 1)))\n",
        "model_BBTN_6.add(Dropout(0.2))\n",
        "model_BBTN_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_6.add(Dropout(0.2))\n",
        "model_BBTN_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_6.add(Dropout(0.2))\n",
        "model_BBTN_6.add(LSTM(units=50))\n",
        "model_BBTN_6.add(Dropout(0.2))\n",
        "model_BBTN_6.add(Dense(units=1))\n",
        "model_BBTN_6.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBTN_6.fit(X_BBTN_6_train,y_BBTN_6_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BUMI\n",
        "BUMI_6 = yf.download(\"BUMI.JK\", start=\"2022-05-10\", end=\"2022-11-10\")\n",
        "BUMI_6.insert(4,\"Return\", BUMI_6['Close'].pct_change())\n",
        "BUMI_6 = BUMI_6.dropna()\n",
        "BUMI_6_test = yf.download(\"BUMI.JK\", start=\"2022-11-09\", end=\"2022-12-10\")\n",
        "BUMI_6_test.insert(4,\"Return\", BUMI_6_test['Close'].pct_change())\n",
        "BUMI_6_test = BUMI_6_test.dropna()\n",
        "training_BUMI_6 = BUMI_6.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BUMI_6_scaled = sc.fit_transform(training_BUMI_6)\n",
        "X_BUMI_6_train = []\n",
        "y_BUMI_6_train = []\n",
        "for i in range(days_period, len(BUMI_6)-1):\n",
        "    X_BUMI_6_train.append(training_BUMI_6_scaled[i-days_period:i, 0])\n",
        "    y_BUMI_6_train.append(training_BUMI_6_scaled[i, 0])\n",
        "X_BUMI_6_train, y_BUMI_6_train = np.array(X_BUMI_6_train), np.array(y_BUMI_6_train)\n",
        "X_BUMI_6_train = np.reshape(X_BUMI_6_train, (X_BUMI_6_train.shape[0], X_BUMI_6_train.shape[1], 1))\n",
        "model_BUMI_6 = Sequential()\n",
        "model_BUMI_6.add(LSTM(units=50,return_sequences=True,input_shape=(X_BUMI_6_train.shape[1], 1)))\n",
        "model_BUMI_6.add(Dropout(0.2))\n",
        "model_BUMI_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_6.add(Dropout(0.2))\n",
        "model_BUMI_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_6.add(Dropout(0.2))\n",
        "model_BUMI_6.add(LSTM(units=50))\n",
        "model_BUMI_6.add(Dropout(0.2))\n",
        "model_BUMI_6.add(Dense(units=1))\n",
        "model_BUMI_6.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BUMI_6.fit(X_BUMI_6_train,y_BUMI_6_train,epochs=10,batch_size=16)\n",
        "\n",
        "# MFIN\n",
        "MFIN_6 = yf.download(\"MFIN.JK\", start=\"2022-05-10\", end=\"2022-11-10\")\n",
        "MFIN_6.insert(4,\"Return\", MFIN_6['Close'].pct_change())\n",
        "MFIN_6 = MFIN_6.dropna()\n",
        "MFIN_6_test = yf.download(\"MFIN.JK\", start=\"2022-11-09\", end=\"2022-12-10\")\n",
        "MFIN_6_test.insert(4,\"Return\", MFIN_6_test['Close'].pct_change())\n",
        "MFIN_6_test = MFIN_6_test.dropna()\n",
        "training_MFIN_6 = MFIN_6.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_MFIN_6_scaled = sc.fit_transform(training_MFIN_6)\n",
        "X_MFIN_6_train = []\n",
        "y_MFIN_6_train = []\n",
        "for i in range(days_period, len(MFIN_6)-1):\n",
        "    X_MFIN_6_train.append(training_MFIN_6_scaled[i-days_period:i, 0])\n",
        "    y_MFIN_6_train.append(training_MFIN_6_scaled[i, 0])\n",
        "X_MFIN_6_train, y_MFIN_6_train = np.array(X_MFIN_6_train), np.array(y_MFIN_6_train)\n",
        "X_MFIN_6_train = np.reshape(X_MFIN_6_train, (X_MFIN_6_train.shape[0], X_MFIN_6_train.shape[1], 1))\n",
        "model_MFIN_6 = Sequential()\n",
        "model_MFIN_6.add(LSTM(units=50,return_sequences=True,input_shape=(X_MFIN_6_train.shape[1], 1)))\n",
        "model_MFIN_6.add(Dropout(0.2))\n",
        "model_MFIN_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_6.add(Dropout(0.2))\n",
        "model_MFIN_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_6.add(Dropout(0.2))\n",
        "model_MFIN_6.add(LSTM(units=50))\n",
        "model_MFIN_6.add(Dropout(0.2))\n",
        "model_MFIN_6.add(Dense(units=1))\n",
        "model_MFIN_6.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_MFIN_6.fit(X_MFIN_6_train,y_MFIN_6_train,epochs=10,batch_size=16)\n",
        "\n",
        "# EXCL\n",
        "EXCL_6 = yf.download(\"EXCL.JK\", start=\"2022-05-10\", end=\"2022-11-10\")\n",
        "EXCL_6.insert(4,\"Return\", EXCL_6['Close'].pct_change())\n",
        "EXCL_6 = EXCL_6.dropna()\n",
        "EXCL_6_test = yf.download(\"EXCL.JK\", start=\"2022-11-09\", end=\"2022-12-10\")\n",
        "EXCL_6_test.insert(4,\"Return\", EXCL_6_test['Close'].pct_change())\n",
        "EXCL_6_test = EXCL_6_test.dropna()\n",
        "training_EXCL_6 = EXCL_6.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_EXCL_6_scaled = sc.fit_transform(training_EXCL_6)\n",
        "X_EXCL_6_train = []\n",
        "y_EXCL_6_train = []\n",
        "for i in range(days_period, len(EXCL_6)-1):\n",
        "    X_EXCL_6_train.append(training_EXCL_6_scaled[i-days_period:i, 0])\n",
        "    y_EXCL_6_train.append(training_EXCL_6_scaled[i, 0])\n",
        "X_EXCL_6_train, y_EXCL_6_train = np.array(X_EXCL_6_train), np.array(y_EXCL_6_train)\n",
        "X_EXCL_6_train = np.reshape(X_EXCL_6_train, (X_EXCL_6_train.shape[0], X_EXCL_6_train.shape[1], 1))\n",
        "model_EXCL_6 = Sequential()\n",
        "model_EXCL_6.add(LSTM(units=50,return_sequences=True,input_shape=(X_EXCL_6_train.shape[1], 1)))\n",
        "model_EXCL_6.add(Dropout(0.2))\n",
        "model_EXCL_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_6.add(Dropout(0.2))\n",
        "model_EXCL_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_6.add(Dropout(0.2))\n",
        "model_EXCL_6.add(LSTM(units=50))\n",
        "model_EXCL_6.add(Dropout(0.2))\n",
        "model_EXCL_6.add(Dense(units=1))\n",
        "model_EXCL_6.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_EXCL_6.fit(X_EXCL_6_train,y_EXCL_6_train,epochs=10,batch_size=16)\n",
        "\n",
        "# PGAS\n",
        "PGAS_6 = yf.download(\"PGAS.JK\", start=\"2022-05-10\", end=\"2022-11-10\")\n",
        "PGAS_6.insert(4,\"Return\", PGAS_6['Close'].pct_change())\n",
        "PGAS_6 = PGAS_6.dropna()\n",
        "PGAS_6_test = yf.download(\"PGAS.JK\", start=\"2022-11-09\", end=\"2022-12-10\")\n",
        "PGAS_6_test.insert(4,\"Return\", PGAS_6_test['Close'].pct_change())\n",
        "PGAS_6_test = PGAS_6_test.dropna()\n",
        "training_PGAS_6 = PGAS_6.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_PGAS_6_scaled = sc.fit_transform(training_PGAS_6)\n",
        "X_PGAS_6_train = []\n",
        "y_PGAS_6_train = []\n",
        "for i in range(days_period, len(PGAS_6)-1):\n",
        "    X_PGAS_6_train.append(training_PGAS_6_scaled[i-days_period:i, 0])\n",
        "    y_PGAS_6_train.append(training_PGAS_6_scaled[i, 0])\n",
        "X_PGAS_6_train, y_PGAS_6_train = np.array(X_PGAS_6_train), np.array(y_PGAS_6_train)\n",
        "X_PGAS_6_train = np.reshape(X_PGAS_6_train, (X_PGAS_6_train.shape[0], X_PGAS_6_train.shape[1], 1))\n",
        "model_PGAS_6 = Sequential()\n",
        "model_PGAS_6.add(LSTM(units=50,return_sequences=True,input_shape=(X_PGAS_6_train.shape[1], 1)))\n",
        "model_PGAS_6.add(Dropout(0.2))\n",
        "model_PGAS_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_6.add(Dropout(0.2))\n",
        "model_PGAS_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_6.add(Dropout(0.2))\n",
        "model_PGAS_6.add(LSTM(units=50))\n",
        "model_PGAS_6.add(Dropout(0.2))\n",
        "model_PGAS_6.add(Dense(units=1))\n",
        "model_PGAS_6.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_PGAS_6.fit(X_PGAS_6_train,y_PGAS_6_train,epochs=10,batch_size=16)\n",
        "\n",
        "# TLKM\n",
        "TLKM_6 = yf.download(\"TLKM.JK\", start=\"2022-05-10\", end=\"2022-11-10\")\n",
        "TLKM_6.insert(4,\"Return\", TLKM_6['Close'].pct_change())\n",
        "TLKM_6 = TLKM_6.dropna()\n",
        "TLKM_6_test = yf.download(\"TLKM.JK\", start=\"2022-11-09\", end=\"2022-12-10\")\n",
        "TLKM_6_test.insert(4,\"Return\", TLKM_6_test['Close'].pct_change())\n",
        "TLKM_6_test = TLKM_6_test.dropna()\n",
        "training_TLKM_6 = TLKM_6.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_TLKM_6_scaled = sc.fit_transform(training_TLKM_6)\n",
        "X_TLKM_6_train = []\n",
        "y_TLKM_6_train = []\n",
        "for i in range(days_period, len(TLKM_6)-1):\n",
        "    X_TLKM_6_train.append(training_TLKM_6_scaled[i-days_period:i, 0])\n",
        "    y_TLKM_6_train.append(training_TLKM_6_scaled[i, 0])\n",
        "X_TLKM_6_train, y_TLKM_6_train = np.array(X_TLKM_6_train), np.array(y_TLKM_6_train)\n",
        "X_TLKM_6_train = np.reshape(X_TLKM_6_train, (X_TLKM_6_train.shape[0], X_TLKM_6_train.shape[1], 1))\n",
        "model_TLKM_6 = Sequential()\n",
        "model_TLKM_6.add(LSTM(units=50,return_sequences=True,input_shape=(X_TLKM_6_train.shape[1], 1)))\n",
        "model_TLKM_6.add(Dropout(0.2))\n",
        "model_TLKM_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_6.add(Dropout(0.2))\n",
        "model_TLKM_6.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_6.add(Dropout(0.2))\n",
        "model_TLKM_6.add(LSTM(units=50))\n",
        "model_TLKM_6.add(Dropout(0.2))\n",
        "model_TLKM_6.add(Dense(units=1))\n",
        "model_TLKM_6.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_TLKM_6.fit(X_TLKM_6_train,y_TLKM_6_train,epochs=10,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chB24JAGG3hS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49059b13-6da1-4ba3-d929-a713a6a7d653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        }
      ],
      "source": [
        "# ADRO\n",
        "real_ADRO_6_return = ADRO_6_test.iloc[:, 4:5].values\n",
        "real_ADRO_6_return = real_ADRO_6_return[:days_predict]\n",
        "ADRO_6_total = ADRO_6['Close'].copy(deep=True)\n",
        "inputs_ADRO_6 = ADRO_6_total[len(ADRO_6) - days_period: len(ADRO_6)].values\n",
        "inputs_ADRO_6 = inputs_ADRO_6.reshape(-1,1)\n",
        "inputs_ADRO_6 = sc.transform(inputs_ADRO_6)\n",
        "predicted_ADRO_6_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ADRO_6_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ADRO_6_test.append(inputs_ADRO_6[i:i+days_period, 0])\n",
        "  X_ADRO_6_test = np.array(X_ADRO_6_test)\n",
        "  X_ADRO_6_test = np.reshape(X_ADRO_6_test, (X_ADRO_6_test.shape[0], X_ADRO_6_test.shape[1], 1))\n",
        "  predicted_ADRO_6_return[j] = model_ADRO_6.predict(X_ADRO_6_test)\n",
        "  inputs_ADRO_6 += (predicted_ADRO_6_return[j])\n",
        "  inputs_ADRO_6 = inputs_ADRO_6.reshape(-1,1)\n",
        "\n",
        "# ASII\n",
        "real_ASII_6_return = ASII_6_test.iloc[:, 4:5].values\n",
        "real_ASII_6_return = real_ASII_6_return[:days_predict]\n",
        "ASII_6_total = ASII_6['Close'].copy(deep=True)\n",
        "inputs_ASII_6 = ASII_6_total[len(ASII_6) - days_period: len(ASII_6)].values\n",
        "inputs_ASII_6 = inputs_ASII_6.reshape(-1,1)\n",
        "inputs_ASII_6 = sc.transform(inputs_ASII_6)\n",
        "predicted_ASII_6_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ASII_6_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ASII_6_test.append(inputs_ASII_6[i:i+days_period, 0])\n",
        "  X_ASII_6_test = np.array(X_ASII_6_test)\n",
        "  X_ASII_6_test = np.reshape(X_ASII_6_test, (X_ASII_6_test.shape[0], X_ASII_6_test.shape[1], 1))\n",
        "  predicted_ASII_6_return[j] = model_ASII_6.predict(X_ASII_6_test)\n",
        "  inputs_ASII_6 += (predicted_ASII_6_return[j])\n",
        "  inputs_ASII_6 = inputs_ASII_6.reshape(-1,1)\n",
        "\n",
        "# BMRI\n",
        "real_BMRI_6_return = BMRI_6_test.iloc[:, 4:5].values\n",
        "real_BMRI_6_return = real_BMRI_6_return[:days_predict]\n",
        "BMRI_6_total = BMRI_6['Close'].copy(deep=True)\n",
        "inputs_BMRI_6 = BMRI_6_total[len(BMRI_6) - days_period: len(BMRI_6)].values\n",
        "inputs_BMRI_6 = inputs_BMRI_6.reshape(-1,1)\n",
        "inputs_BMRI_6 = sc.transform(inputs_BMRI_6)\n",
        "predicted_BMRI_6_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BMRI_6_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BMRI_6_test.append(inputs_BMRI_6[i:i+days_period, 0])\n",
        "  X_BMRI_6_test = np.array(X_BMRI_6_test)\n",
        "  X_BMRI_6_test = np.reshape(X_BMRI_6_test, (X_BMRI_6_test.shape[0], X_BMRI_6_test.shape[1], 1))\n",
        "  predicted_BMRI_6_return[j] = model_BMRI_6.predict(X_BMRI_6_test)\n",
        "  inputs_BMRI_6 += (predicted_BMRI_6_return[j])\n",
        "  inputs_BMRI_6 = inputs_BMRI_6.reshape(-1,1)\n",
        "\n",
        "# BBRI\n",
        "real_BBRI_6_return = BBRI_6_test.iloc[:, 4:5].values\n",
        "real_BBRI_6_return = real_BBRI_6_return[:days_predict]\n",
        "BBRI_6_total = BBRI_6['Close'].copy(deep=True)\n",
        "inputs_BBRI_6 = BBRI_6_total[len(BBRI_6) - days_period: len(BBRI_6)].values\n",
        "inputs_BBRI_6 = inputs_BBRI_6.reshape(-1,1)\n",
        "inputs_BBRI_6 = sc.transform(inputs_BBRI_6)\n",
        "predicted_BBRI_6_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBRI_6_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBRI_6_test.append(inputs_BBRI_6[i:i+days_period, 0])\n",
        "  X_BBRI_6_test = np.array(X_BBRI_6_test)\n",
        "  X_BBRI_6_test = np.reshape(X_BBRI_6_test, (X_BBRI_6_test.shape[0], X_BBRI_6_test.shape[1], 1))\n",
        "  predicted_BBRI_6_return[j] = model_BBRI_6.predict(X_BBRI_6_test)\n",
        "  inputs_BBRI_6 += (predicted_BBRI_6_return[j])\n",
        "  inputs_BBRI_6 = inputs_BBRI_6.reshape(-1,1)\n",
        "\n",
        "# BBTN\n",
        "real_BBTN_6_return = BBTN_6_test.iloc[:, 4:5].values\n",
        "real_BBTN_6_return = real_BBTN_6_return[:days_predict]\n",
        "BBTN_6_total = BBTN_6['Close'].copy(deep=True)\n",
        "inputs_BBTN_6 = BBTN_6_total[len(BBTN_6) - days_period: len(BBTN_6)].values\n",
        "inputs_BBTN_6 = inputs_BBTN_6.reshape(-1,1)\n",
        "inputs_BBTN_6 = sc.transform(inputs_BBTN_6)\n",
        "predicted_BBTN_6_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBTN_6_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBTN_6_test.append(inputs_BBTN_6[i:i+days_period, 0])\n",
        "  X_BBTN_6_test = np.array(X_BBTN_6_test)\n",
        "  X_BBTN_6_test = np.reshape(X_BBTN_6_test, (X_BBTN_6_test.shape[0], X_BBTN_6_test.shape[1], 1))\n",
        "  predicted_BBTN_6_return[j] = model_BBTN_6.predict(X_BBTN_6_test)\n",
        "  inputs_BBTN_6 += (predicted_BBTN_6_return[j])\n",
        "  inputs_BBTN_6 = inputs_BBTN_6.reshape(-1,1)\n",
        "\n",
        "# BUMI\n",
        "real_BUMI_6_return = BUMI_6_test.iloc[:, 4:5].values\n",
        "real_BUMI_6_return = real_BUMI_6_return[:days_predict]\n",
        "BUMI_6_total = BUMI_6['Close'].copy(deep=True)\n",
        "inputs_BUMI_6 = BUMI_6_total[len(BUMI_6) - days_period: len(BUMI_6)].values\n",
        "inputs_BUMI_6 = inputs_BUMI_6.reshape(-1,1)\n",
        "inputs_BUMI_6 = sc.transform(inputs_BUMI_6)\n",
        "predicted_BUMI_6_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BUMI_6_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BUMI_6_test.append(inputs_BUMI_6[i:i+days_period, 0])\n",
        "  X_BUMI_6_test = np.array(X_BUMI_6_test)\n",
        "  X_BUMI_6_test = np.reshape(X_BUMI_6_test, (X_BUMI_6_test.shape[0], X_BUMI_6_test.shape[1], 1))\n",
        "  predicted_BUMI_6_return[j] = model_BUMI_6.predict(X_BUMI_6_test)\n",
        "  inputs_BUMI_6 += (predicted_BUMI_6_return[j])\n",
        "  inputs_BUMI_6 = inputs_BUMI_6.reshape(-1,1)\n",
        "\n",
        "# MFIN\n",
        "real_MFIN_6_return = MFIN_6_test.iloc[:, 4:5].values\n",
        "real_MFIN_6_return = real_MFIN_6_return[:days_predict]\n",
        "MFIN_6_total = MFIN_6['Close'].copy(deep=True)\n",
        "inputs_MFIN_6 = MFIN_6_total[len(MFIN_6) - days_period: len(MFIN_6)].values\n",
        "inputs_MFIN_6 = inputs_MFIN_6.reshape(-1,1)\n",
        "inputs_MFIN_6 = sc.transform(inputs_MFIN_6)\n",
        "predicted_MFIN_6_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_MFIN_6_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_MFIN_6_test.append(inputs_MFIN_6[i:i+days_period, 0])\n",
        "  X_MFIN_6_test = np.array(X_MFIN_6_test)\n",
        "  X_MFIN_6_test = np.reshape(X_MFIN_6_test, (X_MFIN_6_test.shape[0], X_MFIN_6_test.shape[1], 1))\n",
        "  predicted_MFIN_6_return[j] = model_MFIN_6.predict(X_MFIN_6_test)\n",
        "  inputs_MFIN_6 += (predicted_MFIN_6_return[j])\n",
        "  inputs_MFIN_6 = inputs_MFIN_6.reshape(-1,1)\n",
        "\n",
        "# EXCL\n",
        "real_EXCL_6_return = EXCL_6_test.iloc[:, 4:5].values\n",
        "real_EXCL_6_return = real_EXCL_6_return[:days_predict]\n",
        "EXCL_6_total = EXCL_6['Close'].copy(deep=True)\n",
        "inputs_EXCL_6 = EXCL_6_total[len(EXCL_6) - days_period: len(EXCL_6)].values\n",
        "inputs_EXCL_6 = inputs_EXCL_6.reshape(-1,1)\n",
        "inputs_EXCL_6 = sc.transform(inputs_EXCL_6)\n",
        "predicted_EXCL_6_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_EXCL_6_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_EXCL_6_test.append(inputs_EXCL_6[i:i+days_period, 0])\n",
        "  X_EXCL_6_test = np.array(X_EXCL_6_test)\n",
        "  X_EXCL_6_test = np.reshape(X_EXCL_6_test, (X_EXCL_6_test.shape[0], X_EXCL_6_test.shape[1], 1))\n",
        "  predicted_EXCL_6_return[j] = model_EXCL_6.predict(X_EXCL_6_test)\n",
        "  inputs_EXCL_6 += (predicted_EXCL_6_return[j])\n",
        "  inputs_EXCL_6 = inputs_EXCL_6.reshape(-1,1)\n",
        "\n",
        "# PGAS\n",
        "real_PGAS_6_return = PGAS_6_test.iloc[:, 4:5].values\n",
        "real_PGAS_6_return = real_PGAS_6_return[:days_predict]\n",
        "PGAS_6_total = PGAS_6['Close'].copy(deep=True)\n",
        "inputs_PGAS_6 = PGAS_6_total[len(PGAS_6) - days_period: len(PGAS_6)].values\n",
        "inputs_PGAS_6 = inputs_PGAS_6.reshape(-1,1)\n",
        "inputs_PGAS_6 = sc.transform(inputs_PGAS_6)\n",
        "predicted_PGAS_6_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_PGAS_6_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_PGAS_6_test.append(inputs_PGAS_6[i:i+days_period, 0])\n",
        "  X_PGAS_6_test = np.array(X_PGAS_6_test)\n",
        "  X_PGAS_6_test = np.reshape(X_PGAS_6_test, (X_PGAS_6_test.shape[0], X_PGAS_6_test.shape[1], 1))\n",
        "  predicted_PGAS_6_return[j] = model_PGAS_6.predict(X_PGAS_6_test)\n",
        "  inputs_PGAS_6 += (predicted_PGAS_6_return[j])\n",
        "  inputs_PGAS_6 = inputs_PGAS_6.reshape(-1,1)\n",
        "\n",
        "# TLKM\n",
        "real_TLKM_6_return = TLKM_6_test.iloc[:, 4:5].values\n",
        "real_TLKM_6_return = real_TLKM_6_return[:days_predict]\n",
        "TLKM_6_total = TLKM_6['Close'].copy(deep=True)\n",
        "inputs_TLKM_6 = TLKM_6_total[len(TLKM_6) - days_period: len(TLKM_6)].values\n",
        "inputs_TLKM_6 = inputs_TLKM_6.reshape(-1,1)\n",
        "inputs_TLKM_6 = sc.transform(inputs_TLKM_6)\n",
        "predicted_TLKM_6_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_TLKM_6_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_TLKM_6_test.append(inputs_TLKM_6[i:i+days_period, 0])\n",
        "  X_TLKM_6_test = np.array(X_TLKM_6_test)\n",
        "  X_TLKM_6_test = np.reshape(X_TLKM_6_test, (X_TLKM_6_test.shape[0], X_TLKM_6_test.shape[1], 1))\n",
        "  predicted_TLKM_6_return[j] = model_TLKM_6.predict(X_TLKM_6_test)\n",
        "  inputs_TLKM_6 += (predicted_TLKM_6_return[j])\n",
        "  inputs_TLKM_6 = inputs_TLKM_6.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4x2VlhgG3hU"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "predicted_ADRO_6_return = np.squeeze(np.asarray(predicted_ADRO_6_return))\n",
        "predicted_ADRO_6_return = predicted_ADRO_6_return.reshape(-1,1)\n",
        "predicted_ADRO_6_return = sc.inverse_transform(predicted_ADRO_6_return)\n",
        "# ASII\n",
        "predicted_ASII_6_return = np.squeeze(np.asarray(predicted_ASII_6_return))\n",
        "predicted_ASII_6_return = predicted_ASII_6_return.reshape(-1,1)\n",
        "predicted_ASII_6_return = sc.inverse_transform(predicted_ASII_6_return)\n",
        "# BMRI\n",
        "predicted_BMRI_6_return = np.squeeze(np.asarray(predicted_BMRI_6_return))\n",
        "predicted_BMRI_6_return = predicted_BMRI_6_return.reshape(-1,1)\n",
        "predicted_BMRI_6_return = sc.inverse_transform(predicted_BMRI_6_return)\n",
        "# BBRI\n",
        "predicted_BBRI_6_return = np.squeeze(np.asarray(predicted_BBRI_6_return))\n",
        "predicted_BBRI_6_return = predicted_BBRI_6_return.reshape(-1,1)\n",
        "predicted_BBRI_6_return = sc.inverse_transform(predicted_BBRI_6_return)\n",
        "# BBTN\n",
        "predicted_BBTN_6_return = np.squeeze(np.asarray(predicted_BBTN_6_return))\n",
        "predicted_BBTN_6_return = predicted_BBTN_6_return.reshape(-1,1)\n",
        "predicted_BBTN_6_return = sc.inverse_transform(predicted_BBTN_6_return)\n",
        "# BUMI\n",
        "predicted_BUMI_6_return = np.squeeze(np.asarray(predicted_BUMI_6_return))\n",
        "predicted_BUMI_6_return = predicted_BUMI_6_return.reshape(-1,1)\n",
        "predicted_BUMI_6_return = sc.inverse_transform(predicted_BUMI_6_return)\n",
        "# MFIN\n",
        "predicted_MFIN_6_return = np.squeeze(np.asarray(predicted_MFIN_6_return))\n",
        "predicted_MFIN_6_return = predicted_MFIN_6_return.reshape(-1,1)\n",
        "predicted_MFIN_6_return = sc.inverse_transform(predicted_MFIN_6_return)\n",
        "# EXCL\n",
        "predicted_EXCL_6_return = np.squeeze(np.asarray(predicted_EXCL_6_return))\n",
        "predicted_EXCL_6_return = predicted_EXCL_6_return.reshape(-1,1)\n",
        "predicted_EXCL_6_return = sc.inverse_transform(predicted_EXCL_6_return)\n",
        "# PGAS\n",
        "predicted_PGAS_6_return = np.squeeze(np.asarray(predicted_PGAS_6_return))\n",
        "predicted_PGAS_6_return = predicted_PGAS_6_return.reshape(-1,1)\n",
        "predicted_PGAS_6_return = sc.inverse_transform(predicted_PGAS_6_return)\n",
        "# TLKM\n",
        "predicted_TLKM_6_return = np.squeeze(np.asarray(predicted_TLKM_6_return))\n",
        "predicted_TLKM_6_return = predicted_TLKM_6_return.reshape(-1,1)\n",
        "predicted_TLKM_6_return = sc.inverse_transform(predicted_TLKM_6_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1ZtlYfsG3hV"
      },
      "outputs": [],
      "source": [
        "predicted6 = pd.DataFrame(predicted_ADRO_6_return)\n",
        "predicted6.rename(columns={0:'ADRO'}, inplace=True)\n",
        "predicted6.insert(1,\"ASII\", predicted_ASII_6_return)\n",
        "predicted6.insert(2,\"BBRI\", predicted_BBRI_6_return)\n",
        "predicted6.insert(3,\"BBTN\", predicted_BBTN_6_return)\n",
        "predicted6.insert(4,\"BMRI\", predicted_BMRI_6_return)\n",
        "predicted6.insert(5,\"BUMI\", predicted_BUMI_6_return)\n",
        "predicted6.insert(6,\"EXCL\", predicted_EXCL_6_return)\n",
        "predicted6.insert(7,\"MFIN\", predicted_MFIN_6_return)\n",
        "predicted6.insert(8,\"PGAS\", predicted_PGAS_6_return)\n",
        "predicted6.insert(9,\"TLKM\", predicted_TLKM_6_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "SHBY0VzOQyGq",
        "outputId": "d101872b-b3ba-4cfe-ac43-216eb4285729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADRO      ASII      BBRI      BBTN      BMRI      BUMI      EXCL  \\\n",
              "0  0.024882  0.019698  0.016598  0.034896  0.017270 -0.021096  0.014516   \n",
              "1  0.024138  0.019210  0.015812  0.034094  0.016427 -0.021248  0.013747   \n",
              "2  0.023212  0.018587  0.014853  0.033111  0.015414 -0.021437  0.012806   \n",
              "3  0.022067  0.017798  0.013691  0.031907  0.014200 -0.021671  0.011663   \n",
              "4  0.020662  0.016804  0.012291  0.030442  0.012754 -0.021961  0.010286   \n",
              "5  0.018951  0.015564  0.010618  0.028665  0.011042 -0.022322  0.008639   \n",
              "6  0.016887  0.014028  0.008635  0.026522  0.009028 -0.022767  0.006689   \n",
              "7  0.014417  0.012142  0.006306  0.023952  0.006679 -0.023314  0.004399   \n",
              "8  0.011492  0.009850  0.003599  0.020890  0.003962 -0.023979  0.001741   \n",
              "9  0.008069  0.007095  0.000488  0.017272  0.000853 -0.024783 -0.001307   \n",
              "\n",
              "       MFIN      PGAS      TLKM  \n",
              "0  0.010913  0.014389 -0.005046  \n",
              "1  0.010318  0.013599 -0.005821  \n",
              "2  0.009594  0.012645 -0.006702  \n",
              "3  0.008716  0.011510 -0.007702  \n",
              "4  0.007654  0.010159 -0.008832  \n",
              "5  0.006377  0.008558 -0.010104  \n",
              "6  0.004848  0.006679 -0.011532  \n",
              "7  0.003027  0.004492 -0.013126  \n",
              "8  0.000877  0.001970 -0.014895  \n",
              "9 -0.001642 -0.000924 -0.016847  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b8b2e44-687b-4aa1-bfb6-ea85138e6bd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADRO</th>\n",
              "      <th>ASII</th>\n",
              "      <th>BBRI</th>\n",
              "      <th>BBTN</th>\n",
              "      <th>BMRI</th>\n",
              "      <th>BUMI</th>\n",
              "      <th>EXCL</th>\n",
              "      <th>MFIN</th>\n",
              "      <th>PGAS</th>\n",
              "      <th>TLKM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.024882</td>\n",
              "      <td>0.019698</td>\n",
              "      <td>0.016598</td>\n",
              "      <td>0.034896</td>\n",
              "      <td>0.017270</td>\n",
              "      <td>-0.021096</td>\n",
              "      <td>0.014516</td>\n",
              "      <td>0.010913</td>\n",
              "      <td>0.014389</td>\n",
              "      <td>-0.005046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.024138</td>\n",
              "      <td>0.019210</td>\n",
              "      <td>0.015812</td>\n",
              "      <td>0.034094</td>\n",
              "      <td>0.016427</td>\n",
              "      <td>-0.021248</td>\n",
              "      <td>0.013747</td>\n",
              "      <td>0.010318</td>\n",
              "      <td>0.013599</td>\n",
              "      <td>-0.005821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.023212</td>\n",
              "      <td>0.018587</td>\n",
              "      <td>0.014853</td>\n",
              "      <td>0.033111</td>\n",
              "      <td>0.015414</td>\n",
              "      <td>-0.021437</td>\n",
              "      <td>0.012806</td>\n",
              "      <td>0.009594</td>\n",
              "      <td>0.012645</td>\n",
              "      <td>-0.006702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.022067</td>\n",
              "      <td>0.017798</td>\n",
              "      <td>0.013691</td>\n",
              "      <td>0.031907</td>\n",
              "      <td>0.014200</td>\n",
              "      <td>-0.021671</td>\n",
              "      <td>0.011663</td>\n",
              "      <td>0.008716</td>\n",
              "      <td>0.011510</td>\n",
              "      <td>-0.007702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.020662</td>\n",
              "      <td>0.016804</td>\n",
              "      <td>0.012291</td>\n",
              "      <td>0.030442</td>\n",
              "      <td>0.012754</td>\n",
              "      <td>-0.021961</td>\n",
              "      <td>0.010286</td>\n",
              "      <td>0.007654</td>\n",
              "      <td>0.010159</td>\n",
              "      <td>-0.008832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.018951</td>\n",
              "      <td>0.015564</td>\n",
              "      <td>0.010618</td>\n",
              "      <td>0.028665</td>\n",
              "      <td>0.011042</td>\n",
              "      <td>-0.022322</td>\n",
              "      <td>0.008639</td>\n",
              "      <td>0.006377</td>\n",
              "      <td>0.008558</td>\n",
              "      <td>-0.010104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.016887</td>\n",
              "      <td>0.014028</td>\n",
              "      <td>0.008635</td>\n",
              "      <td>0.026522</td>\n",
              "      <td>0.009028</td>\n",
              "      <td>-0.022767</td>\n",
              "      <td>0.006689</td>\n",
              "      <td>0.004848</td>\n",
              "      <td>0.006679</td>\n",
              "      <td>-0.011532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.014417</td>\n",
              "      <td>0.012142</td>\n",
              "      <td>0.006306</td>\n",
              "      <td>0.023952</td>\n",
              "      <td>0.006679</td>\n",
              "      <td>-0.023314</td>\n",
              "      <td>0.004399</td>\n",
              "      <td>0.003027</td>\n",
              "      <td>0.004492</td>\n",
              "      <td>-0.013126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.011492</td>\n",
              "      <td>0.009850</td>\n",
              "      <td>0.003599</td>\n",
              "      <td>0.020890</td>\n",
              "      <td>0.003962</td>\n",
              "      <td>-0.023979</td>\n",
              "      <td>0.001741</td>\n",
              "      <td>0.000877</td>\n",
              "      <td>0.001970</td>\n",
              "      <td>-0.014895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.008069</td>\n",
              "      <td>0.007095</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>0.017272</td>\n",
              "      <td>0.000853</td>\n",
              "      <td>-0.024783</td>\n",
              "      <td>-0.001307</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>-0.000924</td>\n",
              "      <td>-0.016847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b8b2e44-687b-4aa1-bfb6-ea85138e6bd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b8b2e44-687b-4aa1-bfb6-ea85138e6bd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b8b2e44-687b-4aa1-bfb6-ea85138e6bd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0n3TGP8cg9z"
      },
      "source": [
        "## Data Preparation 7\n",
        "1st of January 2018 - 9th of December 2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn4VsOE2fPZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ffb080-a7da-4578-f725-1ce81770485e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 30s 87ms/step - loss: 0.1817\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 87ms/step - loss: 0.0580\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 83ms/step - loss: 0.0431\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0365\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 83ms/step - loss: 0.0362\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 0.0332\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 83ms/step - loss: 0.0330\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 82ms/step - loss: 0.0355\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 139ms/step - loss: 0.0346\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 133ms/step - loss: 0.0344\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 21s 77ms/step - loss: 0.1430\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0601\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 105ms/step - loss: 0.0549\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 0.0392\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 107ms/step - loss: 0.0405\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 106ms/step - loss: 0.0362\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 94ms/step - loss: 0.0383\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 0.0369\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0346\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0336\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 16s 104ms/step - loss: 0.1402\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 121ms/step - loss: 0.0417\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 117ms/step - loss: 0.0466\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 0.0292\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 119ms/step - loss: 0.0294\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 128ms/step - loss: 0.0274\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 117ms/step - loss: 0.0273\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 116ms/step - loss: 0.0222\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 85ms/step - loss: 0.0257\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 0.0242\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 16s 78ms/step - loss: 0.1138\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0599\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0469\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0390\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0362\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0374\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0363\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 83ms/step - loss: 0.0362\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0354\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0354\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 15s 76ms/step - loss: 0.1726\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0430\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0336\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0204\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0230\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0233\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0229\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 0.0264\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0228\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0222\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 19s 80ms/step - loss: 0.0448\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.0447\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0373\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0296\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0336\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0333\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0322\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.0293\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 82ms/step - loss: 0.0315\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0312\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 18s 113ms/step - loss: 0.1659\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 93ms/step - loss: 0.0387\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 0.0319\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.0219\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 106ms/step - loss: 0.0217\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0151\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0173\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0187\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 82ms/step - loss: 0.0190\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 86ms/step - loss: 0.0220\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 16s 81ms/step - loss: 0.0102\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.0079\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0082\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 0.0080\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 212ms/step - loss: 0.0077\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 2s 241ms/step - loss: 0.0082\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 101ms/step - loss: 0.0079\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 94ms/step - loss: 0.0081\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0080\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0080\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 15s 97ms/step - loss: 0.0999\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 83ms/step - loss: 0.0408\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 96ms/step - loss: 0.0433\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 0.0308\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 0.0299\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 0.0292\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 85ms/step - loss: 0.0280\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0302\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 105ms/step - loss: 0.0293\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 0.0269\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 15s 78ms/step - loss: 0.2266\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 84ms/step - loss: 0.0648\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 84ms/step - loss: 0.0505\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.0386\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0324\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0260\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0315\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0356\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0336\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.0306\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efb7a5a33a0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Period parameters\n",
        "days_period = 20\n",
        "days_predict = 10\n",
        "\n",
        "# ADRO\n",
        "ADRO_7 = yf.download(\"ADRO.JK\", start=\"2022-06-10\", end=\"2022-12-10\")\n",
        "ADRO_7.insert(4,\"Return\", ADRO_7['Close'].pct_change())\n",
        "ADRO_7 = ADRO_7.dropna()\n",
        "ADRO_7_test = yf.download(\"ADRO.JK\", start=\"2022-12-09\", end=\"2023-01-10\")\n",
        "ADRO_7_test.insert(4,\"Return\", ADRO_7_test['Close'].pct_change())\n",
        "ADRO_7_test = ADRO_7_test.dropna()\n",
        "training_ADRO_7 = ADRO_7.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ADRO_7_scaled = sc.fit_transform(training_ADRO_7)\n",
        "X_ADRO_7_train = []\n",
        "y_ADRO_7_train = []\n",
        "for i in range(days_period, len(ADRO_7)-1):\n",
        "    X_ADRO_7_train.append(training_ADRO_7_scaled[i-days_period:i, 0])\n",
        "    y_ADRO_7_train.append(training_ADRO_7_scaled[i, 0])\n",
        "X_ADRO_7_train, y_ADRO_7_train = np.array(X_ADRO_7_train), np.array(y_ADRO_7_train)\n",
        "X_ADRO_7_train = np.reshape(X_ADRO_7_train, (X_ADRO_7_train.shape[0], X_ADRO_7_train.shape[1], 1))\n",
        "model_ADRO_7 = Sequential()\n",
        "model_ADRO_7.add(LSTM(units=50,return_sequences=True,input_shape=(X_ADRO_7_train.shape[1], 1)))\n",
        "model_ADRO_7.add(Dropout(0.2))\n",
        "model_ADRO_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_7.add(Dropout(0.2))\n",
        "model_ADRO_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_7.add(Dropout(0.2))\n",
        "model_ADRO_7.add(LSTM(units=50))\n",
        "model_ADRO_7.add(Dropout(0.2))\n",
        "model_ADRO_7.add(Dense(units=1))\n",
        "model_ADRO_7.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ADRO_7.fit(X_ADRO_7_train,y_ADRO_7_train,epochs=10,batch_size=16)\n",
        "\n",
        "# ASII\n",
        "ASII_7 = yf.download(\"ASII.JK\", start=\"2022-06-10\", end=\"2022-12-10\")\n",
        "ASII_7.insert(4,\"Return\", ASII_7['Close'].pct_change())\n",
        "ASII_7 = ASII_7.dropna()\n",
        "ASII_7_test = yf.download(\"ASII.JK\", start=\"2022-12-09\", end=\"2023-01-10\")\n",
        "ASII_7_test.insert(4,\"Return\", ASII_7_test['Close'].pct_change())\n",
        "ASII_7_test = ASII_7_test.dropna()\n",
        "training_ASII_7 = ASII_7.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ASII_7_scaled = sc.fit_transform(training_ASII_7)\n",
        "X_ASII_7_train = []\n",
        "y_ASII_7_train = []\n",
        "for i in range(days_period, len(ASII_7)-1):\n",
        "    X_ASII_7_train.append(training_ASII_7_scaled[i-days_period:i, 0])\n",
        "    y_ASII_7_train.append(training_ASII_7_scaled[i, 0])\n",
        "X_ASII_7_train, y_ASII_7_train = np.array(X_ASII_7_train), np.array(y_ASII_7_train)\n",
        "X_ASII_7_train = np.reshape(X_ASII_7_train, (X_ASII_7_train.shape[0], X_ASII_7_train.shape[1], 1))\n",
        "model_ASII_7 = Sequential()\n",
        "model_ASII_7.add(LSTM(units=50,return_sequences=True,input_shape=(X_ASII_7_train.shape[1], 1)))\n",
        "model_ASII_7.add(Dropout(0.2))\n",
        "model_ASII_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_7.add(Dropout(0.2))\n",
        "model_ASII_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_7.add(Dropout(0.2))\n",
        "model_ASII_7.add(LSTM(units=50))\n",
        "model_ASII_7.add(Dropout(0.2))\n",
        "model_ASII_7.add(Dense(units=1))\n",
        "model_ASII_7.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ASII_7.fit(X_ASII_7_train,y_ASII_7_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BMRI\n",
        "BMRI_7 = yf.download(\"BMRI.JK\", start=\"2022-06-10\", end=\"2022-12-10\")\n",
        "BMRI_7.insert(4,\"Return\", BMRI_7['Close'].pct_change())\n",
        "BMRI_7 = BMRI_7.dropna()\n",
        "BMRI_7_test = yf.download(\"BMRI.JK\", start=\"2022-12-09\", end=\"2023-01-10\")\n",
        "BMRI_7_test.insert(4,\"Return\", BMRI_7_test['Close'].pct_change())\n",
        "BMRI_7_test = BMRI_7_test.dropna()\n",
        "training_BMRI_7 = BMRI_7.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BMRI_7_scaled = sc.fit_transform(training_BMRI_7)\n",
        "X_BMRI_7_train = []\n",
        "y_BMRI_7_train = []\n",
        "for i in range(days_period, len(BMRI_7)-1):\n",
        "    X_BMRI_7_train.append(training_BMRI_7_scaled[i-days_period:i, 0])\n",
        "    y_BMRI_7_train.append(training_BMRI_7_scaled[i, 0])\n",
        "X_BMRI_7_train, y_BMRI_7_train = np.array(X_BMRI_7_train), np.array(y_BMRI_7_train)\n",
        "X_BMRI_7_train = np.reshape(X_BMRI_7_train, (X_BMRI_7_train.shape[0], X_BMRI_7_train.shape[1], 1))\n",
        "model_BMRI_7 = Sequential()\n",
        "model_BMRI_7.add(LSTM(units=50,return_sequences=True,input_shape=(X_BMRI_7_train.shape[1], 1)))\n",
        "model_BMRI_7.add(Dropout(0.2))\n",
        "model_BMRI_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_7.add(Dropout(0.2))\n",
        "model_BMRI_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_7.add(Dropout(0.2))\n",
        "model_BMRI_7.add(LSTM(units=50))\n",
        "model_BMRI_7.add(Dropout(0.2))\n",
        "model_BMRI_7.add(Dense(units=1))\n",
        "model_BMRI_7.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BMRI_7.fit(X_BMRI_7_train,y_BMRI_7_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBRI\n",
        "BBRI_7 = yf.download(\"BBRI.JK\", start=\"2022-06-10\", end=\"2022-12-10\")\n",
        "BBRI_7.insert(4,\"Return\", BBRI_7['Close'].pct_change())\n",
        "BBRI_7 = BBRI_7.dropna()\n",
        "BBRI_7_test = yf.download(\"BBRI.JK\", start=\"2022-12-09\", end=\"2023-01-10\")\n",
        "BBRI_7_test.insert(4,\"Return\", BBRI_7_test['Close'].pct_change())\n",
        "BBRI_7_test = BBRI_7_test.dropna()\n",
        "training_BBRI_7 = BBRI_7.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBRI_7_scaled = sc.fit_transform(training_BBRI_7)\n",
        "X_BBRI_7_train = []\n",
        "y_BBRI_7_train = []\n",
        "for i in range(days_period, len(BBRI_7)-1):\n",
        "    X_BBRI_7_train.append(training_BBRI_7_scaled[i-days_period:i, 0])\n",
        "    y_BBRI_7_train.append(training_BBRI_7_scaled[i, 0])\n",
        "X_BBRI_7_train, y_BBRI_7_train = np.array(X_BBRI_7_train), np.array(y_BBRI_7_train)\n",
        "X_BBRI_7_train = np.reshape(X_BBRI_7_train, (X_BBRI_7_train.shape[0], X_BBRI_7_train.shape[1], 1))\n",
        "model_BBRI_7 = Sequential()\n",
        "model_BBRI_7.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBRI_7_train.shape[1], 1)))\n",
        "model_BBRI_7.add(Dropout(0.2))\n",
        "model_BBRI_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_7.add(Dropout(0.2))\n",
        "model_BBRI_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_7.add(Dropout(0.2))\n",
        "model_BBRI_7.add(LSTM(units=50))\n",
        "model_BBRI_7.add(Dropout(0.2))\n",
        "model_BBRI_7.add(Dense(units=1))\n",
        "model_BBRI_7.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBRI_7.fit(X_BBRI_7_train,y_BBRI_7_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBTN\n",
        "BBTN_7 = yf.download(\"BBTN.JK\", start=\"2022-06-10\", end=\"2022-12-10\")\n",
        "BBTN_7.insert(4,\"Return\", BBTN_7['Close'].pct_change())\n",
        "BBTN_7 = BBTN_7.dropna()\n",
        "BBTN_7_test = yf.download(\"BBTN.JK\", start=\"2022-12-09\", end=\"2023-01-10\")\n",
        "BBTN_7_test.insert(4,\"Return\", BBTN_7_test['Close'].pct_change())\n",
        "BBTN_7_test = BBTN_7_test.dropna()\n",
        "training_BBTN_7 = BBTN_7.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBTN_7_scaled = sc.fit_transform(training_BBTN_7)\n",
        "X_BBTN_7_train = []\n",
        "y_BBTN_7_train = []\n",
        "for i in range(days_period, len(BBTN_7)-1):\n",
        "    X_BBTN_7_train.append(training_BBTN_7_scaled[i-days_period:i, 0])\n",
        "    y_BBTN_7_train.append(training_BBTN_7_scaled[i, 0])\n",
        "X_BBTN_7_train, y_BBTN_7_train = np.array(X_BBTN_7_train), np.array(y_BBTN_7_train)\n",
        "X_BBTN_7_train = np.reshape(X_BBTN_7_train, (X_BBTN_7_train.shape[0], X_BBTN_7_train.shape[1], 1))\n",
        "model_BBTN_7 = Sequential()\n",
        "model_BBTN_7.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBTN_7_train.shape[1], 1)))\n",
        "model_BBTN_7.add(Dropout(0.2))\n",
        "model_BBTN_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_7.add(Dropout(0.2))\n",
        "model_BBTN_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_7.add(Dropout(0.2))\n",
        "model_BBTN_7.add(LSTM(units=50))\n",
        "model_BBTN_7.add(Dropout(0.2))\n",
        "model_BBTN_7.add(Dense(units=1))\n",
        "model_BBTN_7.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBTN_7.fit(X_BBTN_7_train,y_BBTN_7_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BUMI\n",
        "BUMI_7 = yf.download(\"BUMI.JK\", start=\"2022-06-10\", end=\"2022-12-10\")\n",
        "BUMI_7.insert(4,\"Return\", BUMI_7['Close'].pct_change())\n",
        "BUMI_7 = BUMI_7.dropna()\n",
        "BUMI_7_test = yf.download(\"BUMI.JK\", start=\"2022-12-09\", end=\"2023-01-10\")\n",
        "BUMI_7_test.insert(4,\"Return\", BUMI_7_test['Close'].pct_change())\n",
        "BUMI_7_test = BUMI_7_test.dropna()\n",
        "training_BUMI_7 = BUMI_7.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BUMI_7_scaled = sc.fit_transform(training_BUMI_7)\n",
        "X_BUMI_7_train = []\n",
        "y_BUMI_7_train = []\n",
        "for i in range(days_period, len(BUMI_7)-1):\n",
        "    X_BUMI_7_train.append(training_BUMI_7_scaled[i-days_period:i, 0])\n",
        "    y_BUMI_7_train.append(training_BUMI_7_scaled[i, 0])\n",
        "X_BUMI_7_train, y_BUMI_7_train = np.array(X_BUMI_7_train), np.array(y_BUMI_7_train)\n",
        "X_BUMI_7_train = np.reshape(X_BUMI_7_train, (X_BUMI_7_train.shape[0], X_BUMI_7_train.shape[1], 1))\n",
        "model_BUMI_7 = Sequential()\n",
        "model_BUMI_7.add(LSTM(units=50,return_sequences=True,input_shape=(X_BUMI_7_train.shape[1], 1)))\n",
        "model_BUMI_7.add(Dropout(0.2))\n",
        "model_BUMI_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_7.add(Dropout(0.2))\n",
        "model_BUMI_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_7.add(Dropout(0.2))\n",
        "model_BUMI_7.add(LSTM(units=50))\n",
        "model_BUMI_7.add(Dropout(0.2))\n",
        "model_BUMI_7.add(Dense(units=1))\n",
        "model_BUMI_7.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BUMI_7.fit(X_BUMI_7_train,y_BUMI_7_train,epochs=10,batch_size=16)\n",
        "\n",
        "# MFIN\n",
        "MFIN_7 = yf.download(\"MFIN.JK\", start=\"2022-06-10\", end=\"2022-12-10\")\n",
        "MFIN_7.insert(4,\"Return\", MFIN_7['Close'].pct_change())\n",
        "MFIN_7 = MFIN_7.dropna()\n",
        "MFIN_7_test = yf.download(\"MFIN.JK\", start=\"2022-12-09\", end=\"2023-01-10\")\n",
        "MFIN_7_test.insert(4,\"Return\", MFIN_7_test['Close'].pct_change())\n",
        "MFIN_7_test = MFIN_7_test.dropna()\n",
        "training_MFIN_7 = MFIN_7.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_MFIN_7_scaled = sc.fit_transform(training_MFIN_7)\n",
        "X_MFIN_7_train = []\n",
        "y_MFIN_7_train = []\n",
        "for i in range(days_period, len(MFIN_7)-1):\n",
        "    X_MFIN_7_train.append(training_MFIN_7_scaled[i-days_period:i, 0])\n",
        "    y_MFIN_7_train.append(training_MFIN_7_scaled[i, 0])\n",
        "X_MFIN_7_train, y_MFIN_7_train = np.array(X_MFIN_7_train), np.array(y_MFIN_7_train)\n",
        "X_MFIN_7_train = np.reshape(X_MFIN_7_train, (X_MFIN_7_train.shape[0], X_MFIN_7_train.shape[1], 1))\n",
        "model_MFIN_7 = Sequential()\n",
        "model_MFIN_7.add(LSTM(units=50,return_sequences=True,input_shape=(X_MFIN_7_train.shape[1], 1)))\n",
        "model_MFIN_7.add(Dropout(0.2))\n",
        "model_MFIN_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_7.add(Dropout(0.2))\n",
        "model_MFIN_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_7.add(Dropout(0.2))\n",
        "model_MFIN_7.add(LSTM(units=50))\n",
        "model_MFIN_7.add(Dropout(0.2))\n",
        "model_MFIN_7.add(Dense(units=1))\n",
        "model_MFIN_7.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_MFIN_7.fit(X_MFIN_7_train,y_MFIN_7_train,epochs=10,batch_size=16)\n",
        "\n",
        "# EXCL\n",
        "EXCL_7 = yf.download(\"EXCL.JK\", start=\"2022-06-10\", end=\"2022-12-10\")\n",
        "EXCL_7.insert(4,\"Return\", EXCL_7['Close'].pct_change())\n",
        "EXCL_7 = EXCL_7.dropna()\n",
        "EXCL_7_test = yf.download(\"EXCL.JK\", start=\"2022-12-09\", end=\"2023-01-10\")\n",
        "EXCL_7_test.insert(4,\"Return\", EXCL_7_test['Close'].pct_change())\n",
        "EXCL_7_test = EXCL_7_test.dropna()\n",
        "training_EXCL_7 = EXCL_7.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_EXCL_7_scaled = sc.fit_transform(training_EXCL_7)\n",
        "X_EXCL_7_train = []\n",
        "y_EXCL_7_train = []\n",
        "for i in range(days_period, len(EXCL_7)-1):\n",
        "    X_EXCL_7_train.append(training_EXCL_7_scaled[i-days_period:i, 0])\n",
        "    y_EXCL_7_train.append(training_EXCL_7_scaled[i, 0])\n",
        "X_EXCL_7_train, y_EXCL_7_train = np.array(X_EXCL_7_train), np.array(y_EXCL_7_train)\n",
        "X_EXCL_7_train = np.reshape(X_EXCL_7_train, (X_EXCL_7_train.shape[0], X_EXCL_7_train.shape[1], 1))\n",
        "model_EXCL_7 = Sequential()\n",
        "model_EXCL_7.add(LSTM(units=50,return_sequences=True,input_shape=(X_EXCL_7_train.shape[1], 1)))\n",
        "model_EXCL_7.add(Dropout(0.2))\n",
        "model_EXCL_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_7.add(Dropout(0.2))\n",
        "model_EXCL_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_7.add(Dropout(0.2))\n",
        "model_EXCL_7.add(LSTM(units=50))\n",
        "model_EXCL_7.add(Dropout(0.2))\n",
        "model_EXCL_7.add(Dense(units=1))\n",
        "model_EXCL_7.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_EXCL_7.fit(X_EXCL_7_train,y_EXCL_7_train,epochs=10,batch_size=16)\n",
        "\n",
        "# PGAS\n",
        "PGAS_7 = yf.download(\"PGAS.JK\", start=\"2022-06-10\", end=\"2022-12-10\")\n",
        "PGAS_7.insert(4,\"Return\", PGAS_7['Close'].pct_change())\n",
        "PGAS_7 = PGAS_7.dropna()\n",
        "PGAS_7_test = yf.download(\"PGAS.JK\", start=\"2022-12-09\", end=\"2023-01-10\")\n",
        "PGAS_7_test.insert(4,\"Return\", PGAS_7_test['Close'].pct_change())\n",
        "PGAS_7_test = PGAS_7_test.dropna()\n",
        "training_PGAS_7 = PGAS_7.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_PGAS_7_scaled = sc.fit_transform(training_PGAS_7)\n",
        "X_PGAS_7_train = []\n",
        "y_PGAS_7_train = []\n",
        "for i in range(days_period, len(PGAS_7)-1):\n",
        "    X_PGAS_7_train.append(training_PGAS_7_scaled[i-days_period:i, 0])\n",
        "    y_PGAS_7_train.append(training_PGAS_7_scaled[i, 0])\n",
        "X_PGAS_7_train, y_PGAS_7_train = np.array(X_PGAS_7_train), np.array(y_PGAS_7_train)\n",
        "X_PGAS_7_train = np.reshape(X_PGAS_7_train, (X_PGAS_7_train.shape[0], X_PGAS_7_train.shape[1], 1))\n",
        "model_PGAS_7 = Sequential()\n",
        "model_PGAS_7.add(LSTM(units=50,return_sequences=True,input_shape=(X_PGAS_7_train.shape[1], 1)))\n",
        "model_PGAS_7.add(Dropout(0.2))\n",
        "model_PGAS_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_7.add(Dropout(0.2))\n",
        "model_PGAS_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_7.add(Dropout(0.2))\n",
        "model_PGAS_7.add(LSTM(units=50))\n",
        "model_PGAS_7.add(Dropout(0.2))\n",
        "model_PGAS_7.add(Dense(units=1))\n",
        "model_PGAS_7.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_PGAS_7.fit(X_PGAS_7_train,y_PGAS_7_train,epochs=10,batch_size=16)\n",
        "\n",
        "# TLKM\n",
        "TLKM_7 = yf.download(\"TLKM.JK\", start=\"2022-06-10\", end=\"2022-12-10\")\n",
        "TLKM_7.insert(4,\"Return\", TLKM_7['Close'].pct_change())\n",
        "TLKM_7 = TLKM_7.dropna()\n",
        "TLKM_7_test = yf.download(\"TLKM.JK\", start=\"2022-12-09\", end=\"2023-01-10\")\n",
        "TLKM_7_test.insert(4,\"Return\", TLKM_7_test['Close'].pct_change())\n",
        "TLKM_7_test = TLKM_7_test.dropna()\n",
        "training_TLKM_7 = TLKM_7.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_TLKM_7_scaled = sc.fit_transform(training_TLKM_7)\n",
        "X_TLKM_7_train = []\n",
        "y_TLKM_7_train = []\n",
        "for i in range(days_period, len(TLKM_7)-1):\n",
        "    X_TLKM_7_train.append(training_TLKM_7_scaled[i-days_period:i, 0])\n",
        "    y_TLKM_7_train.append(training_TLKM_7_scaled[i, 0])\n",
        "X_TLKM_7_train, y_TLKM_7_train = np.array(X_TLKM_7_train), np.array(y_TLKM_7_train)\n",
        "X_TLKM_7_train = np.reshape(X_TLKM_7_train, (X_TLKM_7_train.shape[0], X_TLKM_7_train.shape[1], 1))\n",
        "model_TLKM_7 = Sequential()\n",
        "model_TLKM_7.add(LSTM(units=50,return_sequences=True,input_shape=(X_TLKM_7_train.shape[1], 1)))\n",
        "model_TLKM_7.add(Dropout(0.2))\n",
        "model_TLKM_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_7.add(Dropout(0.2))\n",
        "model_TLKM_7.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_7.add(Dropout(0.2))\n",
        "model_TLKM_7.add(LSTM(units=50))\n",
        "model_TLKM_7.add(Dropout(0.2))\n",
        "model_TLKM_7.add(Dense(units=1))\n",
        "model_TLKM_7.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_TLKM_7.fit(X_TLKM_7_train,y_TLKM_7_train,epochs=10,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWeb-dCUfPZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37b524cf-8408-4d96-edf8-0bb28dcfb556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ],
      "source": [
        "# ADRO\n",
        "real_ADRO_7_return = ADRO_7_test.iloc[:, 4:5].values\n",
        "real_ADRO_7_return = real_ADRO_7_return[:days_predict]\n",
        "ADRO_7_total = ADRO_7['Close'].copy(deep=True)\n",
        "inputs_ADRO_7 = ADRO_7_total[len(ADRO_7) - days_period: len(ADRO_7)].values\n",
        "inputs_ADRO_7 = inputs_ADRO_7.reshape(-1,1)\n",
        "inputs_ADRO_7 = sc.transform(inputs_ADRO_7)\n",
        "predicted_ADRO_7_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ADRO_7_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ADRO_7_test.append(inputs_ADRO_7[i:i+days_period, 0])\n",
        "  X_ADRO_7_test = np.array(X_ADRO_7_test)\n",
        "  X_ADRO_7_test = np.reshape(X_ADRO_7_test, (X_ADRO_7_test.shape[0], X_ADRO_7_test.shape[1], 1))\n",
        "  predicted_ADRO_7_return[j] = model_ADRO_7.predict(X_ADRO_7_test)\n",
        "  inputs_ADRO_7 += (predicted_ADRO_7_return[j])\n",
        "  inputs_ADRO_7 = inputs_ADRO_7.reshape(-1,1)\n",
        "\n",
        "# ASII\n",
        "real_ASII_7_return = ASII_7_test.iloc[:, 4:5].values\n",
        "real_ASII_7_return = real_ASII_7_return[:days_predict]\n",
        "ASII_7_total = ASII_7['Close'].copy(deep=True)\n",
        "inputs_ASII_7 = ASII_7_total[len(ASII_7) - days_period: len(ASII_7)].values\n",
        "inputs_ASII_7 = inputs_ASII_7.reshape(-1,1)\n",
        "inputs_ASII_7 = sc.transform(inputs_ASII_7)\n",
        "predicted_ASII_7_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ASII_7_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ASII_7_test.append(inputs_ASII_7[i:i+days_period, 0])\n",
        "  X_ASII_7_test = np.array(X_ASII_7_test)\n",
        "  X_ASII_7_test = np.reshape(X_ASII_7_test, (X_ASII_7_test.shape[0], X_ASII_7_test.shape[1], 1))\n",
        "  predicted_ASII_7_return[j] = model_ASII_7.predict(X_ASII_7_test)\n",
        "  inputs_ASII_7 += (predicted_ASII_7_return[j])\n",
        "  inputs_ASII_7 = inputs_ASII_7.reshape(-1,1)\n",
        "\n",
        "# BMRI\n",
        "real_BMRI_7_return = BMRI_7_test.iloc[:, 4:5].values\n",
        "real_BMRI_7_return = real_BMRI_7_return[:days_predict]\n",
        "BMRI_7_total = BMRI_7['Close'].copy(deep=True)\n",
        "inputs_BMRI_7 = BMRI_7_total[len(BMRI_7) - days_period: len(BMRI_7)].values\n",
        "inputs_BMRI_7 = inputs_BMRI_7.reshape(-1,1)\n",
        "inputs_BMRI_7 = sc.transform(inputs_BMRI_7)\n",
        "predicted_BMRI_7_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BMRI_7_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BMRI_7_test.append(inputs_BMRI_7[i:i+days_period, 0])\n",
        "  X_BMRI_7_test = np.array(X_BMRI_7_test)\n",
        "  X_BMRI_7_test = np.reshape(X_BMRI_7_test, (X_BMRI_7_test.shape[0], X_BMRI_7_test.shape[1], 1))\n",
        "  predicted_BMRI_7_return[j] = model_BMRI_7.predict(X_BMRI_7_test)\n",
        "  inputs_BMRI_7 += (predicted_BMRI_7_return[j])\n",
        "  inputs_BMRI_7 = inputs_BMRI_7.reshape(-1,1)\n",
        "\n",
        "# BBRI\n",
        "real_BBRI_7_return = BBRI_7_test.iloc[:, 4:5].values\n",
        "real_BBRI_7_return = real_BBRI_7_return[:days_predict]\n",
        "BBRI_7_total = BBRI_7['Close'].copy(deep=True)\n",
        "inputs_BBRI_7 = BBRI_7_total[len(BBRI_7) - days_period: len(BBRI_7)].values\n",
        "inputs_BBRI_7 = inputs_BBRI_7.reshape(-1,1)\n",
        "inputs_BBRI_7 = sc.transform(inputs_BBRI_7)\n",
        "predicted_BBRI_7_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBRI_7_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBRI_7_test.append(inputs_BBRI_7[i:i+days_period, 0])\n",
        "  X_BBRI_7_test = np.array(X_BBRI_7_test)\n",
        "  X_BBRI_7_test = np.reshape(X_BBRI_7_test, (X_BBRI_7_test.shape[0], X_BBRI_7_test.shape[1], 1))\n",
        "  predicted_BBRI_7_return[j] = model_BBRI_7.predict(X_BBRI_7_test)\n",
        "  inputs_BBRI_7 += (predicted_BBRI_7_return[j])\n",
        "  inputs_BBRI_7 = inputs_BBRI_7.reshape(-1,1)\n",
        "\n",
        "# BBTN\n",
        "real_BBTN_7_return = BBTN_7_test.iloc[:, 4:5].values\n",
        "real_BBTN_7_return = real_BBTN_7_return[:days_predict]\n",
        "BBTN_7_total = BBTN_7['Close'].copy(deep=True)\n",
        "inputs_BBTN_7 = BBTN_7_total[len(BBTN_7) - days_period: len(BBTN_7)].values\n",
        "inputs_BBTN_7 = inputs_BBTN_7.reshape(-1,1)\n",
        "inputs_BBTN_7 = sc.transform(inputs_BBTN_7)\n",
        "predicted_BBTN_7_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBTN_7_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBTN_7_test.append(inputs_BBTN_7[i:i+days_period, 0])\n",
        "  X_BBTN_7_test = np.array(X_BBTN_7_test)\n",
        "  X_BBTN_7_test = np.reshape(X_BBTN_7_test, (X_BBTN_7_test.shape[0], X_BBTN_7_test.shape[1], 1))\n",
        "  predicted_BBTN_7_return[j] = model_BBTN_7.predict(X_BBTN_7_test)\n",
        "  inputs_BBTN_7 += (predicted_BBTN_7_return[j])\n",
        "  inputs_BBTN_7 = inputs_BBTN_7.reshape(-1,1)\n",
        "\n",
        "# BUMI\n",
        "real_BUMI_7_return = BUMI_7_test.iloc[:, 4:5].values\n",
        "real_BUMI_7_return = real_BUMI_7_return[:days_predict]\n",
        "BUMI_7_total = BUMI_7['Close'].copy(deep=True)\n",
        "inputs_BUMI_7 = BUMI_7_total[len(BUMI_7) - days_period: len(BUMI_7)].values\n",
        "inputs_BUMI_7 = inputs_BUMI_7.reshape(-1,1)\n",
        "inputs_BUMI_7 = sc.transform(inputs_BUMI_7)\n",
        "predicted_BUMI_7_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BUMI_7_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BUMI_7_test.append(inputs_BUMI_7[i:i+days_period, 0])\n",
        "  X_BUMI_7_test = np.array(X_BUMI_7_test)\n",
        "  X_BUMI_7_test = np.reshape(X_BUMI_7_test, (X_BUMI_7_test.shape[0], X_BUMI_7_test.shape[1], 1))\n",
        "  predicted_BUMI_7_return[j] = model_BUMI_7.predict(X_BUMI_7_test)\n",
        "  inputs_BUMI_7 += (predicted_BUMI_7_return[j])\n",
        "  inputs_BUMI_7 = inputs_BUMI_7.reshape(-1,1)\n",
        "\n",
        "# MFIN\n",
        "real_MFIN_7_return = MFIN_7_test.iloc[:, 4:5].values\n",
        "real_MFIN_7_return = real_MFIN_7_return[:days_predict]\n",
        "MFIN_7_total = MFIN_7['Close'].copy(deep=True)\n",
        "inputs_MFIN_7 = MFIN_7_total[len(MFIN_7) - days_period: len(MFIN_7)].values\n",
        "inputs_MFIN_7 = inputs_MFIN_7.reshape(-1,1)\n",
        "inputs_MFIN_7 = sc.transform(inputs_MFIN_7)\n",
        "predicted_MFIN_7_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_MFIN_7_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_MFIN_7_test.append(inputs_MFIN_7[i:i+days_period, 0])\n",
        "  X_MFIN_7_test = np.array(X_MFIN_7_test)\n",
        "  X_MFIN_7_test = np.reshape(X_MFIN_7_test, (X_MFIN_7_test.shape[0], X_MFIN_7_test.shape[1], 1))\n",
        "  predicted_MFIN_7_return[j] = model_MFIN_7.predict(X_MFIN_7_test)\n",
        "  inputs_MFIN_7 += (predicted_MFIN_7_return[j])\n",
        "  inputs_MFIN_7 = inputs_MFIN_7.reshape(-1,1)\n",
        "\n",
        "# EXCL\n",
        "real_EXCL_7_return = EXCL_7_test.iloc[:, 4:5].values\n",
        "real_EXCL_7_return = real_EXCL_7_return[:days_predict]\n",
        "EXCL_7_total = EXCL_7['Close'].copy(deep=True)\n",
        "inputs_EXCL_7 = EXCL_7_total[len(EXCL_7) - days_period: len(EXCL_7)].values\n",
        "inputs_EXCL_7 = inputs_EXCL_7.reshape(-1,1)\n",
        "inputs_EXCL_7 = sc.transform(inputs_EXCL_7)\n",
        "predicted_EXCL_7_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_EXCL_7_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_EXCL_7_test.append(inputs_EXCL_7[i:i+days_period, 0])\n",
        "  X_EXCL_7_test = np.array(X_EXCL_7_test)\n",
        "  X_EXCL_7_test = np.reshape(X_EXCL_7_test, (X_EXCL_7_test.shape[0], X_EXCL_7_test.shape[1], 1))\n",
        "  predicted_EXCL_7_return[j] = model_EXCL_7.predict(X_EXCL_7_test)\n",
        "  inputs_EXCL_7 += (predicted_EXCL_7_return[j])\n",
        "  inputs_EXCL_7 = inputs_EXCL_7.reshape(-1,1)\n",
        "\n",
        "# PGAS\n",
        "real_PGAS_7_return = PGAS_7_test.iloc[:, 4:5].values\n",
        "real_PGAS_7_return = real_PGAS_7_return[:days_predict]\n",
        "PGAS_7_total = PGAS_7['Close'].copy(deep=True)\n",
        "inputs_PGAS_7 = PGAS_7_total[len(PGAS_7) - days_period: len(PGAS_7)].values\n",
        "inputs_PGAS_7 = inputs_PGAS_7.reshape(-1,1)\n",
        "inputs_PGAS_7 = sc.transform(inputs_PGAS_7)\n",
        "predicted_PGAS_7_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_PGAS_7_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_PGAS_7_test.append(inputs_PGAS_7[i:i+days_period, 0])\n",
        "  X_PGAS_7_test = np.array(X_PGAS_7_test)\n",
        "  X_PGAS_7_test = np.reshape(X_PGAS_7_test, (X_PGAS_7_test.shape[0], X_PGAS_7_test.shape[1], 1))\n",
        "  predicted_PGAS_7_return[j] = model_PGAS_7.predict(X_PGAS_7_test)\n",
        "  inputs_PGAS_7 += (predicted_PGAS_7_return[j])\n",
        "  inputs_PGAS_7 = inputs_PGAS_7.reshape(-1,1)\n",
        "\n",
        "# TLKM\n",
        "real_TLKM_7_return = TLKM_7_test.iloc[:, 4:5].values\n",
        "real_TLKM_7_return = real_TLKM_7_return[:days_predict]\n",
        "TLKM_7_total = TLKM_7['Close'].copy(deep=True)\n",
        "inputs_TLKM_7 = TLKM_7_total[len(TLKM_7) - days_period: len(TLKM_7)].values\n",
        "inputs_TLKM_7 = inputs_TLKM_7.reshape(-1,1)\n",
        "inputs_TLKM_7 = sc.transform(inputs_TLKM_7)\n",
        "predicted_TLKM_7_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_TLKM_7_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_TLKM_7_test.append(inputs_TLKM_7[i:i+days_period, 0])\n",
        "  X_TLKM_7_test = np.array(X_TLKM_7_test)\n",
        "  X_TLKM_7_test = np.reshape(X_TLKM_7_test, (X_TLKM_7_test.shape[0], X_TLKM_7_test.shape[1], 1))\n",
        "  predicted_TLKM_7_return[j] = model_TLKM_7.predict(X_TLKM_7_test)\n",
        "  inputs_TLKM_7 += (predicted_TLKM_7_return[j])\n",
        "  inputs_TLKM_7 = inputs_TLKM_7.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01LRx9phfPZI"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "predicted_ADRO_7_return = np.squeeze(np.asarray(predicted_ADRO_7_return))\n",
        "predicted_ADRO_7_return = predicted_ADRO_7_return.reshape(-1,1)\n",
        "predicted_ADRO_7_return = sc.inverse_transform(predicted_ADRO_7_return)\n",
        "# ASII\n",
        "predicted_ASII_7_return = np.squeeze(np.asarray(predicted_ASII_7_return))\n",
        "predicted_ASII_7_return = predicted_ASII_7_return.reshape(-1,1)\n",
        "predicted_ASII_7_return = sc.inverse_transform(predicted_ASII_7_return)\n",
        "# BMRI\n",
        "predicted_BMRI_7_return = np.squeeze(np.asarray(predicted_BMRI_7_return))\n",
        "predicted_BMRI_7_return = predicted_BMRI_7_return.reshape(-1,1)\n",
        "predicted_BMRI_7_return = sc.inverse_transform(predicted_BMRI_7_return)\n",
        "# BBRI\n",
        "predicted_BBRI_7_return = np.squeeze(np.asarray(predicted_BBRI_7_return))\n",
        "predicted_BBRI_7_return = predicted_BBRI_7_return.reshape(-1,1)\n",
        "predicted_BBRI_7_return = sc.inverse_transform(predicted_BBRI_7_return)\n",
        "# BBTN\n",
        "predicted_BBTN_7_return = np.squeeze(np.asarray(predicted_BBTN_7_return))\n",
        "predicted_BBTN_7_return = predicted_BBTN_7_return.reshape(-1,1)\n",
        "predicted_BBTN_7_return = sc.inverse_transform(predicted_BBTN_7_return)\n",
        "# BUMI\n",
        "predicted_BUMI_7_return = np.squeeze(np.asarray(predicted_BUMI_7_return))\n",
        "predicted_BUMI_7_return = predicted_BUMI_7_return.reshape(-1,1)\n",
        "predicted_BUMI_7_return = sc.inverse_transform(predicted_BUMI_7_return)\n",
        "# MFIN\n",
        "predicted_MFIN_7_return = np.squeeze(np.asarray(predicted_MFIN_7_return))\n",
        "predicted_MFIN_7_return = predicted_MFIN_7_return.reshape(-1,1)\n",
        "predicted_MFIN_7_return = sc.inverse_transform(predicted_MFIN_7_return)\n",
        "# EXCL\n",
        "predicted_EXCL_7_return = np.squeeze(np.asarray(predicted_EXCL_7_return))\n",
        "predicted_EXCL_7_return = predicted_EXCL_7_return.reshape(-1,1)\n",
        "predicted_EXCL_7_return = sc.inverse_transform(predicted_EXCL_7_return)\n",
        "# PGAS\n",
        "predicted_PGAS_7_return = np.squeeze(np.asarray(predicted_PGAS_7_return))\n",
        "predicted_PGAS_7_return = predicted_PGAS_7_return.reshape(-1,1)\n",
        "predicted_PGAS_7_return = sc.inverse_transform(predicted_PGAS_7_return)\n",
        "# TLKM\n",
        "predicted_TLKM_7_return = np.squeeze(np.asarray(predicted_TLKM_7_return))\n",
        "predicted_TLKM_7_return = predicted_TLKM_7_return.reshape(-1,1)\n",
        "predicted_TLKM_7_return = sc.inverse_transform(predicted_TLKM_7_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0DneMRMfPZJ"
      },
      "outputs": [],
      "source": [
        "predicted7 = pd.DataFrame(predicted_ADRO_7_return)\n",
        "predicted7.rename(columns={0:'ADRO'}, inplace=True)\n",
        "predicted7.insert(1,\"ASII\", predicted_ASII_7_return)\n",
        "predicted7.insert(2,\"BBRI\", predicted_BBRI_7_return)\n",
        "predicted7.insert(3,\"BBTN\", predicted_BBTN_7_return)\n",
        "predicted7.insert(4,\"BMRI\", predicted_BMRI_7_return)\n",
        "predicted7.insert(5,\"BUMI\", predicted_BUMI_7_return)\n",
        "predicted7.insert(6,\"EXCL\", predicted_EXCL_7_return)\n",
        "predicted7.insert(7,\"MFIN\", predicted_MFIN_7_return)\n",
        "predicted7.insert(8,\"PGAS\", predicted_PGAS_7_return)\n",
        "predicted7.insert(9,\"TLKM\", predicted_TLKM_7_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjfgg-FJQ-eH",
        "outputId": "7e4a7245-bc58-4f22-d9df-a208bdf1eb35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADRO      ASII      BBRI      BBTN      BMRI      BUMI      EXCL  \\\n",
              "0  0.026190  0.019829  0.003208  0.016620  0.024427 -0.009756 -0.045117   \n",
              "1  0.025379  0.019062  0.002386  0.015665  0.023522 -0.010400 -0.045129   \n",
              "2  0.024368  0.018103  0.001419  0.014503  0.022416 -0.011172 -0.045161   \n",
              "3  0.023112  0.016913  0.000281  0.013096  0.021072 -0.012094 -0.045219   \n",
              "4  0.021561  0.015445 -0.001057  0.011403  0.019444 -0.013191 -0.045313   \n",
              "5  0.019653  0.013646 -0.002628  0.009383  0.017484 -0.014490 -0.045456   \n",
              "6  0.017323  0.011461 -0.004468  0.006988  0.015137 -0.016019 -0.045663   \n",
              "7  0.014497  0.008826 -0.006618  0.004174  0.012345 -0.017806 -0.045949   \n",
              "8  0.011100  0.005682 -0.009119  0.000897  0.009048 -0.019881 -0.046335   \n",
              "9  0.007061  0.001969 -0.012011 -0.002880  0.005189 -0.022265 -0.046840   \n",
              "\n",
              "       MFIN      PGAS      TLKM  \n",
              "0  0.015547  0.037161 -0.001416  \n",
              "1  0.014670  0.036261 -0.002734  \n",
              "2  0.013601  0.035162 -0.004229  \n",
              "3  0.012302  0.033822 -0.005920  \n",
              "4  0.010734  0.032189 -0.007827  \n",
              "5  0.008848  0.030204 -0.009970  \n",
              "6  0.006596  0.027798 -0.012364  \n",
              "7  0.003922  0.024893 -0.015025  \n",
              "8  0.000774  0.021403 -0.017960  \n",
              "9 -0.002899  0.017240 -0.021169  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91ab8cee-9c93-4d9c-b570-df3dd6316d9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADRO</th>\n",
              "      <th>ASII</th>\n",
              "      <th>BBRI</th>\n",
              "      <th>BBTN</th>\n",
              "      <th>BMRI</th>\n",
              "      <th>BUMI</th>\n",
              "      <th>EXCL</th>\n",
              "      <th>MFIN</th>\n",
              "      <th>PGAS</th>\n",
              "      <th>TLKM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.026190</td>\n",
              "      <td>0.019829</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>0.016620</td>\n",
              "      <td>0.024427</td>\n",
              "      <td>-0.009756</td>\n",
              "      <td>-0.045117</td>\n",
              "      <td>0.015547</td>\n",
              "      <td>0.037161</td>\n",
              "      <td>-0.001416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.025379</td>\n",
              "      <td>0.019062</td>\n",
              "      <td>0.002386</td>\n",
              "      <td>0.015665</td>\n",
              "      <td>0.023522</td>\n",
              "      <td>-0.010400</td>\n",
              "      <td>-0.045129</td>\n",
              "      <td>0.014670</td>\n",
              "      <td>0.036261</td>\n",
              "      <td>-0.002734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.024368</td>\n",
              "      <td>0.018103</td>\n",
              "      <td>0.001419</td>\n",
              "      <td>0.014503</td>\n",
              "      <td>0.022416</td>\n",
              "      <td>-0.011172</td>\n",
              "      <td>-0.045161</td>\n",
              "      <td>0.013601</td>\n",
              "      <td>0.035162</td>\n",
              "      <td>-0.004229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.023112</td>\n",
              "      <td>0.016913</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>0.013096</td>\n",
              "      <td>0.021072</td>\n",
              "      <td>-0.012094</td>\n",
              "      <td>-0.045219</td>\n",
              "      <td>0.012302</td>\n",
              "      <td>0.033822</td>\n",
              "      <td>-0.005920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.021561</td>\n",
              "      <td>0.015445</td>\n",
              "      <td>-0.001057</td>\n",
              "      <td>0.011403</td>\n",
              "      <td>0.019444</td>\n",
              "      <td>-0.013191</td>\n",
              "      <td>-0.045313</td>\n",
              "      <td>0.010734</td>\n",
              "      <td>0.032189</td>\n",
              "      <td>-0.007827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.019653</td>\n",
              "      <td>0.013646</td>\n",
              "      <td>-0.002628</td>\n",
              "      <td>0.009383</td>\n",
              "      <td>0.017484</td>\n",
              "      <td>-0.014490</td>\n",
              "      <td>-0.045456</td>\n",
              "      <td>0.008848</td>\n",
              "      <td>0.030204</td>\n",
              "      <td>-0.009970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.017323</td>\n",
              "      <td>0.011461</td>\n",
              "      <td>-0.004468</td>\n",
              "      <td>0.006988</td>\n",
              "      <td>0.015137</td>\n",
              "      <td>-0.016019</td>\n",
              "      <td>-0.045663</td>\n",
              "      <td>0.006596</td>\n",
              "      <td>0.027798</td>\n",
              "      <td>-0.012364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.014497</td>\n",
              "      <td>0.008826</td>\n",
              "      <td>-0.006618</td>\n",
              "      <td>0.004174</td>\n",
              "      <td>0.012345</td>\n",
              "      <td>-0.017806</td>\n",
              "      <td>-0.045949</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.024893</td>\n",
              "      <td>-0.015025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.011100</td>\n",
              "      <td>0.005682</td>\n",
              "      <td>-0.009119</td>\n",
              "      <td>0.000897</td>\n",
              "      <td>0.009048</td>\n",
              "      <td>-0.019881</td>\n",
              "      <td>-0.046335</td>\n",
              "      <td>0.000774</td>\n",
              "      <td>0.021403</td>\n",
              "      <td>-0.017960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.007061</td>\n",
              "      <td>0.001969</td>\n",
              "      <td>-0.012011</td>\n",
              "      <td>-0.002880</td>\n",
              "      <td>0.005189</td>\n",
              "      <td>-0.022265</td>\n",
              "      <td>-0.046840</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>0.017240</td>\n",
              "      <td>-0.021169</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91ab8cee-9c93-4d9c-b570-df3dd6316d9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91ab8cee-9c93-4d9c-b570-df3dd6316d9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91ab8cee-9c93-4d9c-b570-df3dd6316d9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfmgwSaychfd"
      },
      "source": [
        "## Data Preparation 8\n",
        "1st of January 2018 - 9th of January 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-IEKYmLfVn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04431ba1-8ce6-4eb1-8aec-78ffee6c9f10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 46ms/step - loss: 0.1910\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0547\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0423\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0386\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0395\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0403\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0403\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0376\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0344\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0370\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 42ms/step - loss: 0.1596\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0394\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0322\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0246\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0256\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0283\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0221\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0264\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0236\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0257\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 12s 43ms/step - loss: 0.0908\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0304\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 0.0259\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0227\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 0.0216\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0193\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0182\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0192\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0169\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0195\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 10s 42ms/step - loss: 0.1099\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0483\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 55ms/step - loss: 0.0447\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0345\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0431\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.0389\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.0403\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 0.0379\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 0.0398\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0380\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 11s 44ms/step - loss: 0.1687\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0475\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0431\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.0200\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0168\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0203\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0153\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0138\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0189\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0142\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 10s 42ms/step - loss: 0.0473\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0284\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0276\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0251\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0277\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0281\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0259\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0288\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0269\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0269\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 10s 49ms/step - loss: 0.0826\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0445\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0327\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0305\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0306\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0280\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0285\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0313\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0308\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.0290\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 8s 45ms/step - loss: 0.0118\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0078\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0081\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.0082\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0080\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0079\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 0.0079\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 0.0081\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 71ms/step - loss: 0.0079\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 0.0078\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 44ms/step - loss: 0.1163\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0383\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0401\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 0.0286\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 71ms/step - loss: 0.0266\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 71ms/step - loss: 0.0239\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0261\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 0.0254\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0263\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0243\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 41ms/step - loss: 0.2317\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0637\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0516\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0338\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0362\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0354\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0318\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0357\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0352\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efb52e7ce80>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Period parameters\n",
        "days_period = 20\n",
        "days_predict = 10\n",
        "\n",
        "# ADRO\n",
        "ADRO_8 = yf.download(\"ADRO.JK\", start=\"2022-07-10\", end=\"2023-01-10\")\n",
        "ADRO_8.insert(4,\"Return\", ADRO_8['Close'].pct_change())\n",
        "ADRO_8 = ADRO_8.dropna()\n",
        "ADRO_8_test = yf.download(\"ADRO.JK\", start=\"2023-01-09\", end=\"2023-02-10\")\n",
        "ADRO_8_test.insert(4,\"Return\", ADRO_8_test['Close'].pct_change())\n",
        "ADRO_8_test = ADRO_8_test.dropna()\n",
        "training_ADRO_8 = ADRO_8.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ADRO_8_scaled = sc.fit_transform(training_ADRO_8)\n",
        "X_ADRO_8_train = []\n",
        "y_ADRO_8_train = []\n",
        "for i in range(days_period, len(ADRO_8)-1):\n",
        "    X_ADRO_8_train.append(training_ADRO_8_scaled[i-days_period:i, 0])\n",
        "    y_ADRO_8_train.append(training_ADRO_8_scaled[i, 0])\n",
        "X_ADRO_8_train, y_ADRO_8_train = np.array(X_ADRO_8_train), np.array(y_ADRO_8_train)\n",
        "X_ADRO_8_train = np.reshape(X_ADRO_8_train, (X_ADRO_8_train.shape[0], X_ADRO_8_train.shape[1], 1))\n",
        "model_ADRO_8 = Sequential()\n",
        "model_ADRO_8.add(LSTM(units=50,return_sequences=True,input_shape=(X_ADRO_8_train.shape[1], 1)))\n",
        "model_ADRO_8.add(Dropout(0.2))\n",
        "model_ADRO_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_8.add(Dropout(0.2))\n",
        "model_ADRO_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_8.add(Dropout(0.2))\n",
        "model_ADRO_8.add(LSTM(units=50))\n",
        "model_ADRO_8.add(Dropout(0.2))\n",
        "model_ADRO_8.add(Dense(units=1))\n",
        "model_ADRO_8.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ADRO_8.fit(X_ADRO_8_train,y_ADRO_8_train,epochs=10,batch_size=16)\n",
        "\n",
        "# ASII\n",
        "ASII_8 = yf.download(\"ASII.JK\", start=\"2022-07-10\", end=\"2023-01-10\")\n",
        "ASII_8.insert(4,\"Return\", ASII_8['Close'].pct_change())\n",
        "ASII_8 = ASII_8.dropna()\n",
        "ASII_8_test = yf.download(\"ASII.JK\", start=\"2023-01-09\", end=\"2023-02-10\")\n",
        "ASII_8_test.insert(4,\"Return\", ASII_8_test['Close'].pct_change())\n",
        "ASII_8_test = ASII_8_test.dropna()\n",
        "training_ASII_8 = ASII_8.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ASII_8_scaled = sc.fit_transform(training_ASII_8)\n",
        "X_ASII_8_train = []\n",
        "y_ASII_8_train = []\n",
        "for i in range(days_period, len(ASII_8)-1):\n",
        "    X_ASII_8_train.append(training_ASII_8_scaled[i-days_period:i, 0])\n",
        "    y_ASII_8_train.append(training_ASII_8_scaled[i, 0])\n",
        "X_ASII_8_train, y_ASII_8_train = np.array(X_ASII_8_train), np.array(y_ASII_8_train)\n",
        "X_ASII_8_train = np.reshape(X_ASII_8_train, (X_ASII_8_train.shape[0], X_ASII_8_train.shape[1], 1))\n",
        "model_ASII_8 = Sequential()\n",
        "model_ASII_8.add(LSTM(units=50,return_sequences=True,input_shape=(X_ASII_8_train.shape[1], 1)))\n",
        "model_ASII_8.add(Dropout(0.2))\n",
        "model_ASII_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_8.add(Dropout(0.2))\n",
        "model_ASII_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_8.add(Dropout(0.2))\n",
        "model_ASII_8.add(LSTM(units=50))\n",
        "model_ASII_8.add(Dropout(0.2))\n",
        "model_ASII_8.add(Dense(units=1))\n",
        "model_ASII_8.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ASII_8.fit(X_ASII_8_train,y_ASII_8_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BMRI\n",
        "BMRI_8 = yf.download(\"BMRI.JK\", start=\"2022-07-10\", end=\"2023-01-10\")\n",
        "BMRI_8.insert(4,\"Return\", BMRI_8['Close'].pct_change())\n",
        "BMRI_8 = BMRI_8.dropna()\n",
        "BMRI_8_test = yf.download(\"BMRI.JK\", start=\"2023-01-09\", end=\"2023-02-10\")\n",
        "BMRI_8_test.insert(4,\"Return\", BMRI_8_test['Close'].pct_change())\n",
        "BMRI_8_test = BMRI_8_test.dropna()\n",
        "training_BMRI_8 = BMRI_8.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BMRI_8_scaled = sc.fit_transform(training_BMRI_8)\n",
        "X_BMRI_8_train = []\n",
        "y_BMRI_8_train = []\n",
        "for i in range(days_period, len(BMRI_8)-1):\n",
        "    X_BMRI_8_train.append(training_BMRI_8_scaled[i-days_period:i, 0])\n",
        "    y_BMRI_8_train.append(training_BMRI_8_scaled[i, 0])\n",
        "X_BMRI_8_train, y_BMRI_8_train = np.array(X_BMRI_8_train), np.array(y_BMRI_8_train)\n",
        "X_BMRI_8_train = np.reshape(X_BMRI_8_train, (X_BMRI_8_train.shape[0], X_BMRI_8_train.shape[1], 1))\n",
        "model_BMRI_8 = Sequential()\n",
        "model_BMRI_8.add(LSTM(units=50,return_sequences=True,input_shape=(X_BMRI_8_train.shape[1], 1)))\n",
        "model_BMRI_8.add(Dropout(0.2))\n",
        "model_BMRI_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_8.add(Dropout(0.2))\n",
        "model_BMRI_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_8.add(Dropout(0.2))\n",
        "model_BMRI_8.add(LSTM(units=50))\n",
        "model_BMRI_8.add(Dropout(0.2))\n",
        "model_BMRI_8.add(Dense(units=1))\n",
        "model_BMRI_8.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BMRI_8.fit(X_BMRI_8_train,y_BMRI_8_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBRI\n",
        "BBRI_8 = yf.download(\"BBRI.JK\", start=\"2022-07-10\", end=\"2023-01-10\")\n",
        "BBRI_8.insert(4,\"Return\", BBRI_8['Close'].pct_change())\n",
        "BBRI_8 = BBRI_8.dropna()\n",
        "BBRI_8_test = yf.download(\"BBRI.JK\", start=\"2023-01-09\", end=\"2023-02-10\")\n",
        "BBRI_8_test.insert(4,\"Return\", BBRI_8_test['Close'].pct_change())\n",
        "BBRI_8_test = BBRI_8_test.dropna()\n",
        "training_BBRI_8 = BBRI_8.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBRI_8_scaled = sc.fit_transform(training_BBRI_8)\n",
        "X_BBRI_8_train = []\n",
        "y_BBRI_8_train = []\n",
        "for i in range(days_period, len(BBRI_8)-1):\n",
        "    X_BBRI_8_train.append(training_BBRI_8_scaled[i-days_period:i, 0])\n",
        "    y_BBRI_8_train.append(training_BBRI_8_scaled[i, 0])\n",
        "X_BBRI_8_train, y_BBRI_8_train = np.array(X_BBRI_8_train), np.array(y_BBRI_8_train)\n",
        "X_BBRI_8_train = np.reshape(X_BBRI_8_train, (X_BBRI_8_train.shape[0], X_BBRI_8_train.shape[1], 1))\n",
        "model_BBRI_8 = Sequential()\n",
        "model_BBRI_8.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBRI_8_train.shape[1], 1)))\n",
        "model_BBRI_8.add(Dropout(0.2))\n",
        "model_BBRI_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_8.add(Dropout(0.2))\n",
        "model_BBRI_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_8.add(Dropout(0.2))\n",
        "model_BBRI_8.add(LSTM(units=50))\n",
        "model_BBRI_8.add(Dropout(0.2))\n",
        "model_BBRI_8.add(Dense(units=1))\n",
        "model_BBRI_8.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBRI_8.fit(X_BBRI_8_train,y_BBRI_8_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBTN\n",
        "BBTN_8 = yf.download(\"BBTN.JK\", start=\"2022-07-10\", end=\"2023-01-10\")\n",
        "BBTN_8.insert(4,\"Return\", BBTN_8['Close'].pct_change())\n",
        "BBTN_8 = BBTN_8.dropna()\n",
        "BBTN_8_test = yf.download(\"BBTN.JK\", start=\"2023-01-09\", end=\"2023-02-10\")\n",
        "BBTN_8_test.insert(4,\"Return\", BBTN_8_test['Close'].pct_change())\n",
        "BBTN_8_test = BBTN_8_test.dropna()\n",
        "training_BBTN_8 = BBTN_8.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBTN_8_scaled = sc.fit_transform(training_BBTN_8)\n",
        "X_BBTN_8_train = []\n",
        "y_BBTN_8_train = []\n",
        "for i in range(days_period, len(BBTN_8)-1):\n",
        "    X_BBTN_8_train.append(training_BBTN_8_scaled[i-days_period:i, 0])\n",
        "    y_BBTN_8_train.append(training_BBTN_8_scaled[i, 0])\n",
        "X_BBTN_8_train, y_BBTN_8_train = np.array(X_BBTN_8_train), np.array(y_BBTN_8_train)\n",
        "X_BBTN_8_train = np.reshape(X_BBTN_8_train, (X_BBTN_8_train.shape[0], X_BBTN_8_train.shape[1], 1))\n",
        "model_BBTN_8 = Sequential()\n",
        "model_BBTN_8.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBTN_8_train.shape[1], 1)))\n",
        "model_BBTN_8.add(Dropout(0.2))\n",
        "model_BBTN_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_8.add(Dropout(0.2))\n",
        "model_BBTN_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_8.add(Dropout(0.2))\n",
        "model_BBTN_8.add(LSTM(units=50))\n",
        "model_BBTN_8.add(Dropout(0.2))\n",
        "model_BBTN_8.add(Dense(units=1))\n",
        "model_BBTN_8.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBTN_8.fit(X_BBTN_8_train,y_BBTN_8_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BUMI\n",
        "BUMI_8 = yf.download(\"BUMI.JK\", start=\"2022-07-10\", end=\"2023-01-10\")\n",
        "BUMI_8.insert(4,\"Return\", BUMI_8['Close'].pct_change())\n",
        "BUMI_8 = BUMI_8.dropna()\n",
        "BUMI_8_test = yf.download(\"BUMI.JK\", start=\"2023-01-09\", end=\"2023-02-10\")\n",
        "BUMI_8_test.insert(4,\"Return\", BUMI_8_test['Close'].pct_change())\n",
        "BUMI_8_test = BUMI_8_test.dropna()\n",
        "training_BUMI_8 = BUMI_8.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BUMI_8_scaled = sc.fit_transform(training_BUMI_8)\n",
        "X_BUMI_8_train = []\n",
        "y_BUMI_8_train = []\n",
        "for i in range(days_period, len(BUMI_8)-1):\n",
        "    X_BUMI_8_train.append(training_BUMI_8_scaled[i-days_period:i, 0])\n",
        "    y_BUMI_8_train.append(training_BUMI_8_scaled[i, 0])\n",
        "X_BUMI_8_train, y_BUMI_8_train = np.array(X_BUMI_8_train), np.array(y_BUMI_8_train)\n",
        "X_BUMI_8_train = np.reshape(X_BUMI_8_train, (X_BUMI_8_train.shape[0], X_BUMI_8_train.shape[1], 1))\n",
        "model_BUMI_8 = Sequential()\n",
        "model_BUMI_8.add(LSTM(units=50,return_sequences=True,input_shape=(X_BUMI_8_train.shape[1], 1)))\n",
        "model_BUMI_8.add(Dropout(0.2))\n",
        "model_BUMI_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_8.add(Dropout(0.2))\n",
        "model_BUMI_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_8.add(Dropout(0.2))\n",
        "model_BUMI_8.add(LSTM(units=50))\n",
        "model_BUMI_8.add(Dropout(0.2))\n",
        "model_BUMI_8.add(Dense(units=1))\n",
        "model_BUMI_8.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BUMI_8.fit(X_BUMI_8_train,y_BUMI_8_train,epochs=10,batch_size=16)\n",
        "\n",
        "# MFIN\n",
        "MFIN_8 = yf.download(\"MFIN.JK\", start=\"2022-07-10\", end=\"2023-01-10\")\n",
        "MFIN_8.insert(4,\"Return\", MFIN_8['Close'].pct_change())\n",
        "MFIN_8 = MFIN_8.dropna()\n",
        "MFIN_8_test = yf.download(\"MFIN.JK\", start=\"2023-01-09\", end=\"2023-02-10\")\n",
        "MFIN_8_test.insert(4,\"Return\", MFIN_8_test['Close'].pct_change())\n",
        "MFIN_8_test = MFIN_8_test.dropna()\n",
        "training_MFIN_8 = MFIN_8.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_MFIN_8_scaled = sc.fit_transform(training_MFIN_8)\n",
        "X_MFIN_8_train = []\n",
        "y_MFIN_8_train = []\n",
        "for i in range(days_period, len(MFIN_8)-1):\n",
        "    X_MFIN_8_train.append(training_MFIN_8_scaled[i-days_period:i, 0])\n",
        "    y_MFIN_8_train.append(training_MFIN_8_scaled[i, 0])\n",
        "X_MFIN_8_train, y_MFIN_8_train = np.array(X_MFIN_8_train), np.array(y_MFIN_8_train)\n",
        "X_MFIN_8_train = np.reshape(X_MFIN_8_train, (X_MFIN_8_train.shape[0], X_MFIN_8_train.shape[1], 1))\n",
        "model_MFIN_8 = Sequential()\n",
        "model_MFIN_8.add(LSTM(units=50,return_sequences=True,input_shape=(X_MFIN_8_train.shape[1], 1)))\n",
        "model_MFIN_8.add(Dropout(0.2))\n",
        "model_MFIN_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_8.add(Dropout(0.2))\n",
        "model_MFIN_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_8.add(Dropout(0.2))\n",
        "model_MFIN_8.add(LSTM(units=50))\n",
        "model_MFIN_8.add(Dropout(0.2))\n",
        "model_MFIN_8.add(Dense(units=1))\n",
        "model_MFIN_8.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_MFIN_8.fit(X_MFIN_8_train,y_MFIN_8_train,epochs=10,batch_size=16)\n",
        "\n",
        "# EXCL\n",
        "EXCL_8 = yf.download(\"EXCL.JK\", start=\"2022-07-10\", end=\"2023-01-10\")\n",
        "EXCL_8.insert(4,\"Return\", EXCL_8['Close'].pct_change())\n",
        "EXCL_8 = EXCL_8.dropna()\n",
        "EXCL_8_test = yf.download(\"EXCL.JK\", start=\"2023-01-09\", end=\"2023-02-10\")\n",
        "EXCL_8_test.insert(4,\"Return\", EXCL_8_test['Close'].pct_change())\n",
        "EXCL_8_test = EXCL_8_test.dropna()\n",
        "training_EXCL_8 = EXCL_8.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_EXCL_8_scaled = sc.fit_transform(training_EXCL_8)\n",
        "X_EXCL_8_train = []\n",
        "y_EXCL_8_train = []\n",
        "for i in range(days_period, len(EXCL_8)-1):\n",
        "    X_EXCL_8_train.append(training_EXCL_8_scaled[i-days_period:i, 0])\n",
        "    y_EXCL_8_train.append(training_EXCL_8_scaled[i, 0])\n",
        "X_EXCL_8_train, y_EXCL_8_train = np.array(X_EXCL_8_train), np.array(y_EXCL_8_train)\n",
        "X_EXCL_8_train = np.reshape(X_EXCL_8_train, (X_EXCL_8_train.shape[0], X_EXCL_8_train.shape[1], 1))\n",
        "model_EXCL_8 = Sequential()\n",
        "model_EXCL_8.add(LSTM(units=50,return_sequences=True,input_shape=(X_EXCL_8_train.shape[1], 1)))\n",
        "model_EXCL_8.add(Dropout(0.2))\n",
        "model_EXCL_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_8.add(Dropout(0.2))\n",
        "model_EXCL_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_8.add(Dropout(0.2))\n",
        "model_EXCL_8.add(LSTM(units=50))\n",
        "model_EXCL_8.add(Dropout(0.2))\n",
        "model_EXCL_8.add(Dense(units=1))\n",
        "model_EXCL_8.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_EXCL_8.fit(X_EXCL_8_train,y_EXCL_8_train,epochs=10,batch_size=16)\n",
        "\n",
        "# PGAS\n",
        "PGAS_8 = yf.download(\"PGAS.JK\", start=\"2022-07-10\", end=\"2023-01-10\")\n",
        "PGAS_8.insert(4,\"Return\", PGAS_8['Close'].pct_change())\n",
        "PGAS_8 = PGAS_8.dropna()\n",
        "PGAS_8_test = yf.download(\"PGAS.JK\", start=\"2023-01-09\", end=\"2023-02-10\")\n",
        "PGAS_8_test.insert(4,\"Return\", PGAS_8_test['Close'].pct_change())\n",
        "PGAS_8_test = PGAS_8_test.dropna()\n",
        "training_PGAS_8 = PGAS_8.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_PGAS_8_scaled = sc.fit_transform(training_PGAS_8)\n",
        "X_PGAS_8_train = []\n",
        "y_PGAS_8_train = []\n",
        "for i in range(days_period, len(PGAS_8)-1):\n",
        "    X_PGAS_8_train.append(training_PGAS_8_scaled[i-days_period:i, 0])\n",
        "    y_PGAS_8_train.append(training_PGAS_8_scaled[i, 0])\n",
        "X_PGAS_8_train, y_PGAS_8_train = np.array(X_PGAS_8_train), np.array(y_PGAS_8_train)\n",
        "X_PGAS_8_train = np.reshape(X_PGAS_8_train, (X_PGAS_8_train.shape[0], X_PGAS_8_train.shape[1], 1))\n",
        "model_PGAS_8 = Sequential()\n",
        "model_PGAS_8.add(LSTM(units=50,return_sequences=True,input_shape=(X_PGAS_8_train.shape[1], 1)))\n",
        "model_PGAS_8.add(Dropout(0.2))\n",
        "model_PGAS_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_8.add(Dropout(0.2))\n",
        "model_PGAS_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_8.add(Dropout(0.2))\n",
        "model_PGAS_8.add(LSTM(units=50))\n",
        "model_PGAS_8.add(Dropout(0.2))\n",
        "model_PGAS_8.add(Dense(units=1))\n",
        "model_PGAS_8.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_PGAS_8.fit(X_PGAS_8_train,y_PGAS_8_train,epochs=10,batch_size=16)\n",
        "\n",
        "# TLKM\n",
        "TLKM_8 = yf.download(\"TLKM.JK\", start=\"2022-07-10\", end=\"2023-01-10\")\n",
        "TLKM_8.insert(4,\"Return\", TLKM_8['Close'].pct_change())\n",
        "TLKM_8 = TLKM_8.dropna()\n",
        "TLKM_8_test = yf.download(\"TLKM.JK\", start=\"2023-01-09\", end=\"2023-02-10\")\n",
        "TLKM_8_test.insert(4,\"Return\", TLKM_8_test['Close'].pct_change())\n",
        "TLKM_8_test = TLKM_8_test.dropna()\n",
        "training_TLKM_8 = TLKM_8.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_TLKM_8_scaled = sc.fit_transform(training_TLKM_8)\n",
        "X_TLKM_8_train = []\n",
        "y_TLKM_8_train = []\n",
        "for i in range(days_period, len(TLKM_8)-1):\n",
        "    X_TLKM_8_train.append(training_TLKM_8_scaled[i-days_period:i, 0])\n",
        "    y_TLKM_8_train.append(training_TLKM_8_scaled[i, 0])\n",
        "X_TLKM_8_train, y_TLKM_8_train = np.array(X_TLKM_8_train), np.array(y_TLKM_8_train)\n",
        "X_TLKM_8_train = np.reshape(X_TLKM_8_train, (X_TLKM_8_train.shape[0], X_TLKM_8_train.shape[1], 1))\n",
        "model_TLKM_8 = Sequential()\n",
        "model_TLKM_8.add(LSTM(units=50,return_sequences=True,input_shape=(X_TLKM_8_train.shape[1], 1)))\n",
        "model_TLKM_8.add(Dropout(0.2))\n",
        "model_TLKM_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_8.add(Dropout(0.2))\n",
        "model_TLKM_8.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_8.add(Dropout(0.2))\n",
        "model_TLKM_8.add(LSTM(units=50))\n",
        "model_TLKM_8.add(Dropout(0.2))\n",
        "model_TLKM_8.add(Dense(units=1))\n",
        "model_TLKM_8.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_TLKM_8.fit(X_TLKM_8_train,y_TLKM_8_train,epochs=10,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihQtNdTifVn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67aa808-f59d-48e5-8f2b-1b6768c46db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        }
      ],
      "source": [
        "# ADRO\n",
        "real_ADRO_8_return = ADRO_8_test.iloc[:, 4:5].values\n",
        "real_ADRO_8_return = real_ADRO_8_return[:days_predict]\n",
        "ADRO_8_total = ADRO_8['Close'].copy(deep=True)\n",
        "inputs_ADRO_8 = ADRO_8_total[len(ADRO_8) - days_period: len(ADRO_8)].values\n",
        "inputs_ADRO_8 = inputs_ADRO_8.reshape(-1,1)\n",
        "inputs_ADRO_8 = sc.transform(inputs_ADRO_8)\n",
        "predicted_ADRO_8_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ADRO_8_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ADRO_8_test.append(inputs_ADRO_8[i:i+days_period, 0])\n",
        "  X_ADRO_8_test = np.array(X_ADRO_8_test)\n",
        "  X_ADRO_8_test = np.reshape(X_ADRO_8_test, (X_ADRO_8_test.shape[0], X_ADRO_8_test.shape[1], 1))\n",
        "  predicted_ADRO_8_return[j] = model_ADRO_8.predict(X_ADRO_8_test)\n",
        "  inputs_ADRO_8 += (predicted_ADRO_8_return[j])\n",
        "  inputs_ADRO_8 = inputs_ADRO_8.reshape(-1,1)\n",
        "\n",
        "# ASII\n",
        "real_ASII_8_return = ASII_8_test.iloc[:, 4:5].values\n",
        "real_ASII_8_return = real_ASII_8_return[:days_predict]\n",
        "ASII_8_total = ASII_8['Close'].copy(deep=True)\n",
        "inputs_ASII_8 = ASII_8_total[len(ASII_8) - days_period: len(ASII_8)].values\n",
        "inputs_ASII_8 = inputs_ASII_8.reshape(-1,1)\n",
        "inputs_ASII_8 = sc.transform(inputs_ASII_8)\n",
        "predicted_ASII_8_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ASII_8_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ASII_8_test.append(inputs_ASII_8[i:i+days_period, 0])\n",
        "  X_ASII_8_test = np.array(X_ASII_8_test)\n",
        "  X_ASII_8_test = np.reshape(X_ASII_8_test, (X_ASII_8_test.shape[0], X_ASII_8_test.shape[1], 1))\n",
        "  predicted_ASII_8_return[j] = model_ASII_8.predict(X_ASII_8_test)\n",
        "  inputs_ASII_8 += (predicted_ASII_8_return[j])\n",
        "  inputs_ASII_8 = inputs_ASII_8.reshape(-1,1)\n",
        "\n",
        "# BMRI\n",
        "real_BMRI_8_return = BMRI_8_test.iloc[:, 4:5].values\n",
        "real_BMRI_8_return = real_BMRI_8_return[:days_predict]\n",
        "BMRI_8_total = BMRI_8['Close'].copy(deep=True)\n",
        "inputs_BMRI_8 = BMRI_8_total[len(BMRI_8) - days_period: len(BMRI_8)].values\n",
        "inputs_BMRI_8 = inputs_BMRI_8.reshape(-1,1)\n",
        "inputs_BMRI_8 = sc.transform(inputs_BMRI_8)\n",
        "predicted_BMRI_8_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BMRI_8_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BMRI_8_test.append(inputs_BMRI_8[i:i+days_period, 0])\n",
        "  X_BMRI_8_test = np.array(X_BMRI_8_test)\n",
        "  X_BMRI_8_test = np.reshape(X_BMRI_8_test, (X_BMRI_8_test.shape[0], X_BMRI_8_test.shape[1], 1))\n",
        "  predicted_BMRI_8_return[j] = model_BMRI_8.predict(X_BMRI_8_test)\n",
        "  inputs_BMRI_8 += (predicted_BMRI_8_return[j])\n",
        "  inputs_BMRI_8 = inputs_BMRI_8.reshape(-1,1)\n",
        "\n",
        "# BBRI\n",
        "real_BBRI_8_return = BBRI_8_test.iloc[:, 4:5].values\n",
        "real_BBRI_8_return = real_BBRI_8_return[:days_predict]\n",
        "BBRI_8_total = BBRI_8['Close'].copy(deep=True)\n",
        "inputs_BBRI_8 = BBRI_8_total[len(BBRI_8) - days_period: len(BBRI_8)].values\n",
        "inputs_BBRI_8 = inputs_BBRI_8.reshape(-1,1)\n",
        "inputs_BBRI_8 = sc.transform(inputs_BBRI_8)\n",
        "predicted_BBRI_8_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBRI_8_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBRI_8_test.append(inputs_BBRI_8[i:i+days_period, 0])\n",
        "  X_BBRI_8_test = np.array(X_BBRI_8_test)\n",
        "  X_BBRI_8_test = np.reshape(X_BBRI_8_test, (X_BBRI_8_test.shape[0], X_BBRI_8_test.shape[1], 1))\n",
        "  predicted_BBRI_8_return[j] = model_BBRI_8.predict(X_BBRI_8_test)\n",
        "  inputs_BBRI_8 += (predicted_BBRI_8_return[j])\n",
        "  inputs_BBRI_8 = inputs_BBRI_8.reshape(-1,1)\n",
        "\n",
        "# BBTN\n",
        "real_BBTN_8_return = BBTN_8_test.iloc[:, 4:5].values\n",
        "real_BBTN_8_return = real_BBTN_8_return[:days_predict]\n",
        "BBTN_8_total = BBTN_8['Close'].copy(deep=True)\n",
        "inputs_BBTN_8 = BBTN_8_total[len(BBTN_8) - days_period: len(BBTN_8)].values\n",
        "inputs_BBTN_8 = inputs_BBTN_8.reshape(-1,1)\n",
        "inputs_BBTN_8 = sc.transform(inputs_BBTN_8)\n",
        "predicted_BBTN_8_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBTN_8_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBTN_8_test.append(inputs_BBTN_8[i:i+days_period, 0])\n",
        "  X_BBTN_8_test = np.array(X_BBTN_8_test)\n",
        "  X_BBTN_8_test = np.reshape(X_BBTN_8_test, (X_BBTN_8_test.shape[0], X_BBTN_8_test.shape[1], 1))\n",
        "  predicted_BBTN_8_return[j] = model_BBTN_8.predict(X_BBTN_8_test)\n",
        "  inputs_BBTN_8 += (predicted_BBTN_8_return[j])\n",
        "  inputs_BBTN_8 = inputs_BBTN_8.reshape(-1,1)\n",
        "\n",
        "# BUMI\n",
        "real_BUMI_8_return = BUMI_8_test.iloc[:, 4:5].values\n",
        "real_BUMI_8_return = real_BUMI_8_return[:days_predict]\n",
        "BUMI_8_total = BUMI_8['Close'].copy(deep=True)\n",
        "inputs_BUMI_8 = BUMI_8_total[len(BUMI_8) - days_period: len(BUMI_8)].values\n",
        "inputs_BUMI_8 = inputs_BUMI_8.reshape(-1,1)\n",
        "inputs_BUMI_8 = sc.transform(inputs_BUMI_8)\n",
        "predicted_BUMI_8_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BUMI_8_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BUMI_8_test.append(inputs_BUMI_8[i:i+days_period, 0])\n",
        "  X_BUMI_8_test = np.array(X_BUMI_8_test)\n",
        "  X_BUMI_8_test = np.reshape(X_BUMI_8_test, (X_BUMI_8_test.shape[0], X_BUMI_8_test.shape[1], 1))\n",
        "  predicted_BUMI_8_return[j] = model_BUMI_8.predict(X_BUMI_8_test)\n",
        "  inputs_BUMI_8 += (predicted_BUMI_8_return[j])\n",
        "  inputs_BUMI_8 = inputs_BUMI_8.reshape(-1,1)\n",
        "\n",
        "# MFIN\n",
        "real_MFIN_8_return = MFIN_8_test.iloc[:, 4:5].values\n",
        "real_MFIN_8_return = real_MFIN_8_return[:days_predict]\n",
        "MFIN_8_total = MFIN_8['Close'].copy(deep=True)\n",
        "inputs_MFIN_8 = MFIN_8_total[len(MFIN_8) - days_period: len(MFIN_8)].values\n",
        "inputs_MFIN_8 = inputs_MFIN_8.reshape(-1,1)\n",
        "inputs_MFIN_8 = sc.transform(inputs_MFIN_8)\n",
        "predicted_MFIN_8_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_MFIN_8_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_MFIN_8_test.append(inputs_MFIN_8[i:i+days_period, 0])\n",
        "  X_MFIN_8_test = np.array(X_MFIN_8_test)\n",
        "  X_MFIN_8_test = np.reshape(X_MFIN_8_test, (X_MFIN_8_test.shape[0], X_MFIN_8_test.shape[1], 1))\n",
        "  predicted_MFIN_8_return[j] = model_MFIN_8.predict(X_MFIN_8_test)\n",
        "  inputs_MFIN_8 += (predicted_MFIN_8_return[j])\n",
        "  inputs_MFIN_8 = inputs_MFIN_8.reshape(-1,1)\n",
        "\n",
        "# EXCL\n",
        "real_EXCL_8_return = EXCL_8_test.iloc[:, 4:5].values\n",
        "real_EXCL_8_return = real_EXCL_8_return[:days_predict]\n",
        "EXCL_8_total = EXCL_8['Close'].copy(deep=True)\n",
        "inputs_EXCL_8 = EXCL_8_total[len(EXCL_8) - days_period: len(EXCL_8)].values\n",
        "inputs_EXCL_8 = inputs_EXCL_8.reshape(-1,1)\n",
        "inputs_EXCL_8 = sc.transform(inputs_EXCL_8)\n",
        "predicted_EXCL_8_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_EXCL_8_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_EXCL_8_test.append(inputs_EXCL_8[i:i+days_period, 0])\n",
        "  X_EXCL_8_test = np.array(X_EXCL_8_test)\n",
        "  X_EXCL_8_test = np.reshape(X_EXCL_8_test, (X_EXCL_8_test.shape[0], X_EXCL_8_test.shape[1], 1))\n",
        "  predicted_EXCL_8_return[j] = model_EXCL_8.predict(X_EXCL_8_test)\n",
        "  inputs_EXCL_8 += (predicted_EXCL_8_return[j])\n",
        "  inputs_EXCL_8 = inputs_EXCL_8.reshape(-1,1)\n",
        "\n",
        "# PGAS\n",
        "real_PGAS_8_return = PGAS_8_test.iloc[:, 4:5].values\n",
        "real_PGAS_8_return = real_PGAS_8_return[:days_predict]\n",
        "PGAS_8_total = PGAS_8['Close'].copy(deep=True)\n",
        "inputs_PGAS_8 = PGAS_8_total[len(PGAS_8) - days_period: len(PGAS_8)].values\n",
        "inputs_PGAS_8 = inputs_PGAS_8.reshape(-1,1)\n",
        "inputs_PGAS_8 = sc.transform(inputs_PGAS_8)\n",
        "predicted_PGAS_8_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_PGAS_8_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_PGAS_8_test.append(inputs_PGAS_8[i:i+days_period, 0])\n",
        "  X_PGAS_8_test = np.array(X_PGAS_8_test)\n",
        "  X_PGAS_8_test = np.reshape(X_PGAS_8_test, (X_PGAS_8_test.shape[0], X_PGAS_8_test.shape[1], 1))\n",
        "  predicted_PGAS_8_return[j] = model_PGAS_8.predict(X_PGAS_8_test)\n",
        "  inputs_PGAS_8 += (predicted_PGAS_8_return[j])\n",
        "  inputs_PGAS_8 = inputs_PGAS_8.reshape(-1,1)\n",
        "\n",
        "# TLKM\n",
        "real_TLKM_8_return = TLKM_8_test.iloc[:, 4:5].values\n",
        "real_TLKM_8_return = real_TLKM_8_return[:days_predict]\n",
        "TLKM_8_total = TLKM_8['Close'].copy(deep=True)\n",
        "inputs_TLKM_8 = TLKM_8_total[len(TLKM_8) - days_period: len(TLKM_8)].values\n",
        "inputs_TLKM_8 = inputs_TLKM_8.reshape(-1,1)\n",
        "inputs_TLKM_8 = sc.transform(inputs_TLKM_8)\n",
        "predicted_TLKM_8_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_TLKM_8_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_TLKM_8_test.append(inputs_TLKM_8[i:i+days_period, 0])\n",
        "  X_TLKM_8_test = np.array(X_TLKM_8_test)\n",
        "  X_TLKM_8_test = np.reshape(X_TLKM_8_test, (X_TLKM_8_test.shape[0], X_TLKM_8_test.shape[1], 1))\n",
        "  predicted_TLKM_8_return[j] = model_TLKM_8.predict(X_TLKM_8_test)\n",
        "  inputs_TLKM_8 += (predicted_TLKM_8_return[j])\n",
        "  inputs_TLKM_8 = inputs_TLKM_8.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZncOoLySfVoA"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "predicted_ADRO_8_return = np.squeeze(np.asarray(predicted_ADRO_8_return))\n",
        "predicted_ADRO_8_return = predicted_ADRO_8_return.reshape(-1,1)\n",
        "predicted_ADRO_8_return = sc.inverse_transform(predicted_ADRO_8_return)\n",
        "# ASII\n",
        "predicted_ASII_8_return = np.squeeze(np.asarray(predicted_ASII_8_return))\n",
        "predicted_ASII_8_return = predicted_ASII_8_return.reshape(-1,1)\n",
        "predicted_ASII_8_return = sc.inverse_transform(predicted_ASII_8_return)\n",
        "# BMRI\n",
        "predicted_BMRI_8_return = np.squeeze(np.asarray(predicted_BMRI_8_return))\n",
        "predicted_BMRI_8_return = predicted_BMRI_8_return.reshape(-1,1)\n",
        "predicted_BMRI_8_return = sc.inverse_transform(predicted_BMRI_8_return)\n",
        "# BBRI\n",
        "predicted_BBRI_8_return = np.squeeze(np.asarray(predicted_BBRI_8_return))\n",
        "predicted_BBRI_8_return = predicted_BBRI_8_return.reshape(-1,1)\n",
        "predicted_BBRI_8_return = sc.inverse_transform(predicted_BBRI_8_return)\n",
        "# BBTN\n",
        "predicted_BBTN_8_return = np.squeeze(np.asarray(predicted_BBTN_8_return))\n",
        "predicted_BBTN_8_return = predicted_BBTN_8_return.reshape(-1,1)\n",
        "predicted_BBTN_8_return = sc.inverse_transform(predicted_BBTN_8_return)\n",
        "# BUMI\n",
        "predicted_BUMI_8_return = np.squeeze(np.asarray(predicted_BUMI_8_return))\n",
        "predicted_BUMI_8_return = predicted_BUMI_8_return.reshape(-1,1)\n",
        "predicted_BUMI_8_return = sc.inverse_transform(predicted_BUMI_8_return)\n",
        "# MFIN\n",
        "predicted_MFIN_8_return = np.squeeze(np.asarray(predicted_MFIN_8_return))\n",
        "predicted_MFIN_8_return = predicted_MFIN_8_return.reshape(-1,1)\n",
        "predicted_MFIN_8_return = sc.inverse_transform(predicted_MFIN_8_return)\n",
        "# EXCL\n",
        "predicted_EXCL_8_return = np.squeeze(np.asarray(predicted_EXCL_8_return))\n",
        "predicted_EXCL_8_return = predicted_EXCL_8_return.reshape(-1,1)\n",
        "predicted_EXCL_8_return = sc.inverse_transform(predicted_EXCL_8_return)\n",
        "# PGAS\n",
        "predicted_PGAS_8_return = np.squeeze(np.asarray(predicted_PGAS_8_return))\n",
        "predicted_PGAS_8_return = predicted_PGAS_8_return.reshape(-1,1)\n",
        "predicted_PGAS_8_return = sc.inverse_transform(predicted_PGAS_8_return)\n",
        "# TLKM\n",
        "predicted_TLKM_8_return = np.squeeze(np.asarray(predicted_TLKM_8_return))\n",
        "predicted_TLKM_8_return = predicted_TLKM_8_return.reshape(-1,1)\n",
        "predicted_TLKM_8_return = sc.inverse_transform(predicted_TLKM_8_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r8CjN_WfVoB"
      },
      "outputs": [],
      "source": [
        "predicted8 = pd.DataFrame(predicted_ADRO_8_return)\n",
        "predicted8.rename(columns={0:'ADRO'}, inplace=True)\n",
        "predicted8.insert(1,\"ASII\", predicted_ASII_8_return)\n",
        "predicted8.insert(2,\"BBRI\", predicted_BBRI_8_return)\n",
        "predicted8.insert(3,\"BBTN\", predicted_BBTN_8_return)\n",
        "predicted8.insert(4,\"BMRI\", predicted_BMRI_8_return)\n",
        "predicted8.insert(5,\"BUMI\", predicted_BUMI_8_return)\n",
        "predicted8.insert(6,\"EXCL\", predicted_EXCL_8_return)\n",
        "predicted8.insert(7,\"MFIN\", predicted_MFIN_8_return)\n",
        "predicted8.insert(8,\"PGAS\", predicted_PGAS_8_return)\n",
        "predicted8.insert(9,\"TLKM\", predicted_TLKM_8_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyJbdmo6RWMC",
        "outputId": "7385344a-856f-46d6-d9b1-2ba2e0543dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADRO      ASII      BBRI      BBTN      BMRI      BUMI      EXCL  \\\n",
              "0  0.016507 -0.005660 -0.006197  0.024816 -0.018712 -0.029348 -0.046260   \n",
              "1  0.015618 -0.006324 -0.006883  0.023891 -0.018932 -0.029603 -0.046155   \n",
              "2  0.014539 -0.007130 -0.007706  0.022775 -0.019248 -0.029911 -0.046062   \n",
              "3  0.013235 -0.008103 -0.008690  0.021431 -0.019684 -0.030284 -0.045992   \n",
              "4  0.011665 -0.009270 -0.009860  0.019815 -0.020267 -0.030735 -0.045954   \n",
              "5  0.009784 -0.010660 -0.011243  0.017877 -0.021029 -0.031282 -0.045959   \n",
              "6  0.007543 -0.012304 -0.012868  0.015562 -0.022003 -0.031942 -0.046024   \n",
              "7  0.004889 -0.014232 -0.014765  0.012806 -0.023227 -0.032738 -0.046166   \n",
              "8  0.001770 -0.016473 -0.016961  0.009546 -0.024737 -0.033696 -0.046404   \n",
              "9 -0.001862 -0.019051 -0.019480  0.005713 -0.026564 -0.034842 -0.046763   \n",
              "\n",
              "       MFIN      PGAS      TLKM  \n",
              "0  0.004399  0.003834  0.025538  \n",
              "1  0.003463  0.003588  0.024547  \n",
              "2  0.002345  0.003221  0.023345  \n",
              "3  0.001013  0.002699  0.021890  \n",
              "4 -0.000565  0.001980  0.020137  \n",
              "5 -0.002424  0.001017  0.018035  \n",
              "6 -0.004599 -0.000244  0.015529  \n",
              "7 -0.007124 -0.001866  0.012558  \n",
              "8 -0.010028 -0.003915  0.009063  \n",
              "9 -0.013333 -0.006458  0.004988  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-396accb9-2a98-43f2-b15f-f2fc01ecf039\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADRO</th>\n",
              "      <th>ASII</th>\n",
              "      <th>BBRI</th>\n",
              "      <th>BBTN</th>\n",
              "      <th>BMRI</th>\n",
              "      <th>BUMI</th>\n",
              "      <th>EXCL</th>\n",
              "      <th>MFIN</th>\n",
              "      <th>PGAS</th>\n",
              "      <th>TLKM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.016507</td>\n",
              "      <td>-0.005660</td>\n",
              "      <td>-0.006197</td>\n",
              "      <td>0.024816</td>\n",
              "      <td>-0.018712</td>\n",
              "      <td>-0.029348</td>\n",
              "      <td>-0.046260</td>\n",
              "      <td>0.004399</td>\n",
              "      <td>0.003834</td>\n",
              "      <td>0.025538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.015618</td>\n",
              "      <td>-0.006324</td>\n",
              "      <td>-0.006883</td>\n",
              "      <td>0.023891</td>\n",
              "      <td>-0.018932</td>\n",
              "      <td>-0.029603</td>\n",
              "      <td>-0.046155</td>\n",
              "      <td>0.003463</td>\n",
              "      <td>0.003588</td>\n",
              "      <td>0.024547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.014539</td>\n",
              "      <td>-0.007130</td>\n",
              "      <td>-0.007706</td>\n",
              "      <td>0.022775</td>\n",
              "      <td>-0.019248</td>\n",
              "      <td>-0.029911</td>\n",
              "      <td>-0.046062</td>\n",
              "      <td>0.002345</td>\n",
              "      <td>0.003221</td>\n",
              "      <td>0.023345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.013235</td>\n",
              "      <td>-0.008103</td>\n",
              "      <td>-0.008690</td>\n",
              "      <td>0.021431</td>\n",
              "      <td>-0.019684</td>\n",
              "      <td>-0.030284</td>\n",
              "      <td>-0.045992</td>\n",
              "      <td>0.001013</td>\n",
              "      <td>0.002699</td>\n",
              "      <td>0.021890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.011665</td>\n",
              "      <td>-0.009270</td>\n",
              "      <td>-0.009860</td>\n",
              "      <td>0.019815</td>\n",
              "      <td>-0.020267</td>\n",
              "      <td>-0.030735</td>\n",
              "      <td>-0.045954</td>\n",
              "      <td>-0.000565</td>\n",
              "      <td>0.001980</td>\n",
              "      <td>0.020137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.009784</td>\n",
              "      <td>-0.010660</td>\n",
              "      <td>-0.011243</td>\n",
              "      <td>0.017877</td>\n",
              "      <td>-0.021029</td>\n",
              "      <td>-0.031282</td>\n",
              "      <td>-0.045959</td>\n",
              "      <td>-0.002424</td>\n",
              "      <td>0.001017</td>\n",
              "      <td>0.018035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.007543</td>\n",
              "      <td>-0.012304</td>\n",
              "      <td>-0.012868</td>\n",
              "      <td>0.015562</td>\n",
              "      <td>-0.022003</td>\n",
              "      <td>-0.031942</td>\n",
              "      <td>-0.046024</td>\n",
              "      <td>-0.004599</td>\n",
              "      <td>-0.000244</td>\n",
              "      <td>0.015529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.004889</td>\n",
              "      <td>-0.014232</td>\n",
              "      <td>-0.014765</td>\n",
              "      <td>0.012806</td>\n",
              "      <td>-0.023227</td>\n",
              "      <td>-0.032738</td>\n",
              "      <td>-0.046166</td>\n",
              "      <td>-0.007124</td>\n",
              "      <td>-0.001866</td>\n",
              "      <td>0.012558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.001770</td>\n",
              "      <td>-0.016473</td>\n",
              "      <td>-0.016961</td>\n",
              "      <td>0.009546</td>\n",
              "      <td>-0.024737</td>\n",
              "      <td>-0.033696</td>\n",
              "      <td>-0.046404</td>\n",
              "      <td>-0.010028</td>\n",
              "      <td>-0.003915</td>\n",
              "      <td>0.009063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.001862</td>\n",
              "      <td>-0.019051</td>\n",
              "      <td>-0.019480</td>\n",
              "      <td>0.005713</td>\n",
              "      <td>-0.026564</td>\n",
              "      <td>-0.034842</td>\n",
              "      <td>-0.046763</td>\n",
              "      <td>-0.013333</td>\n",
              "      <td>-0.006458</td>\n",
              "      <td>0.004988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-396accb9-2a98-43f2-b15f-f2fc01ecf039')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-396accb9-2a98-43f2-b15f-f2fc01ecf039 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-396accb9-2a98-43f2-b15f-f2fc01ecf039');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "varGnXGtch2T"
      },
      "source": [
        "## Data Preparation 9\n",
        "1st of January 2018 - 9th of February 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1tD1vVnfXM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0569e6-8095-4304-a5f7-2ee0012c9db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 11s 77ms/step - loss: 0.1591\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 0.0473\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0400\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 0.0385\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0357\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0293\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0350\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0366\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0321\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0343\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 43ms/step - loss: 0.2118\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0754\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0676\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0455\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0393\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0386\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0341\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0380\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0351\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0377\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 44ms/step - loss: 0.1865\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0630\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0471\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0364\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0356\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0345\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0344\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0372\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0327\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0359\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 43ms/step - loss: 0.2302\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0774\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0519\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0524\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0494\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0469\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0466\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0486\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0434\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0458\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 42ms/step - loss: 0.1881\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0396\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0323\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0164\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0169\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0180\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0181\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0157\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0164\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0145\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 13s 75ms/step - loss: 0.0654\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 71ms/step - loss: 0.0307\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.0258\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0262\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0248\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0234\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0244\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0272\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0251\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0238\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 42ms/step - loss: 0.0643\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0310\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0294\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0178\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0228\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0220\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0171\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0193\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0201\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.0191\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 43ms/step - loss: 0.0117\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0087\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0083\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0081\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0083\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0078\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0080\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0080\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 0.0080\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0082\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 41ms/step - loss: 0.0765\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0335\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0255\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0210\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0167\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0169\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0188\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0181\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0180\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0185\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 8s 40ms/step - loss: 0.2542\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.0438\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0508\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0316\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0291\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0294\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0319\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0310\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 0.0293\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 0.0300\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efb2b6f5c90>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Period parameters\n",
        "days_period = 20\n",
        "days_predict = 10\n",
        "\n",
        "# ADRO\n",
        "ADRO_9 = yf.download(\"ADRO.JK\", start=\"2022-08-10\", end=\"2023-02-10\")\n",
        "ADRO_9.insert(4,\"Return\", ADRO_9['Close'].pct_change())\n",
        "ADRO_9 = ADRO_9.dropna()\n",
        "ADRO_9_test = yf.download(\"ADRO.JK\", start=\"2023-02-09\", end=\"2023-03-10\")\n",
        "ADRO_9_test.insert(4,\"Return\", ADRO_9_test['Close'].pct_change())\n",
        "ADRO_9_test = ADRO_9_test.dropna()\n",
        "training_ADRO_9 = ADRO_9.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ADRO_9_scaled = sc.fit_transform(training_ADRO_9)\n",
        "X_ADRO_9_train = []\n",
        "y_ADRO_9_train = []\n",
        "for i in range(days_period, len(ADRO_9)-1):\n",
        "    X_ADRO_9_train.append(training_ADRO_9_scaled[i-days_period:i, 0])\n",
        "    y_ADRO_9_train.append(training_ADRO_9_scaled[i, 0])\n",
        "X_ADRO_9_train, y_ADRO_9_train = np.array(X_ADRO_9_train), np.array(y_ADRO_9_train)\n",
        "X_ADRO_9_train = np.reshape(X_ADRO_9_train, (X_ADRO_9_train.shape[0], X_ADRO_9_train.shape[1], 1))\n",
        "model_ADRO_9 = Sequential()\n",
        "model_ADRO_9.add(LSTM(units=50,return_sequences=True,input_shape=(X_ADRO_9_train.shape[1], 1)))\n",
        "model_ADRO_9.add(Dropout(0.2))\n",
        "model_ADRO_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_9.add(Dropout(0.2))\n",
        "model_ADRO_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_9.add(Dropout(0.2))\n",
        "model_ADRO_9.add(LSTM(units=50))\n",
        "model_ADRO_9.add(Dropout(0.2))\n",
        "model_ADRO_9.add(Dense(units=1))\n",
        "model_ADRO_9.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ADRO_9.fit(X_ADRO_9_train,y_ADRO_9_train,epochs=10,batch_size=16)\n",
        "\n",
        "# ASII\n",
        "ASII_9 = yf.download(\"ASII.JK\", start=\"2022-08-10\", end=\"2023-02-10\")\n",
        "ASII_9.insert(4,\"Return\", ASII_9['Close'].pct_change())\n",
        "ASII_9 = ASII_9.dropna()\n",
        "ASII_9_test = yf.download(\"ASII.JK\", start=\"2023-02-09\", end=\"2023-03-10\")\n",
        "ASII_9_test.insert(4,\"Return\", ASII_9_test['Close'].pct_change())\n",
        "ASII_9_test = ASII_9_test.dropna()\n",
        "training_ASII_9 = ASII_9.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ASII_9_scaled = sc.fit_transform(training_ASII_9)\n",
        "X_ASII_9_train = []\n",
        "y_ASII_9_train = []\n",
        "for i in range(days_period, len(ASII_9)-1):\n",
        "    X_ASII_9_train.append(training_ASII_9_scaled[i-days_period:i, 0])\n",
        "    y_ASII_9_train.append(training_ASII_9_scaled[i, 0])\n",
        "X_ASII_9_train, y_ASII_9_train = np.array(X_ASII_9_train), np.array(y_ASII_9_train)\n",
        "X_ASII_9_train = np.reshape(X_ASII_9_train, (X_ASII_9_train.shape[0], X_ASII_9_train.shape[1], 1))\n",
        "model_ASII_9 = Sequential()\n",
        "model_ASII_9.add(LSTM(units=50,return_sequences=True,input_shape=(X_ASII_9_train.shape[1], 1)))\n",
        "model_ASII_9.add(Dropout(0.2))\n",
        "model_ASII_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_9.add(Dropout(0.2))\n",
        "model_ASII_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_9.add(Dropout(0.2))\n",
        "model_ASII_9.add(LSTM(units=50))\n",
        "model_ASII_9.add(Dropout(0.2))\n",
        "model_ASII_9.add(Dense(units=1))\n",
        "model_ASII_9.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ASII_9.fit(X_ASII_9_train,y_ASII_9_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BMRI\n",
        "BMRI_9 = yf.download(\"BMRI.JK\", start=\"2022-08-10\", end=\"2023-02-10\")\n",
        "BMRI_9.insert(4,\"Return\", BMRI_9['Close'].pct_change())\n",
        "BMRI_9 = BMRI_9.dropna()\n",
        "BMRI_9_test = yf.download(\"BMRI.JK\", start=\"2023-02-09\", end=\"2023-03-10\")\n",
        "BMRI_9_test.insert(4,\"Return\", BMRI_9_test['Close'].pct_change())\n",
        "BMRI_9_test = BMRI_9_test.dropna()\n",
        "training_BMRI_9 = BMRI_9.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BMRI_9_scaled = sc.fit_transform(training_BMRI_9)\n",
        "X_BMRI_9_train = []\n",
        "y_BMRI_9_train = []\n",
        "for i in range(days_period, len(BMRI_9)-1):\n",
        "    X_BMRI_9_train.append(training_BMRI_9_scaled[i-days_period:i, 0])\n",
        "    y_BMRI_9_train.append(training_BMRI_9_scaled[i, 0])\n",
        "X_BMRI_9_train, y_BMRI_9_train = np.array(X_BMRI_9_train), np.array(y_BMRI_9_train)\n",
        "X_BMRI_9_train = np.reshape(X_BMRI_9_train, (X_BMRI_9_train.shape[0], X_BMRI_9_train.shape[1], 1))\n",
        "model_BMRI_9 = Sequential()\n",
        "model_BMRI_9.add(LSTM(units=50,return_sequences=True,input_shape=(X_BMRI_9_train.shape[1], 1)))\n",
        "model_BMRI_9.add(Dropout(0.2))\n",
        "model_BMRI_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_9.add(Dropout(0.2))\n",
        "model_BMRI_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_9.add(Dropout(0.2))\n",
        "model_BMRI_9.add(LSTM(units=50))\n",
        "model_BMRI_9.add(Dropout(0.2))\n",
        "model_BMRI_9.add(Dense(units=1))\n",
        "model_BMRI_9.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BMRI_9.fit(X_BMRI_9_train,y_BMRI_9_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBRI\n",
        "BBRI_9 = yf.download(\"BBRI.JK\", start=\"2022-08-10\", end=\"2023-02-10\")\n",
        "BBRI_9.insert(4,\"Return\", BBRI_9['Close'].pct_change())\n",
        "BBRI_9 = BBRI_9.dropna()\n",
        "BBRI_9_test = yf.download(\"BBRI.JK\", start=\"2023-02-09\", end=\"2023-03-10\")\n",
        "BBRI_9_test.insert(4,\"Return\", BBRI_9_test['Close'].pct_change())\n",
        "BBRI_9_test = BBRI_9_test.dropna()\n",
        "training_BBRI_9 = BBRI_9.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBRI_9_scaled = sc.fit_transform(training_BBRI_9)\n",
        "X_BBRI_9_train = []\n",
        "y_BBRI_9_train = []\n",
        "for i in range(days_period, len(BBRI_9)-1):\n",
        "    X_BBRI_9_train.append(training_BBRI_9_scaled[i-days_period:i, 0])\n",
        "    y_BBRI_9_train.append(training_BBRI_9_scaled[i, 0])\n",
        "X_BBRI_9_train, y_BBRI_9_train = np.array(X_BBRI_9_train), np.array(y_BBRI_9_train)\n",
        "X_BBRI_9_train = np.reshape(X_BBRI_9_train, (X_BBRI_9_train.shape[0], X_BBRI_9_train.shape[1], 1))\n",
        "model_BBRI_9 = Sequential()\n",
        "model_BBRI_9.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBRI_9_train.shape[1], 1)))\n",
        "model_BBRI_9.add(Dropout(0.2))\n",
        "model_BBRI_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_9.add(Dropout(0.2))\n",
        "model_BBRI_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_9.add(Dropout(0.2))\n",
        "model_BBRI_9.add(LSTM(units=50))\n",
        "model_BBRI_9.add(Dropout(0.2))\n",
        "model_BBRI_9.add(Dense(units=1))\n",
        "model_BBRI_9.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBRI_9.fit(X_BBRI_9_train,y_BBRI_9_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBTN\n",
        "BBTN_9 = yf.download(\"BBTN.JK\", start=\"2022-08-10\", end=\"2023-02-10\")\n",
        "BBTN_9.insert(4,\"Return\", BBTN_9['Close'].pct_change())\n",
        "BBTN_9 = BBTN_9.dropna()\n",
        "BBTN_9_test = yf.download(\"BBTN.JK\", start=\"2023-02-09\", end=\"2023-03-10\")\n",
        "BBTN_9_test.insert(4,\"Return\", BBTN_9_test['Close'].pct_change())\n",
        "BBTN_9_test = BBTN_9_test.dropna()\n",
        "training_BBTN_9 = BBTN_9.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBTN_9_scaled = sc.fit_transform(training_BBTN_9)\n",
        "X_BBTN_9_train = []\n",
        "y_BBTN_9_train = []\n",
        "for i in range(days_period, len(BBTN_9)-1):\n",
        "    X_BBTN_9_train.append(training_BBTN_9_scaled[i-days_period:i, 0])\n",
        "    y_BBTN_9_train.append(training_BBTN_9_scaled[i, 0])\n",
        "X_BBTN_9_train, y_BBTN_9_train = np.array(X_BBTN_9_train), np.array(y_BBTN_9_train)\n",
        "X_BBTN_9_train = np.reshape(X_BBTN_9_train, (X_BBTN_9_train.shape[0], X_BBTN_9_train.shape[1], 1))\n",
        "model_BBTN_9 = Sequential()\n",
        "model_BBTN_9.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBTN_9_train.shape[1], 1)))\n",
        "model_BBTN_9.add(Dropout(0.2))\n",
        "model_BBTN_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_9.add(Dropout(0.2))\n",
        "model_BBTN_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_9.add(Dropout(0.2))\n",
        "model_BBTN_9.add(LSTM(units=50))\n",
        "model_BBTN_9.add(Dropout(0.2))\n",
        "model_BBTN_9.add(Dense(units=1))\n",
        "model_BBTN_9.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBTN_9.fit(X_BBTN_9_train,y_BBTN_9_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BUMI\n",
        "BUMI_9 = yf.download(\"BUMI.JK\", start=\"2022-08-10\", end=\"2023-02-10\")\n",
        "BUMI_9.insert(4,\"Return\", BUMI_9['Close'].pct_change())\n",
        "BUMI_9 = BUMI_9.dropna()\n",
        "BUMI_9_test = yf.download(\"BUMI.JK\", start=\"2023-02-09\", end=\"2023-03-10\")\n",
        "BUMI_9_test.insert(4,\"Return\", BUMI_9_test['Close'].pct_change())\n",
        "BUMI_9_test = BUMI_9_test.dropna()\n",
        "training_BUMI_9 = BUMI_9.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BUMI_9_scaled = sc.fit_transform(training_BUMI_9)\n",
        "X_BUMI_9_train = []\n",
        "y_BUMI_9_train = []\n",
        "for i in range(days_period, len(BUMI_9)-1):\n",
        "    X_BUMI_9_train.append(training_BUMI_9_scaled[i-days_period:i, 0])\n",
        "    y_BUMI_9_train.append(training_BUMI_9_scaled[i, 0])\n",
        "X_BUMI_9_train, y_BUMI_9_train = np.array(X_BUMI_9_train), np.array(y_BUMI_9_train)\n",
        "X_BUMI_9_train = np.reshape(X_BUMI_9_train, (X_BUMI_9_train.shape[0], X_BUMI_9_train.shape[1], 1))\n",
        "model_BUMI_9 = Sequential()\n",
        "model_BUMI_9.add(LSTM(units=50,return_sequences=True,input_shape=(X_BUMI_9_train.shape[1], 1)))\n",
        "model_BUMI_9.add(Dropout(0.2))\n",
        "model_BUMI_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_9.add(Dropout(0.2))\n",
        "model_BUMI_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_9.add(Dropout(0.2))\n",
        "model_BUMI_9.add(LSTM(units=50))\n",
        "model_BUMI_9.add(Dropout(0.2))\n",
        "model_BUMI_9.add(Dense(units=1))\n",
        "model_BUMI_9.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BUMI_9.fit(X_BUMI_9_train,y_BUMI_9_train,epochs=10,batch_size=16)\n",
        "\n",
        "# MFIN\n",
        "MFIN_9 = yf.download(\"MFIN.JK\", start=\"2022-08-10\", end=\"2023-02-10\")\n",
        "MFIN_9.insert(4,\"Return\", MFIN_9['Close'].pct_change())\n",
        "MFIN_9 = MFIN_9.dropna()\n",
        "MFIN_9_test = yf.download(\"MFIN.JK\", start=\"2023-02-09\", end=\"2023-03-10\")\n",
        "MFIN_9_test.insert(4,\"Return\", MFIN_9_test['Close'].pct_change())\n",
        "MFIN_9_test = MFIN_9_test.dropna()\n",
        "training_MFIN_9 = MFIN_9.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_MFIN_9_scaled = sc.fit_transform(training_MFIN_9)\n",
        "X_MFIN_9_train = []\n",
        "y_MFIN_9_train = []\n",
        "for i in range(days_period, len(MFIN_9)-1):\n",
        "    X_MFIN_9_train.append(training_MFIN_9_scaled[i-days_period:i, 0])\n",
        "    y_MFIN_9_train.append(training_MFIN_9_scaled[i, 0])\n",
        "X_MFIN_9_train, y_MFIN_9_train = np.array(X_MFIN_9_train), np.array(y_MFIN_9_train)\n",
        "X_MFIN_9_train = np.reshape(X_MFIN_9_train, (X_MFIN_9_train.shape[0], X_MFIN_9_train.shape[1], 1))\n",
        "model_MFIN_9 = Sequential()\n",
        "model_MFIN_9.add(LSTM(units=50,return_sequences=True,input_shape=(X_MFIN_9_train.shape[1], 1)))\n",
        "model_MFIN_9.add(Dropout(0.2))\n",
        "model_MFIN_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_9.add(Dropout(0.2))\n",
        "model_MFIN_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_9.add(Dropout(0.2))\n",
        "model_MFIN_9.add(LSTM(units=50))\n",
        "model_MFIN_9.add(Dropout(0.2))\n",
        "model_MFIN_9.add(Dense(units=1))\n",
        "model_MFIN_9.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_MFIN_9.fit(X_MFIN_9_train,y_MFIN_9_train,epochs=10,batch_size=16)\n",
        "\n",
        "# EXCL\n",
        "EXCL_9 = yf.download(\"EXCL.JK\", start=\"2022-08-10\", end=\"2023-02-10\")\n",
        "EXCL_9.insert(4,\"Return\", EXCL_9['Close'].pct_change())\n",
        "EXCL_9 = EXCL_9.dropna()\n",
        "EXCL_9_test = yf.download(\"EXCL.JK\", start=\"2023-02-09\", end=\"2023-03-10\")\n",
        "EXCL_9_test.insert(4,\"Return\", EXCL_9_test['Close'].pct_change())\n",
        "EXCL_9_test = EXCL_9_test.dropna()\n",
        "training_EXCL_9 = EXCL_9.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_EXCL_9_scaled = sc.fit_transform(training_EXCL_9)\n",
        "X_EXCL_9_train = []\n",
        "y_EXCL_9_train = []\n",
        "for i in range(days_period, len(EXCL_9)-1):\n",
        "    X_EXCL_9_train.append(training_EXCL_9_scaled[i-days_period:i, 0])\n",
        "    y_EXCL_9_train.append(training_EXCL_9_scaled[i, 0])\n",
        "X_EXCL_9_train, y_EXCL_9_train = np.array(X_EXCL_9_train), np.array(y_EXCL_9_train)\n",
        "X_EXCL_9_train = np.reshape(X_EXCL_9_train, (X_EXCL_9_train.shape[0], X_EXCL_9_train.shape[1], 1))\n",
        "model_EXCL_9 = Sequential()\n",
        "model_EXCL_9.add(LSTM(units=50,return_sequences=True,input_shape=(X_EXCL_9_train.shape[1], 1)))\n",
        "model_EXCL_9.add(Dropout(0.2))\n",
        "model_EXCL_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_9.add(Dropout(0.2))\n",
        "model_EXCL_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_9.add(Dropout(0.2))\n",
        "model_EXCL_9.add(LSTM(units=50))\n",
        "model_EXCL_9.add(Dropout(0.2))\n",
        "model_EXCL_9.add(Dense(units=1))\n",
        "model_EXCL_9.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_EXCL_9.fit(X_EXCL_9_train,y_EXCL_9_train,epochs=10,batch_size=16)\n",
        "\n",
        "# PGAS\n",
        "PGAS_9 = yf.download(\"PGAS.JK\", start=\"2022-08-10\", end=\"2023-02-10\")\n",
        "PGAS_9.insert(4,\"Return\", PGAS_9['Close'].pct_change())\n",
        "PGAS_9 = PGAS_9.dropna()\n",
        "PGAS_9_test = yf.download(\"PGAS.JK\", start=\"2023-02-09\", end=\"2023-03-10\")\n",
        "PGAS_9_test.insert(4,\"Return\", PGAS_9_test['Close'].pct_change())\n",
        "PGAS_9_test = PGAS_9_test.dropna()\n",
        "training_PGAS_9 = PGAS_9.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_PGAS_9_scaled = sc.fit_transform(training_PGAS_9)\n",
        "X_PGAS_9_train = []\n",
        "y_PGAS_9_train = []\n",
        "for i in range(days_period, len(PGAS_9)-1):\n",
        "    X_PGAS_9_train.append(training_PGAS_9_scaled[i-days_period:i, 0])\n",
        "    y_PGAS_9_train.append(training_PGAS_9_scaled[i, 0])\n",
        "X_PGAS_9_train, y_PGAS_9_train = np.array(X_PGAS_9_train), np.array(y_PGAS_9_train)\n",
        "X_PGAS_9_train = np.reshape(X_PGAS_9_train, (X_PGAS_9_train.shape[0], X_PGAS_9_train.shape[1], 1))\n",
        "model_PGAS_9 = Sequential()\n",
        "model_PGAS_9.add(LSTM(units=50,return_sequences=True,input_shape=(X_PGAS_9_train.shape[1], 1)))\n",
        "model_PGAS_9.add(Dropout(0.2))\n",
        "model_PGAS_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_9.add(Dropout(0.2))\n",
        "model_PGAS_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_9.add(Dropout(0.2))\n",
        "model_PGAS_9.add(LSTM(units=50))\n",
        "model_PGAS_9.add(Dropout(0.2))\n",
        "model_PGAS_9.add(Dense(units=1))\n",
        "model_PGAS_9.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_PGAS_9.fit(X_PGAS_9_train,y_PGAS_9_train,epochs=10,batch_size=16)\n",
        "\n",
        "# TLKM\n",
        "TLKM_9 = yf.download(\"TLKM.JK\", start=\"2022-08-10\", end=\"2023-02-10\")\n",
        "TLKM_9.insert(4,\"Return\", TLKM_9['Close'].pct_change())\n",
        "TLKM_9 = TLKM_9.dropna()\n",
        "TLKM_9_test = yf.download(\"TLKM.JK\", start=\"2023-02-09\", end=\"2023-03-10\")\n",
        "TLKM_9_test.insert(4,\"Return\", TLKM_9_test['Close'].pct_change())\n",
        "TLKM_9_test = TLKM_9_test.dropna()\n",
        "training_TLKM_9 = TLKM_9.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_TLKM_9_scaled = sc.fit_transform(training_TLKM_9)\n",
        "X_TLKM_9_train = []\n",
        "y_TLKM_9_train = []\n",
        "for i in range(days_period, len(TLKM_9)-1):\n",
        "    X_TLKM_9_train.append(training_TLKM_9_scaled[i-days_period:i, 0])\n",
        "    y_TLKM_9_train.append(training_TLKM_9_scaled[i, 0])\n",
        "X_TLKM_9_train, y_TLKM_9_train = np.array(X_TLKM_9_train), np.array(y_TLKM_9_train)\n",
        "X_TLKM_9_train = np.reshape(X_TLKM_9_train, (X_TLKM_9_train.shape[0], X_TLKM_9_train.shape[1], 1))\n",
        "model_TLKM_9 = Sequential()\n",
        "model_TLKM_9.add(LSTM(units=50,return_sequences=True,input_shape=(X_TLKM_9_train.shape[1], 1)))\n",
        "model_TLKM_9.add(Dropout(0.2))\n",
        "model_TLKM_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_9.add(Dropout(0.2))\n",
        "model_TLKM_9.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_9.add(Dropout(0.2))\n",
        "model_TLKM_9.add(LSTM(units=50))\n",
        "model_TLKM_9.add(Dropout(0.2))\n",
        "model_TLKM_9.add(Dense(units=1))\n",
        "model_TLKM_9.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_TLKM_9.fit(X_TLKM_9_train,y_TLKM_9_train,epochs=10,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5RpMIWafXM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e862b8-0532-4b3b-8985-b94412681d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        }
      ],
      "source": [
        "# ADRO\n",
        "real_ADRO_9_return = ADRO_9_test.iloc[:, 4:5].values\n",
        "real_ADRO_9_return = real_ADRO_9_return[:days_predict]\n",
        "ADRO_9_total = ADRO_9['Close'].copy(deep=True)\n",
        "inputs_ADRO_9 = ADRO_9_total[len(ADRO_9) - days_period: len(ADRO_9)].values\n",
        "inputs_ADRO_9 = inputs_ADRO_9.reshape(-1,1)\n",
        "inputs_ADRO_9 = sc.transform(inputs_ADRO_9)\n",
        "predicted_ADRO_9_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ADRO_9_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ADRO_9_test.append(inputs_ADRO_9[i:i+days_period, 0])\n",
        "  X_ADRO_9_test = np.array(X_ADRO_9_test)\n",
        "  X_ADRO_9_test = np.reshape(X_ADRO_9_test, (X_ADRO_9_test.shape[0], X_ADRO_9_test.shape[1], 1))\n",
        "  predicted_ADRO_9_return[j] = model_ADRO_9.predict(X_ADRO_9_test)\n",
        "  inputs_ADRO_9 += (predicted_ADRO_9_return[j])\n",
        "  inputs_ADRO_9 = inputs_ADRO_9.reshape(-1,1)\n",
        "\n",
        "# ASII\n",
        "real_ASII_9_return = ASII_9_test.iloc[:, 4:5].values\n",
        "real_ASII_9_return = real_ASII_9_return[:days_predict]\n",
        "ASII_9_total = ASII_9['Close'].copy(deep=True)\n",
        "inputs_ASII_9 = ASII_9_total[len(ASII_9) - days_period: len(ASII_9)].values\n",
        "inputs_ASII_9 = inputs_ASII_9.reshape(-1,1)\n",
        "inputs_ASII_9 = sc.transform(inputs_ASII_9)\n",
        "predicted_ASII_9_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ASII_9_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ASII_9_test.append(inputs_ASII_9[i:i+days_period, 0])\n",
        "  X_ASII_9_test = np.array(X_ASII_9_test)\n",
        "  X_ASII_9_test = np.reshape(X_ASII_9_test, (X_ASII_9_test.shape[0], X_ASII_9_test.shape[1], 1))\n",
        "  predicted_ASII_9_return[j] = model_ASII_9.predict(X_ASII_9_test)\n",
        "  inputs_ASII_9 += (predicted_ASII_9_return[j])\n",
        "  inputs_ASII_9 = inputs_ASII_9.reshape(-1,1)\n",
        "\n",
        "# BMRI\n",
        "real_BMRI_9_return = BMRI_9_test.iloc[:, 4:5].values\n",
        "real_BMRI_9_return = real_BMRI_9_return[:days_predict]\n",
        "BMRI_9_total = BMRI_9['Close'].copy(deep=True)\n",
        "inputs_BMRI_9 = BMRI_9_total[len(BMRI_9) - days_period: len(BMRI_9)].values\n",
        "inputs_BMRI_9 = inputs_BMRI_9.reshape(-1,1)\n",
        "inputs_BMRI_9 = sc.transform(inputs_BMRI_9)\n",
        "predicted_BMRI_9_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BMRI_9_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BMRI_9_test.append(inputs_BMRI_9[i:i+days_period, 0])\n",
        "  X_BMRI_9_test = np.array(X_BMRI_9_test)\n",
        "  X_BMRI_9_test = np.reshape(X_BMRI_9_test, (X_BMRI_9_test.shape[0], X_BMRI_9_test.shape[1], 1))\n",
        "  predicted_BMRI_9_return[j] = model_BMRI_9.predict(X_BMRI_9_test)\n",
        "  inputs_BMRI_9 += (predicted_BMRI_9_return[j])\n",
        "  inputs_BMRI_9 = inputs_BMRI_9.reshape(-1,1)\n",
        "\n",
        "# BBRI\n",
        "real_BBRI_9_return = BBRI_9_test.iloc[:, 4:5].values\n",
        "real_BBRI_9_return = real_BBRI_9_return[:days_predict]\n",
        "BBRI_9_total = BBRI_9['Close'].copy(deep=True)\n",
        "inputs_BBRI_9 = BBRI_9_total[len(BBRI_9) - days_period: len(BBRI_9)].values\n",
        "inputs_BBRI_9 = inputs_BBRI_9.reshape(-1,1)\n",
        "inputs_BBRI_9 = sc.transform(inputs_BBRI_9)\n",
        "predicted_BBRI_9_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBRI_9_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBRI_9_test.append(inputs_BBRI_9[i:i+days_period, 0])\n",
        "  X_BBRI_9_test = np.array(X_BBRI_9_test)\n",
        "  X_BBRI_9_test = np.reshape(X_BBRI_9_test, (X_BBRI_9_test.shape[0], X_BBRI_9_test.shape[1], 1))\n",
        "  predicted_BBRI_9_return[j] = model_BBRI_9.predict(X_BBRI_9_test)\n",
        "  inputs_BBRI_9 += (predicted_BBRI_9_return[j])\n",
        "  inputs_BBRI_9 = inputs_BBRI_9.reshape(-1,1)\n",
        "\n",
        "# BBTN\n",
        "real_BBTN_9_return = BBTN_9_test.iloc[:, 4:5].values\n",
        "real_BBTN_9_return = real_BBTN_9_return[:days_predict]\n",
        "BBTN_9_total = BBTN_9['Close'].copy(deep=True)\n",
        "inputs_BBTN_9 = BBTN_9_total[len(BBTN_9) - days_period: len(BBTN_9)].values\n",
        "inputs_BBTN_9 = inputs_BBTN_9.reshape(-1,1)\n",
        "inputs_BBTN_9 = sc.transform(inputs_BBTN_9)\n",
        "predicted_BBTN_9_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBTN_9_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBTN_9_test.append(inputs_BBTN_9[i:i+days_period, 0])\n",
        "  X_BBTN_9_test = np.array(X_BBTN_9_test)\n",
        "  X_BBTN_9_test = np.reshape(X_BBTN_9_test, (X_BBTN_9_test.shape[0], X_BBTN_9_test.shape[1], 1))\n",
        "  predicted_BBTN_9_return[j] = model_BBTN_9.predict(X_BBTN_9_test)\n",
        "  inputs_BBTN_9 += (predicted_BBTN_9_return[j])\n",
        "  inputs_BBTN_9 = inputs_BBTN_9.reshape(-1,1)\n",
        "\n",
        "# BUMI\n",
        "real_BUMI_9_return = BUMI_9_test.iloc[:, 4:5].values\n",
        "real_BUMI_9_return = real_BUMI_9_return[:days_predict]\n",
        "BUMI_9_total = BUMI_9['Close'].copy(deep=True)\n",
        "inputs_BUMI_9 = BUMI_9_total[len(BUMI_9) - days_period: len(BUMI_9)].values\n",
        "inputs_BUMI_9 = inputs_BUMI_9.reshape(-1,1)\n",
        "inputs_BUMI_9 = sc.transform(inputs_BUMI_9)\n",
        "predicted_BUMI_9_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BUMI_9_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BUMI_9_test.append(inputs_BUMI_9[i:i+days_period, 0])\n",
        "  X_BUMI_9_test = np.array(X_BUMI_9_test)\n",
        "  X_BUMI_9_test = np.reshape(X_BUMI_9_test, (X_BUMI_9_test.shape[0], X_BUMI_9_test.shape[1], 1))\n",
        "  predicted_BUMI_9_return[j] = model_BUMI_9.predict(X_BUMI_9_test)\n",
        "  inputs_BUMI_9 += (predicted_BUMI_9_return[j])\n",
        "  inputs_BUMI_9 = inputs_BUMI_9.reshape(-1,1)\n",
        "\n",
        "# MFIN\n",
        "real_MFIN_9_return = MFIN_9_test.iloc[:, 4:5].values\n",
        "real_MFIN_9_return = real_MFIN_9_return[:days_predict]\n",
        "MFIN_9_total = MFIN_9['Close'].copy(deep=True)\n",
        "inputs_MFIN_9 = MFIN_9_total[len(MFIN_9) - days_period: len(MFIN_9)].values\n",
        "inputs_MFIN_9 = inputs_MFIN_9.reshape(-1,1)\n",
        "inputs_MFIN_9 = sc.transform(inputs_MFIN_9)\n",
        "predicted_MFIN_9_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_MFIN_9_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_MFIN_9_test.append(inputs_MFIN_9[i:i+days_period, 0])\n",
        "  X_MFIN_9_test = np.array(X_MFIN_9_test)\n",
        "  X_MFIN_9_test = np.reshape(X_MFIN_9_test, (X_MFIN_9_test.shape[0], X_MFIN_9_test.shape[1], 1))\n",
        "  predicted_MFIN_9_return[j] = model_MFIN_9.predict(X_MFIN_9_test)\n",
        "  inputs_MFIN_9 += (predicted_MFIN_9_return[j])\n",
        "  inputs_MFIN_9 = inputs_MFIN_9.reshape(-1,1)\n",
        "\n",
        "# EXCL\n",
        "real_EXCL_9_return = EXCL_9_test.iloc[:, 4:5].values\n",
        "real_EXCL_9_return = real_EXCL_9_return[:days_predict]\n",
        "EXCL_9_total = EXCL_9['Close'].copy(deep=True)\n",
        "inputs_EXCL_9 = EXCL_9_total[len(EXCL_9) - days_period: len(EXCL_9)].values\n",
        "inputs_EXCL_9 = inputs_EXCL_9.reshape(-1,1)\n",
        "inputs_EXCL_9 = sc.transform(inputs_EXCL_9)\n",
        "predicted_EXCL_9_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_EXCL_9_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_EXCL_9_test.append(inputs_EXCL_9[i:i+days_period, 0])\n",
        "  X_EXCL_9_test = np.array(X_EXCL_9_test)\n",
        "  X_EXCL_9_test = np.reshape(X_EXCL_9_test, (X_EXCL_9_test.shape[0], X_EXCL_9_test.shape[1], 1))\n",
        "  predicted_EXCL_9_return[j] = model_EXCL_9.predict(X_EXCL_9_test)\n",
        "  inputs_EXCL_9 += (predicted_EXCL_9_return[j])\n",
        "  inputs_EXCL_9 = inputs_EXCL_9.reshape(-1,1)\n",
        "\n",
        "# PGAS\n",
        "real_PGAS_9_return = PGAS_9_test.iloc[:, 4:5].values\n",
        "real_PGAS_9_return = real_PGAS_9_return[:days_predict]\n",
        "PGAS_9_total = PGAS_9['Close'].copy(deep=True)\n",
        "inputs_PGAS_9 = PGAS_9_total[len(PGAS_9) - days_period: len(PGAS_9)].values\n",
        "inputs_PGAS_9 = inputs_PGAS_9.reshape(-1,1)\n",
        "inputs_PGAS_9 = sc.transform(inputs_PGAS_9)\n",
        "predicted_PGAS_9_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_PGAS_9_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_PGAS_9_test.append(inputs_PGAS_9[i:i+days_period, 0])\n",
        "  X_PGAS_9_test = np.array(X_PGAS_9_test)\n",
        "  X_PGAS_9_test = np.reshape(X_PGAS_9_test, (X_PGAS_9_test.shape[0], X_PGAS_9_test.shape[1], 1))\n",
        "  predicted_PGAS_9_return[j] = model_PGAS_9.predict(X_PGAS_9_test)\n",
        "  inputs_PGAS_9 += (predicted_PGAS_9_return[j])\n",
        "  inputs_PGAS_9 = inputs_PGAS_9.reshape(-1,1)\n",
        "\n",
        "# TLKM\n",
        "real_TLKM_9_return = TLKM_9_test.iloc[:, 4:5].values\n",
        "real_TLKM_9_return = real_TLKM_9_return[:days_predict]\n",
        "TLKM_9_total = TLKM_9['Close'].copy(deep=True)\n",
        "inputs_TLKM_9 = TLKM_9_total[len(TLKM_9) - days_period: len(TLKM_9)].values\n",
        "inputs_TLKM_9 = inputs_TLKM_9.reshape(-1,1)\n",
        "inputs_TLKM_9 = sc.transform(inputs_TLKM_9)\n",
        "predicted_TLKM_9_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_TLKM_9_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_TLKM_9_test.append(inputs_TLKM_9[i:i+days_period, 0])\n",
        "  X_TLKM_9_test = np.array(X_TLKM_9_test)\n",
        "  X_TLKM_9_test = np.reshape(X_TLKM_9_test, (X_TLKM_9_test.shape[0], X_TLKM_9_test.shape[1], 1))\n",
        "  predicted_TLKM_9_return[j] = model_TLKM_9.predict(X_TLKM_9_test)\n",
        "  inputs_TLKM_9 += (predicted_TLKM_9_return[j])\n",
        "  inputs_TLKM_9 = inputs_TLKM_9.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0gq9pGTfXNA"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "predicted_ADRO_9_return = np.squeeze(np.asarray(predicted_ADRO_9_return))\n",
        "predicted_ADRO_9_return = predicted_ADRO_9_return.reshape(-1,1)\n",
        "predicted_ADRO_9_return = sc.inverse_transform(predicted_ADRO_9_return)\n",
        "# ASII\n",
        "predicted_ASII_9_return = np.squeeze(np.asarray(predicted_ASII_9_return))\n",
        "predicted_ASII_9_return = predicted_ASII_9_return.reshape(-1,1)\n",
        "predicted_ASII_9_return = sc.inverse_transform(predicted_ASII_9_return)\n",
        "# BMRI\n",
        "predicted_BMRI_9_return = np.squeeze(np.asarray(predicted_BMRI_9_return))\n",
        "predicted_BMRI_9_return = predicted_BMRI_9_return.reshape(-1,1)\n",
        "predicted_BMRI_9_return = sc.inverse_transform(predicted_BMRI_9_return)\n",
        "# BBRI\n",
        "predicted_BBRI_9_return = np.squeeze(np.asarray(predicted_BBRI_9_return))\n",
        "predicted_BBRI_9_return = predicted_BBRI_9_return.reshape(-1,1)\n",
        "predicted_BBRI_9_return = sc.inverse_transform(predicted_BBRI_9_return)\n",
        "# BBTN\n",
        "predicted_BBTN_9_return = np.squeeze(np.asarray(predicted_BBTN_9_return))\n",
        "predicted_BBTN_9_return = predicted_BBTN_9_return.reshape(-1,1)\n",
        "predicted_BBTN_9_return = sc.inverse_transform(predicted_BBTN_9_return)\n",
        "# BUMI\n",
        "predicted_BUMI_9_return = np.squeeze(np.asarray(predicted_BUMI_9_return))\n",
        "predicted_BUMI_9_return = predicted_BUMI_9_return.reshape(-1,1)\n",
        "predicted_BUMI_9_return = sc.inverse_transform(predicted_BUMI_9_return)\n",
        "# MFIN\n",
        "predicted_MFIN_9_return = np.squeeze(np.asarray(predicted_MFIN_9_return))\n",
        "predicted_MFIN_9_return = predicted_MFIN_9_return.reshape(-1,1)\n",
        "predicted_MFIN_9_return = sc.inverse_transform(predicted_MFIN_9_return)\n",
        "# EXCL\n",
        "predicted_EXCL_9_return = np.squeeze(np.asarray(predicted_EXCL_9_return))\n",
        "predicted_EXCL_9_return = predicted_EXCL_9_return.reshape(-1,1)\n",
        "predicted_EXCL_9_return = sc.inverse_transform(predicted_EXCL_9_return)\n",
        "# PGAS\n",
        "predicted_PGAS_9_return = np.squeeze(np.asarray(predicted_PGAS_9_return))\n",
        "predicted_PGAS_9_return = predicted_PGAS_9_return.reshape(-1,1)\n",
        "predicted_PGAS_9_return = sc.inverse_transform(predicted_PGAS_9_return)\n",
        "# TLKM\n",
        "predicted_TLKM_9_return = np.squeeze(np.asarray(predicted_TLKM_9_return))\n",
        "predicted_TLKM_9_return = predicted_TLKM_9_return.reshape(-1,1)\n",
        "predicted_TLKM_9_return = sc.inverse_transform(predicted_TLKM_9_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUorPzdzfXNB"
      },
      "outputs": [],
      "source": [
        "predicted9 = pd.DataFrame(predicted_ADRO_9_return)\n",
        "predicted9.rename(columns={0:'ADRO'}, inplace=True)\n",
        "predicted9.insert(1,\"ASII\", predicted_ASII_9_return)\n",
        "predicted9.insert(2,\"BBRI\", predicted_BBRI_9_return)\n",
        "predicted9.insert(3,\"BBTN\", predicted_BBTN_9_return)\n",
        "predicted9.insert(4,\"BMRI\", predicted_BMRI_9_return)\n",
        "predicted9.insert(5,\"BUMI\", predicted_BUMI_9_return)\n",
        "predicted9.insert(6,\"EXCL\", predicted_EXCL_9_return)\n",
        "predicted9.insert(7,\"MFIN\", predicted_MFIN_9_return)\n",
        "predicted9.insert(8,\"PGAS\", predicted_PGAS_9_return)\n",
        "predicted9.insert(9,\"TLKM\", predicted_TLKM_9_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POZEc_nhR5PX",
        "outputId": "a9606872-2c75-4fa3-9eb1-608785d93330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADRO      ASII      BBRI      BBTN      BMRI      BUMI      EXCL  \\\n",
              "0 -0.000794  0.004492 -0.007737 -0.001726  0.001002 -0.026757 -0.054850   \n",
              "1 -0.001853  0.003526 -0.008409 -0.001999  0.000119 -0.026562 -0.054876   \n",
              "2 -0.003086  0.002396 -0.009216 -0.002399 -0.000957 -0.026377 -0.054904   \n",
              "3 -0.004515  0.001077 -0.010179 -0.002963 -0.002258 -0.026220 -0.054932   \n",
              "4 -0.006162 -0.000457 -0.011322 -0.003725 -0.003816 -0.026110 -0.054962   \n",
              "5 -0.008051 -0.002236 -0.012667 -0.004730 -0.005664 -0.026074 -0.054993   \n",
              "6 -0.010201 -0.004290 -0.014240 -0.006028 -0.007833 -0.026147 -0.055024   \n",
              "7 -0.012631 -0.006649 -0.016064 -0.007668 -0.010349 -0.026371 -0.055057   \n",
              "8 -0.015355 -0.009343 -0.018160 -0.009705 -0.013231 -0.026796 -0.055092   \n",
              "9 -0.018381 -0.012400 -0.020545 -0.012195 -0.016486 -0.027481 -0.055131   \n",
              "\n",
              "       MFIN      PGAS      TLKM  \n",
              "0 -0.061712 -0.009631  0.001977  \n",
              "1 -0.061137 -0.010525  0.000818  \n",
              "2 -0.060533 -0.011576 -0.000531  \n",
              "3 -0.059903 -0.012803 -0.002097  \n",
              "4 -0.059247 -0.014225 -0.003908  \n",
              "5 -0.058569 -0.015860 -0.005992  \n",
              "6 -0.057875 -0.017725 -0.008376  \n",
              "7 -0.057174 -0.019833 -0.011081  \n",
              "8 -0.056478 -0.022193 -0.014125  \n",
              "9 -0.055803 -0.024805 -0.017511  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bc3e75b-2ec4-47be-9e01-3422af8cb9f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADRO</th>\n",
              "      <th>ASII</th>\n",
              "      <th>BBRI</th>\n",
              "      <th>BBTN</th>\n",
              "      <th>BMRI</th>\n",
              "      <th>BUMI</th>\n",
              "      <th>EXCL</th>\n",
              "      <th>MFIN</th>\n",
              "      <th>PGAS</th>\n",
              "      <th>TLKM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.000794</td>\n",
              "      <td>0.004492</td>\n",
              "      <td>-0.007737</td>\n",
              "      <td>-0.001726</td>\n",
              "      <td>0.001002</td>\n",
              "      <td>-0.026757</td>\n",
              "      <td>-0.054850</td>\n",
              "      <td>-0.061712</td>\n",
              "      <td>-0.009631</td>\n",
              "      <td>0.001977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001853</td>\n",
              "      <td>0.003526</td>\n",
              "      <td>-0.008409</td>\n",
              "      <td>-0.001999</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>-0.026562</td>\n",
              "      <td>-0.054876</td>\n",
              "      <td>-0.061137</td>\n",
              "      <td>-0.010525</td>\n",
              "      <td>0.000818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.003086</td>\n",
              "      <td>0.002396</td>\n",
              "      <td>-0.009216</td>\n",
              "      <td>-0.002399</td>\n",
              "      <td>-0.000957</td>\n",
              "      <td>-0.026377</td>\n",
              "      <td>-0.054904</td>\n",
              "      <td>-0.060533</td>\n",
              "      <td>-0.011576</td>\n",
              "      <td>-0.000531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.004515</td>\n",
              "      <td>0.001077</td>\n",
              "      <td>-0.010179</td>\n",
              "      <td>-0.002963</td>\n",
              "      <td>-0.002258</td>\n",
              "      <td>-0.026220</td>\n",
              "      <td>-0.054932</td>\n",
              "      <td>-0.059903</td>\n",
              "      <td>-0.012803</td>\n",
              "      <td>-0.002097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.006162</td>\n",
              "      <td>-0.000457</td>\n",
              "      <td>-0.011322</td>\n",
              "      <td>-0.003725</td>\n",
              "      <td>-0.003816</td>\n",
              "      <td>-0.026110</td>\n",
              "      <td>-0.054962</td>\n",
              "      <td>-0.059247</td>\n",
              "      <td>-0.014225</td>\n",
              "      <td>-0.003908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.008051</td>\n",
              "      <td>-0.002236</td>\n",
              "      <td>-0.012667</td>\n",
              "      <td>-0.004730</td>\n",
              "      <td>-0.005664</td>\n",
              "      <td>-0.026074</td>\n",
              "      <td>-0.054993</td>\n",
              "      <td>-0.058569</td>\n",
              "      <td>-0.015860</td>\n",
              "      <td>-0.005992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.010201</td>\n",
              "      <td>-0.004290</td>\n",
              "      <td>-0.014240</td>\n",
              "      <td>-0.006028</td>\n",
              "      <td>-0.007833</td>\n",
              "      <td>-0.026147</td>\n",
              "      <td>-0.055024</td>\n",
              "      <td>-0.057875</td>\n",
              "      <td>-0.017725</td>\n",
              "      <td>-0.008376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.012631</td>\n",
              "      <td>-0.006649</td>\n",
              "      <td>-0.016064</td>\n",
              "      <td>-0.007668</td>\n",
              "      <td>-0.010349</td>\n",
              "      <td>-0.026371</td>\n",
              "      <td>-0.055057</td>\n",
              "      <td>-0.057174</td>\n",
              "      <td>-0.019833</td>\n",
              "      <td>-0.011081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.015355</td>\n",
              "      <td>-0.009343</td>\n",
              "      <td>-0.018160</td>\n",
              "      <td>-0.009705</td>\n",
              "      <td>-0.013231</td>\n",
              "      <td>-0.026796</td>\n",
              "      <td>-0.055092</td>\n",
              "      <td>-0.056478</td>\n",
              "      <td>-0.022193</td>\n",
              "      <td>-0.014125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.018381</td>\n",
              "      <td>-0.012400</td>\n",
              "      <td>-0.020545</td>\n",
              "      <td>-0.012195</td>\n",
              "      <td>-0.016486</td>\n",
              "      <td>-0.027481</td>\n",
              "      <td>-0.055131</td>\n",
              "      <td>-0.055803</td>\n",
              "      <td>-0.024805</td>\n",
              "      <td>-0.017511</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bc3e75b-2ec4-47be-9e01-3422af8cb9f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7bc3e75b-2ec4-47be-9e01-3422af8cb9f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7bc3e75b-2ec4-47be-9e01-3422af8cb9f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw0DVZbAciU-"
      },
      "source": [
        "## Data Preparation 10\n",
        "1st of January 2018 - 9th of March 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUj-8Pk5oLse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ca94a0-9c16-442d-a2bb-340aeec5a64f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 10s 60ms/step - loss: 0.1129\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0347\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0390\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0361\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0370\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0313\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0351\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0328\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0322\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0342\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 9s 39ms/step - loss: 0.1236\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0310\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0292\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0241\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0252\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0237\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0242\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0239\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0243\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0246\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 14s 68ms/step - loss: 0.1582\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.0424\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.0494\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0374\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0347\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0381\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0314\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0310\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0344\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0322\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 9s 41ms/step - loss: 0.1681\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0695\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0476\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0500\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0456\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0434\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0470\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0428\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0572\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0496\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 9s 43ms/step - loss: 0.1860\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0529\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0282\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0217\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0189\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0155\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0160\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0162\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0144\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0174\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 9s 42ms/step - loss: 0.0749\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0305\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0289\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0278\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0268\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0253\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0256\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0279\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0276\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.0258\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 9s 41ms/step - loss: 0.0831\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0206\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0198\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0183\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0146\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0164\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0168\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 0.0152\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.0163\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 0.0179\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 10s 41ms/step - loss: 0.0111\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0078\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0078\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0077\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0081\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0072\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0073\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0078\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0073\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0076\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 9s 40ms/step - loss: 0.0852\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0278\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0235\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0230\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0202\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0169\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0177\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0166\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0170\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0172\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 9s 42ms/step - loss: 0.3041\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0552\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0392\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0351\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0316\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0300\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0372\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.0277\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.0397\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.0269\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efb0889cc10>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Period parameters\n",
        "days_period = 20\n",
        "days_predict = 10\n",
        "\n",
        "# ADRO\n",
        "ADRO_10 = yf.download(\"ADRO.JK\", start=\"2022-09-01\", end=\"2023-03-10\")\n",
        "ADRO_10.insert(4,\"Return\", ADRO_10['Close'].pct_change())\n",
        "ADRO_10 = ADRO_10.dropna()\n",
        "ADRO_10_test = yf.download(\"ADRO.JK\", start=\"2023-03-09\", end=\"2023-04-10\")\n",
        "ADRO_10_test.insert(4,\"Return\", ADRO_10_test['Close'].pct_change())\n",
        "ADRO_10_test = ADRO_10_test.dropna()\n",
        "training_ADRO_10 = ADRO_10.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ADRO_10_scaled = sc.fit_transform(training_ADRO_10)\n",
        "X_ADRO_10_train = []\n",
        "y_ADRO_10_train = []\n",
        "for i in range(days_period, len(ADRO_10)-1):\n",
        "    X_ADRO_10_train.append(training_ADRO_10_scaled[i-days_period:i, 0])\n",
        "    y_ADRO_10_train.append(training_ADRO_10_scaled[i, 0])\n",
        "X_ADRO_10_train, y_ADRO_10_train = np.array(X_ADRO_10_train), np.array(y_ADRO_10_train)\n",
        "X_ADRO_10_train = np.reshape(X_ADRO_10_train, (X_ADRO_10_train.shape[0], X_ADRO_10_train.shape[1], 1))\n",
        "model_ADRO_10 = Sequential()\n",
        "model_ADRO_10.add(LSTM(units=50,return_sequences=True,input_shape=(X_ADRO_10_train.shape[1], 1)))\n",
        "model_ADRO_10.add(Dropout(0.2))\n",
        "model_ADRO_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_10.add(Dropout(0.2))\n",
        "model_ADRO_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_10.add(Dropout(0.2))\n",
        "model_ADRO_10.add(LSTM(units=50))\n",
        "model_ADRO_10.add(Dropout(0.2))\n",
        "model_ADRO_10.add(Dense(units=1))\n",
        "model_ADRO_10.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ADRO_10.fit(X_ADRO_10_train,y_ADRO_10_train,epochs=10,batch_size=16)\n",
        "\n",
        "# ASII\n",
        "ASII_10 = yf.download(\"ASII.JK\", start=\"2022-09-01\", end=\"2023-03-10\")\n",
        "ASII_10.insert(4,\"Return\", ASII_10['Close'].pct_change())\n",
        "ASII_10 = ASII_10.dropna()\n",
        "ASII_10_test = yf.download(\"ASII.JK\", start=\"2023-03-09\", end=\"2023-04-10\")\n",
        "ASII_10_test.insert(4,\"Return\", ASII_10_test['Close'].pct_change())\n",
        "ASII_10_test = ASII_10_test.dropna()\n",
        "training_ASII_10 = ASII_10.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ASII_10_scaled = sc.fit_transform(training_ASII_10)\n",
        "X_ASII_10_train = []\n",
        "y_ASII_10_train = []\n",
        "for i in range(days_period, len(ASII_10)-1):\n",
        "    X_ASII_10_train.append(training_ASII_10_scaled[i-days_period:i, 0])\n",
        "    y_ASII_10_train.append(training_ASII_10_scaled[i, 0])\n",
        "X_ASII_10_train, y_ASII_10_train = np.array(X_ASII_10_train), np.array(y_ASII_10_train)\n",
        "X_ASII_10_train = np.reshape(X_ASII_10_train, (X_ASII_10_train.shape[0], X_ASII_10_train.shape[1], 1))\n",
        "model_ASII_10 = Sequential()\n",
        "model_ASII_10.add(LSTM(units=50,return_sequences=True,input_shape=(X_ASII_10_train.shape[1], 1)))\n",
        "model_ASII_10.add(Dropout(0.2))\n",
        "model_ASII_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_10.add(Dropout(0.2))\n",
        "model_ASII_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_10.add(Dropout(0.2))\n",
        "model_ASII_10.add(LSTM(units=50))\n",
        "model_ASII_10.add(Dropout(0.2))\n",
        "model_ASII_10.add(Dense(units=1))\n",
        "model_ASII_10.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ASII_10.fit(X_ASII_10_train,y_ASII_10_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BMRI\n",
        "BMRI_10 = yf.download(\"BMRI.JK\", start=\"2022-09-01\", end=\"2023-03-10\")\n",
        "BMRI_10.insert(4,\"Return\", BMRI_10['Close'].pct_change())\n",
        "BMRI_10 = BMRI_10.dropna()\n",
        "BMRI_10_test = yf.download(\"BMRI.JK\", start=\"2023-03-09\", end=\"2023-04-10\")\n",
        "BMRI_10_test.insert(4,\"Return\", BMRI_10_test['Close'].pct_change())\n",
        "BMRI_10_test = BMRI_10_test.dropna()\n",
        "training_BMRI_10 = BMRI_10.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BMRI_10_scaled = sc.fit_transform(training_BMRI_10)\n",
        "X_BMRI_10_train = []\n",
        "y_BMRI_10_train = []\n",
        "for i in range(days_period, len(BMRI_10)-1):\n",
        "    X_BMRI_10_train.append(training_BMRI_10_scaled[i-days_period:i, 0])\n",
        "    y_BMRI_10_train.append(training_BMRI_10_scaled[i, 0])\n",
        "X_BMRI_10_train, y_BMRI_10_train = np.array(X_BMRI_10_train), np.array(y_BMRI_10_train)\n",
        "X_BMRI_10_train = np.reshape(X_BMRI_10_train, (X_BMRI_10_train.shape[0], X_BMRI_10_train.shape[1], 1))\n",
        "model_BMRI_10 = Sequential()\n",
        "model_BMRI_10.add(LSTM(units=50,return_sequences=True,input_shape=(X_BMRI_10_train.shape[1], 1)))\n",
        "model_BMRI_10.add(Dropout(0.2))\n",
        "model_BMRI_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_10.add(Dropout(0.2))\n",
        "model_BMRI_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_10.add(Dropout(0.2))\n",
        "model_BMRI_10.add(LSTM(units=50))\n",
        "model_BMRI_10.add(Dropout(0.2))\n",
        "model_BMRI_10.add(Dense(units=1))\n",
        "model_BMRI_10.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BMRI_10.fit(X_BMRI_10_train,y_BMRI_10_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBRI\n",
        "BBRI_10 = yf.download(\"BBRI.JK\", start=\"2022-09-01\", end=\"2023-03-10\")\n",
        "BBRI_10.insert(4,\"Return\", BBRI_10['Close'].pct_change())\n",
        "BBRI_10 = BBRI_10.dropna()\n",
        "BBRI_10_test = yf.download(\"BBRI.JK\", start=\"2023-03-09\", end=\"2023-04-10\")\n",
        "BBRI_10_test.insert(4,\"Return\", BBRI_10_test['Close'].pct_change())\n",
        "BBRI_10_test = BBRI_10_test.dropna()\n",
        "training_BBRI_10 = BBRI_10.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBRI_10_scaled = sc.fit_transform(training_BBRI_10)\n",
        "X_BBRI_10_train = []\n",
        "y_BBRI_10_train = []\n",
        "for i in range(days_period, len(BBRI_10)-1):\n",
        "    X_BBRI_10_train.append(training_BBRI_10_scaled[i-days_period:i, 0])\n",
        "    y_BBRI_10_train.append(training_BBRI_10_scaled[i, 0])\n",
        "X_BBRI_10_train, y_BBRI_10_train = np.array(X_BBRI_10_train), np.array(y_BBRI_10_train)\n",
        "X_BBRI_10_train = np.reshape(X_BBRI_10_train, (X_BBRI_10_train.shape[0], X_BBRI_10_train.shape[1], 1))\n",
        "model_BBRI_10 = Sequential()\n",
        "model_BBRI_10.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBRI_10_train.shape[1], 1)))\n",
        "model_BBRI_10.add(Dropout(0.2))\n",
        "model_BBRI_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_10.add(Dropout(0.2))\n",
        "model_BBRI_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_10.add(Dropout(0.2))\n",
        "model_BBRI_10.add(LSTM(units=50))\n",
        "model_BBRI_10.add(Dropout(0.2))\n",
        "model_BBRI_10.add(Dense(units=1))\n",
        "model_BBRI_10.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBRI_10.fit(X_BBRI_10_train,y_BBRI_10_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBTN\n",
        "BBTN_10 = yf.download(\"BBTN.JK\", start=\"2022-09-01\", end=\"2023-03-10\")\n",
        "BBTN_10.insert(4,\"Return\", BBTN_10['Close'].pct_change())\n",
        "BBTN_10 = BBTN_10.dropna()\n",
        "BBTN_10_test = yf.download(\"BBTN.JK\", start=\"2023-03-09\", end=\"2023-04-10\")\n",
        "BBTN_10_test.insert(4,\"Return\", BBTN_10_test['Close'].pct_change())\n",
        "BBTN_10_test = BBTN_10_test.dropna()\n",
        "training_BBTN_10 = BBTN_10.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBTN_10_scaled = sc.fit_transform(training_BBTN_10)\n",
        "X_BBTN_10_train = []\n",
        "y_BBTN_10_train = []\n",
        "for i in range(days_period, len(BBTN_10)-1):\n",
        "    X_BBTN_10_train.append(training_BBTN_10_scaled[i-days_period:i, 0])\n",
        "    y_BBTN_10_train.append(training_BBTN_10_scaled[i, 0])\n",
        "X_BBTN_10_train, y_BBTN_10_train = np.array(X_BBTN_10_train), np.array(y_BBTN_10_train)\n",
        "X_BBTN_10_train = np.reshape(X_BBTN_10_train, (X_BBTN_10_train.shape[0], X_BBTN_10_train.shape[1], 1))\n",
        "model_BBTN_10 = Sequential()\n",
        "model_BBTN_10.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBTN_10_train.shape[1], 1)))\n",
        "model_BBTN_10.add(Dropout(0.2))\n",
        "model_BBTN_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_10.add(Dropout(0.2))\n",
        "model_BBTN_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_10.add(Dropout(0.2))\n",
        "model_BBTN_10.add(LSTM(units=50))\n",
        "model_BBTN_10.add(Dropout(0.2))\n",
        "model_BBTN_10.add(Dense(units=1))\n",
        "model_BBTN_10.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBTN_10.fit(X_BBTN_10_train,y_BBTN_10_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BUMI\n",
        "BUMI_10 = yf.download(\"BUMI.JK\", start=\"2022-09-01\", end=\"2023-03-10\")\n",
        "BUMI_10.insert(4,\"Return\", BUMI_10['Close'].pct_change())\n",
        "BUMI_10 = BUMI_10.dropna()\n",
        "BUMI_10_test = yf.download(\"BUMI.JK\", start=\"2023-03-09\", end=\"2023-04-10\")\n",
        "BUMI_10_test.insert(4,\"Return\", BUMI_10_test['Close'].pct_change())\n",
        "BUMI_10_test = BUMI_10_test.dropna()\n",
        "training_BUMI_10 = BUMI_10.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BUMI_10_scaled = sc.fit_transform(training_BUMI_10)\n",
        "X_BUMI_10_train = []\n",
        "y_BUMI_10_train = []\n",
        "for i in range(days_period, len(BUMI_10)-1):\n",
        "    X_BUMI_10_train.append(training_BUMI_10_scaled[i-days_period:i, 0])\n",
        "    y_BUMI_10_train.append(training_BUMI_10_scaled[i, 0])\n",
        "X_BUMI_10_train, y_BUMI_10_train = np.array(X_BUMI_10_train), np.array(y_BUMI_10_train)\n",
        "X_BUMI_10_train = np.reshape(X_BUMI_10_train, (X_BUMI_10_train.shape[0], X_BUMI_10_train.shape[1], 1))\n",
        "model_BUMI_10 = Sequential()\n",
        "model_BUMI_10.add(LSTM(units=50,return_sequences=True,input_shape=(X_BUMI_10_train.shape[1], 1)))\n",
        "model_BUMI_10.add(Dropout(0.2))\n",
        "model_BUMI_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_10.add(Dropout(0.2))\n",
        "model_BUMI_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_10.add(Dropout(0.2))\n",
        "model_BUMI_10.add(LSTM(units=50))\n",
        "model_BUMI_10.add(Dropout(0.2))\n",
        "model_BUMI_10.add(Dense(units=1))\n",
        "model_BUMI_10.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BUMI_10.fit(X_BUMI_10_train,y_BUMI_10_train,epochs=10,batch_size=16)\n",
        "\n",
        "# MFIN\n",
        "MFIN_10 = yf.download(\"MFIN.JK\", start=\"2022-09-01\", end=\"2023-03-10\")\n",
        "MFIN_10.insert(4,\"Return\", MFIN_10['Close'].pct_change())\n",
        "MFIN_10 = MFIN_10.dropna()\n",
        "MFIN_10_test = yf.download(\"MFIN.JK\", start=\"2023-03-09\", end=\"2023-04-10\")\n",
        "MFIN_10_test.insert(4,\"Return\", MFIN_10_test['Close'].pct_change())\n",
        "MFIN_10_test = MFIN_10_test.dropna()\n",
        "training_MFIN_10 = MFIN_10.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_MFIN_10_scaled = sc.fit_transform(training_MFIN_10)\n",
        "X_MFIN_10_train = []\n",
        "y_MFIN_10_train = []\n",
        "for i in range(days_period, len(MFIN_10)-1):\n",
        "    X_MFIN_10_train.append(training_MFIN_10_scaled[i-days_period:i, 0])\n",
        "    y_MFIN_10_train.append(training_MFIN_10_scaled[i, 0])\n",
        "X_MFIN_10_train, y_MFIN_10_train = np.array(X_MFIN_10_train), np.array(y_MFIN_10_train)\n",
        "X_MFIN_10_train = np.reshape(X_MFIN_10_train, (X_MFIN_10_train.shape[0], X_MFIN_10_train.shape[1], 1))\n",
        "model_MFIN_10 = Sequential()\n",
        "model_MFIN_10.add(LSTM(units=50,return_sequences=True,input_shape=(X_MFIN_10_train.shape[1], 1)))\n",
        "model_MFIN_10.add(Dropout(0.2))\n",
        "model_MFIN_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_10.add(Dropout(0.2))\n",
        "model_MFIN_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_10.add(Dropout(0.2))\n",
        "model_MFIN_10.add(LSTM(units=50))\n",
        "model_MFIN_10.add(Dropout(0.2))\n",
        "model_MFIN_10.add(Dense(units=1))\n",
        "model_MFIN_10.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_MFIN_10.fit(X_MFIN_10_train,y_MFIN_10_train,epochs=10,batch_size=16)\n",
        "\n",
        "# EXCL\n",
        "EXCL_10 = yf.download(\"EXCL.JK\", start=\"2022-09-01\", end=\"2023-03-10\")\n",
        "EXCL_10.insert(4,\"Return\", EXCL_10['Close'].pct_change())\n",
        "EXCL_10 = EXCL_10.dropna()\n",
        "EXCL_10_test = yf.download(\"EXCL.JK\", start=\"2023-03-09\", end=\"2023-04-10\")\n",
        "EXCL_10_test.insert(4,\"Return\", EXCL_10_test['Close'].pct_change())\n",
        "EXCL_10_test = EXCL_10_test.dropna()\n",
        "training_EXCL_10 = EXCL_10.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_EXCL_10_scaled = sc.fit_transform(training_EXCL_10)\n",
        "X_EXCL_10_train = []\n",
        "y_EXCL_10_train = []\n",
        "for i in range(days_period, len(EXCL_10)-1):\n",
        "    X_EXCL_10_train.append(training_EXCL_10_scaled[i-days_period:i, 0])\n",
        "    y_EXCL_10_train.append(training_EXCL_10_scaled[i, 0])\n",
        "X_EXCL_10_train, y_EXCL_10_train = np.array(X_EXCL_10_train), np.array(y_EXCL_10_train)\n",
        "X_EXCL_10_train = np.reshape(X_EXCL_10_train, (X_EXCL_10_train.shape[0], X_EXCL_10_train.shape[1], 1))\n",
        "model_EXCL_10 = Sequential()\n",
        "model_EXCL_10.add(LSTM(units=50,return_sequences=True,input_shape=(X_EXCL_10_train.shape[1], 1)))\n",
        "model_EXCL_10.add(Dropout(0.2))\n",
        "model_EXCL_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_10.add(Dropout(0.2))\n",
        "model_EXCL_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_10.add(Dropout(0.2))\n",
        "model_EXCL_10.add(LSTM(units=50))\n",
        "model_EXCL_10.add(Dropout(0.2))\n",
        "model_EXCL_10.add(Dense(units=1))\n",
        "model_EXCL_10.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_EXCL_10.fit(X_EXCL_10_train,y_EXCL_10_train,epochs=10,batch_size=16)\n",
        "\n",
        "# PGAS\n",
        "PGAS_10 = yf.download(\"PGAS.JK\", start=\"2022-09-01\", end=\"2023-03-10\")\n",
        "PGAS_10.insert(4,\"Return\", PGAS_10['Close'].pct_change())\n",
        "PGAS_10 = PGAS_10.dropna()\n",
        "PGAS_10_test = yf.download(\"PGAS.JK\", start=\"2023-03-09\", end=\"2023-04-10\")\n",
        "PGAS_10_test.insert(4,\"Return\", PGAS_10_test['Close'].pct_change())\n",
        "PGAS_10_test = PGAS_10_test.dropna()\n",
        "training_PGAS_10 = PGAS_10.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_PGAS_10_scaled = sc.fit_transform(training_PGAS_10)\n",
        "X_PGAS_10_train = []\n",
        "y_PGAS_10_train = []\n",
        "for i in range(days_period, len(PGAS_10)-1):\n",
        "    X_PGAS_10_train.append(training_PGAS_10_scaled[i-days_period:i, 0])\n",
        "    y_PGAS_10_train.append(training_PGAS_10_scaled[i, 0])\n",
        "X_PGAS_10_train, y_PGAS_10_train = np.array(X_PGAS_10_train), np.array(y_PGAS_10_train)\n",
        "X_PGAS_10_train = np.reshape(X_PGAS_10_train, (X_PGAS_10_train.shape[0], X_PGAS_10_train.shape[1], 1))\n",
        "model_PGAS_10 = Sequential()\n",
        "model_PGAS_10.add(LSTM(units=50,return_sequences=True,input_shape=(X_PGAS_10_train.shape[1], 1)))\n",
        "model_PGAS_10.add(Dropout(0.2))\n",
        "model_PGAS_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_10.add(Dropout(0.2))\n",
        "model_PGAS_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_10.add(Dropout(0.2))\n",
        "model_PGAS_10.add(LSTM(units=50))\n",
        "model_PGAS_10.add(Dropout(0.2))\n",
        "model_PGAS_10.add(Dense(units=1))\n",
        "model_PGAS_10.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_PGAS_10.fit(X_PGAS_10_train,y_PGAS_10_train,epochs=10,batch_size=16)\n",
        "\n",
        "# TLKM\n",
        "TLKM_10 = yf.download(\"TLKM.JK\", start=\"2022-09-01\", end=\"2023-03-10\")\n",
        "TLKM_10.insert(4,\"Return\", TLKM_10['Close'].pct_change())\n",
        "TLKM_10 = TLKM_10.dropna()\n",
        "TLKM_10_test = yf.download(\"TLKM.JK\", start=\"2023-03-09\", end=\"2023-04-10\")\n",
        "TLKM_10_test.insert(4,\"Return\", TLKM_10_test['Close'].pct_change())\n",
        "TLKM_10_test = TLKM_10_test.dropna()\n",
        "training_TLKM_10 = TLKM_10.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_TLKM_10_scaled = sc.fit_transform(training_TLKM_10)\n",
        "X_TLKM_10_train = []\n",
        "y_TLKM_10_train = []\n",
        "for i in range(days_period, len(TLKM_10)-1):\n",
        "    X_TLKM_10_train.append(training_TLKM_10_scaled[i-days_period:i, 0])\n",
        "    y_TLKM_10_train.append(training_TLKM_10_scaled[i, 0])\n",
        "X_TLKM_10_train, y_TLKM_10_train = np.array(X_TLKM_10_train), np.array(y_TLKM_10_train)\n",
        "X_TLKM_10_train = np.reshape(X_TLKM_10_train, (X_TLKM_10_train.shape[0], X_TLKM_10_train.shape[1], 1))\n",
        "model_TLKM_10 = Sequential()\n",
        "model_TLKM_10.add(LSTM(units=50,return_sequences=True,input_shape=(X_TLKM_10_train.shape[1], 1)))\n",
        "model_TLKM_10.add(Dropout(0.2))\n",
        "model_TLKM_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_10.add(Dropout(0.2))\n",
        "model_TLKM_10.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_10.add(Dropout(0.2))\n",
        "model_TLKM_10.add(LSTM(units=50))\n",
        "model_TLKM_10.add(Dropout(0.2))\n",
        "model_TLKM_10.add(Dense(units=1))\n",
        "model_TLKM_10.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_TLKM_10.fit(X_TLKM_10_train,y_TLKM_10_train,epochs=10,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqcc1As7oLsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6693bf-1386-4ecd-b69a-ca4d654a58dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        }
      ],
      "source": [
        "# ADRO\n",
        "real_ADRO_10_return = ADRO_10_test.iloc[:, 4:5].values\n",
        "real_ADRO_10_return = real_ADRO_10_return[:days_predict]\n",
        "ADRO_10_total = ADRO_10['Close'].copy(deep=True)\n",
        "inputs_ADRO_10 = ADRO_10_total[len(ADRO_10) - days_period: len(ADRO_10)].values\n",
        "inputs_ADRO_10 = inputs_ADRO_10.reshape(-1,1)\n",
        "inputs_ADRO_10 = sc.transform(inputs_ADRO_10)\n",
        "predicted_ADRO_10_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ADRO_10_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ADRO_10_test.append(inputs_ADRO_10[i:i+days_period, 0])\n",
        "  X_ADRO_10_test = np.array(X_ADRO_10_test)\n",
        "  X_ADRO_10_test = np.reshape(X_ADRO_10_test, (X_ADRO_10_test.shape[0], X_ADRO_10_test.shape[1], 1))\n",
        "  predicted_ADRO_10_return[j] = model_ADRO_10.predict(X_ADRO_10_test)\n",
        "  inputs_ADRO_10 += (predicted_ADRO_10_return[j])\n",
        "  inputs_ADRO_10 = inputs_ADRO_10.reshape(-1,1)\n",
        "\n",
        "# ASII\n",
        "real_ASII_10_return = ASII_10_test.iloc[:, 4:5].values\n",
        "real_ASII_10_return = real_ASII_10_return[:days_predict]\n",
        "ASII_10_total = ASII_10['Close'].copy(deep=True)\n",
        "inputs_ASII_10 = ASII_10_total[len(ASII_10) - days_period: len(ASII_10)].values\n",
        "inputs_ASII_10 = inputs_ASII_10.reshape(-1,1)\n",
        "inputs_ASII_10 = sc.transform(inputs_ASII_10)\n",
        "predicted_ASII_10_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ASII_10_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ASII_10_test.append(inputs_ASII_10[i:i+days_period, 0])\n",
        "  X_ASII_10_test = np.array(X_ASII_10_test)\n",
        "  X_ASII_10_test = np.reshape(X_ASII_10_test, (X_ASII_10_test.shape[0], X_ASII_10_test.shape[1], 1))\n",
        "  predicted_ASII_10_return[j] = model_ASII_10.predict(X_ASII_10_test)\n",
        "  inputs_ASII_10 += (predicted_ASII_10_return[j])\n",
        "  inputs_ASII_10 = inputs_ASII_10.reshape(-1,1)\n",
        "\n",
        "# BMRI\n",
        "real_BMRI_10_return = BMRI_10_test.iloc[:, 4:5].values\n",
        "real_BMRI_10_return = real_BMRI_10_return[:days_predict]\n",
        "BMRI_10_total = BMRI_10['Close'].copy(deep=True)\n",
        "inputs_BMRI_10 = BMRI_10_total[len(BMRI_10) - days_period: len(BMRI_10)].values\n",
        "inputs_BMRI_10 = inputs_BMRI_10.reshape(-1,1)\n",
        "inputs_BMRI_10 = sc.transform(inputs_BMRI_10)\n",
        "predicted_BMRI_10_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BMRI_10_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BMRI_10_test.append(inputs_BMRI_10[i:i+days_period, 0])\n",
        "  X_BMRI_10_test = np.array(X_BMRI_10_test)\n",
        "  X_BMRI_10_test = np.reshape(X_BMRI_10_test, (X_BMRI_10_test.shape[0], X_BMRI_10_test.shape[1], 1))\n",
        "  predicted_BMRI_10_return[j] = model_BMRI_10.predict(X_BMRI_10_test)\n",
        "  inputs_BMRI_10 += (predicted_BMRI_10_return[j])\n",
        "  inputs_BMRI_10 = inputs_BMRI_10.reshape(-1,1)\n",
        "\n",
        "# BBRI\n",
        "real_BBRI_10_return = BBRI_10_test.iloc[:, 4:5].values\n",
        "real_BBRI_10_return = real_BBRI_10_return[:days_predict]\n",
        "BBRI_10_total = BBRI_10['Close'].copy(deep=True)\n",
        "inputs_BBRI_10 = BBRI_10_total[len(BBRI_10) - days_period: len(BBRI_10)].values\n",
        "inputs_BBRI_10 = inputs_BBRI_10.reshape(-1,1)\n",
        "inputs_BBRI_10 = sc.transform(inputs_BBRI_10)\n",
        "predicted_BBRI_10_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBRI_10_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBRI_10_test.append(inputs_BBRI_10[i:i+days_period, 0])\n",
        "  X_BBRI_10_test = np.array(X_BBRI_10_test)\n",
        "  X_BBRI_10_test = np.reshape(X_BBRI_10_test, (X_BBRI_10_test.shape[0], X_BBRI_10_test.shape[1], 1))\n",
        "  predicted_BBRI_10_return[j] = model_BBRI_10.predict(X_BBRI_10_test)\n",
        "  inputs_BBRI_10 += (predicted_BBRI_10_return[j])\n",
        "  inputs_BBRI_10 = inputs_BBRI_10.reshape(-1,1)\n",
        "\n",
        "# BBTN\n",
        "real_BBTN_10_return = BBTN_10_test.iloc[:, 4:5].values\n",
        "real_BBTN_10_return = real_BBTN_10_return[:days_predict]\n",
        "BBTN_10_total = BBTN_10['Close'].copy(deep=True)\n",
        "inputs_BBTN_10 = BBTN_10_total[len(BBTN_10) - days_period: len(BBTN_10)].values\n",
        "inputs_BBTN_10 = inputs_BBTN_10.reshape(-1,1)\n",
        "inputs_BBTN_10 = sc.transform(inputs_BBTN_10)\n",
        "predicted_BBTN_10_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBTN_10_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBTN_10_test.append(inputs_BBTN_10[i:i+days_period, 0])\n",
        "  X_BBTN_10_test = np.array(X_BBTN_10_test)\n",
        "  X_BBTN_10_test = np.reshape(X_BBTN_10_test, (X_BBTN_10_test.shape[0], X_BBTN_10_test.shape[1], 1))\n",
        "  predicted_BBTN_10_return[j] = model_BBTN_10.predict(X_BBTN_10_test)\n",
        "  inputs_BBTN_10 += (predicted_BBTN_10_return[j])\n",
        "  inputs_BBTN_10 = inputs_BBTN_10.reshape(-1,1)\n",
        "\n",
        "# BUMI\n",
        "real_BUMI_10_return = BUMI_10_test.iloc[:, 4:5].values\n",
        "real_BUMI_10_return = real_BUMI_10_return[:days_predict]\n",
        "BUMI_10_total = BUMI_10['Close'].copy(deep=True)\n",
        "inputs_BUMI_10 = BUMI_10_total[len(BUMI_10) - days_period: len(BUMI_10)].values\n",
        "inputs_BUMI_10 = inputs_BUMI_10.reshape(-1,1)\n",
        "inputs_BUMI_10 = sc.transform(inputs_BUMI_10)\n",
        "predicted_BUMI_10_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BUMI_10_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BUMI_10_test.append(inputs_BUMI_10[i:i+days_period, 0])\n",
        "  X_BUMI_10_test = np.array(X_BUMI_10_test)\n",
        "  X_BUMI_10_test = np.reshape(X_BUMI_10_test, (X_BUMI_10_test.shape[0], X_BUMI_10_test.shape[1], 1))\n",
        "  predicted_BUMI_10_return[j] = model_BUMI_10.predict(X_BUMI_10_test)\n",
        "  inputs_BUMI_10 += (predicted_BUMI_10_return[j])\n",
        "  inputs_BUMI_10 = inputs_BUMI_10.reshape(-1,1)\n",
        "\n",
        "# MFIN\n",
        "real_MFIN_10_return = MFIN_10_test.iloc[:, 4:5].values\n",
        "real_MFIN_10_return = real_MFIN_10_return[:days_predict]\n",
        "MFIN_10_total = MFIN_10['Close'].copy(deep=True)\n",
        "inputs_MFIN_10 = MFIN_10_total[len(MFIN_10) - days_period: len(MFIN_10)].values\n",
        "inputs_MFIN_10 = inputs_MFIN_10.reshape(-1,1)\n",
        "inputs_MFIN_10 = sc.transform(inputs_MFIN_10)\n",
        "predicted_MFIN_10_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_MFIN_10_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_MFIN_10_test.append(inputs_MFIN_10[i:i+days_period, 0])\n",
        "  X_MFIN_10_test = np.array(X_MFIN_10_test)\n",
        "  X_MFIN_10_test = np.reshape(X_MFIN_10_test, (X_MFIN_10_test.shape[0], X_MFIN_10_test.shape[1], 1))\n",
        "  predicted_MFIN_10_return[j] = model_MFIN_10.predict(X_MFIN_10_test)\n",
        "  inputs_MFIN_10 += (predicted_MFIN_10_return[j])\n",
        "  inputs_MFIN_10 = inputs_MFIN_10.reshape(-1,1)\n",
        "\n",
        "# EXCL\n",
        "real_EXCL_10_return = EXCL_10_test.iloc[:, 4:5].values\n",
        "real_EXCL_10_return = real_EXCL_10_return[:days_predict]\n",
        "EXCL_10_total = EXCL_10['Close'].copy(deep=True)\n",
        "inputs_EXCL_10 = EXCL_10_total[len(EXCL_10) - days_period: len(EXCL_10)].values\n",
        "inputs_EXCL_10 = inputs_EXCL_10.reshape(-1,1)\n",
        "inputs_EXCL_10 = sc.transform(inputs_EXCL_10)\n",
        "predicted_EXCL_10_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_EXCL_10_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_EXCL_10_test.append(inputs_EXCL_10[i:i+days_period, 0])\n",
        "  X_EXCL_10_test = np.array(X_EXCL_10_test)\n",
        "  X_EXCL_10_test = np.reshape(X_EXCL_10_test, (X_EXCL_10_test.shape[0], X_EXCL_10_test.shape[1], 1))\n",
        "  predicted_EXCL_10_return[j] = model_EXCL_10.predict(X_EXCL_10_test)\n",
        "  inputs_EXCL_10 += (predicted_EXCL_10_return[j])\n",
        "  inputs_EXCL_10 = inputs_EXCL_10.reshape(-1,1)\n",
        "\n",
        "# PGAS\n",
        "real_PGAS_10_return = PGAS_10_test.iloc[:, 4:5].values\n",
        "real_PGAS_10_return = real_PGAS_10_return[:days_predict]\n",
        "PGAS_10_total = PGAS_10['Close'].copy(deep=True)\n",
        "inputs_PGAS_10 = PGAS_10_total[len(PGAS_10) - days_period: len(PGAS_10)].values\n",
        "inputs_PGAS_10 = inputs_PGAS_10.reshape(-1,1)\n",
        "inputs_PGAS_10 = sc.transform(inputs_PGAS_10)\n",
        "predicted_PGAS_10_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_PGAS_10_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_PGAS_10_test.append(inputs_PGAS_10[i:i+days_period, 0])\n",
        "  X_PGAS_10_test = np.array(X_PGAS_10_test)\n",
        "  X_PGAS_10_test = np.reshape(X_PGAS_10_test, (X_PGAS_10_test.shape[0], X_PGAS_10_test.shape[1], 1))\n",
        "  predicted_PGAS_10_return[j] = model_PGAS_10.predict(X_PGAS_10_test)\n",
        "  inputs_PGAS_10 += (predicted_PGAS_10_return[j])\n",
        "  inputs_PGAS_10 = inputs_PGAS_10.reshape(-1,1)\n",
        "\n",
        "# TLKM\n",
        "real_TLKM_10_return = TLKM_10_test.iloc[:, 4:5].values\n",
        "real_TLKM_10_return = real_TLKM_10_return[:days_predict]\n",
        "TLKM_10_total = TLKM_10['Close'].copy(deep=True)\n",
        "inputs_TLKM_10 = TLKM_10_total[len(TLKM_10) - days_period: len(TLKM_10)].values\n",
        "inputs_TLKM_10 = inputs_TLKM_10.reshape(-1,1)\n",
        "inputs_TLKM_10 = sc.transform(inputs_TLKM_10)\n",
        "predicted_TLKM_10_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_TLKM_10_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_TLKM_10_test.append(inputs_TLKM_10[i:i+days_period, 0])\n",
        "  X_TLKM_10_test = np.array(X_TLKM_10_test)\n",
        "  X_TLKM_10_test = np.reshape(X_TLKM_10_test, (X_TLKM_10_test.shape[0], X_TLKM_10_test.shape[1], 1))\n",
        "  predicted_TLKM_10_return[j] = model_TLKM_10.predict(X_TLKM_10_test)\n",
        "  inputs_TLKM_10 += (predicted_TLKM_10_return[j])\n",
        "  inputs_TLKM_10 = inputs_TLKM_10.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5fHkU76oLsk"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "predicted_ADRO_10_return = np.squeeze(np.asarray(predicted_ADRO_10_return))\n",
        "predicted_ADRO_10_return = predicted_ADRO_10_return.reshape(-1,1)\n",
        "predicted_ADRO_10_return = sc.inverse_transform(predicted_ADRO_10_return)\n",
        "# ASII\n",
        "predicted_ASII_10_return = np.squeeze(np.asarray(predicted_ASII_10_return))\n",
        "predicted_ASII_10_return = predicted_ASII_10_return.reshape(-1,1)\n",
        "predicted_ASII_10_return = sc.inverse_transform(predicted_ASII_10_return)\n",
        "# BMRI\n",
        "predicted_BMRI_10_return = np.squeeze(np.asarray(predicted_BMRI_10_return))\n",
        "predicted_BMRI_10_return = predicted_BMRI_10_return.reshape(-1,1)\n",
        "predicted_BMRI_10_return = sc.inverse_transform(predicted_BMRI_10_return)\n",
        "# BBRI\n",
        "predicted_BBRI_10_return = np.squeeze(np.asarray(predicted_BBRI_10_return))\n",
        "predicted_BBRI_10_return = predicted_BBRI_10_return.reshape(-1,1)\n",
        "predicted_BBRI_10_return = sc.inverse_transform(predicted_BBRI_10_return)\n",
        "# BBTN\n",
        "predicted_BBTN_10_return = np.squeeze(np.asarray(predicted_BBTN_10_return))\n",
        "predicted_BBTN_10_return = predicted_BBTN_10_return.reshape(-1,1)\n",
        "predicted_BBTN_10_return = sc.inverse_transform(predicted_BBTN_10_return)\n",
        "# BUMI\n",
        "predicted_BUMI_10_return = np.squeeze(np.asarray(predicted_BUMI_10_return))\n",
        "predicted_BUMI_10_return = predicted_BUMI_10_return.reshape(-1,1)\n",
        "predicted_BUMI_10_return = sc.inverse_transform(predicted_BUMI_10_return)\n",
        "# MFIN\n",
        "predicted_MFIN_10_return = np.squeeze(np.asarray(predicted_MFIN_10_return))\n",
        "predicted_MFIN_10_return = predicted_MFIN_10_return.reshape(-1,1)\n",
        "predicted_MFIN_10_return = sc.inverse_transform(predicted_MFIN_10_return)\n",
        "# EXCL\n",
        "predicted_EXCL_10_return = np.squeeze(np.asarray(predicted_EXCL_10_return))\n",
        "predicted_EXCL_10_return = predicted_EXCL_10_return.reshape(-1,1)\n",
        "predicted_EXCL_10_return = sc.inverse_transform(predicted_EXCL_10_return)\n",
        "# PGAS\n",
        "predicted_PGAS_10_return = np.squeeze(np.asarray(predicted_PGAS_10_return))\n",
        "predicted_PGAS_10_return = predicted_PGAS_10_return.reshape(-1,1)\n",
        "predicted_PGAS_10_return = sc.inverse_transform(predicted_PGAS_10_return)\n",
        "# TLKM\n",
        "predicted_TLKM_10_return = np.squeeze(np.asarray(predicted_TLKM_10_return))\n",
        "predicted_TLKM_10_return = predicted_TLKM_10_return.reshape(-1,1)\n",
        "predicted_TLKM_10_return = sc.inverse_transform(predicted_TLKM_10_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psCcZ3SWoLsl"
      },
      "outputs": [],
      "source": [
        "predicted10 = pd.DataFrame(predicted_ADRO_10_return)\n",
        "predicted10.rename(columns={0:'ADRO'}, inplace=True)\n",
        "predicted10.insert(1,\"ASII\", predicted_ASII_10_return)\n",
        "predicted10.insert(2,\"BBRI\", predicted_BBRI_10_return)\n",
        "predicted10.insert(3,\"BBTN\", predicted_BBTN_10_return)\n",
        "predicted10.insert(4,\"BMRI\", predicted_BMRI_10_return)\n",
        "predicted10.insert(5,\"BUMI\", predicted_BUMI_10_return)\n",
        "predicted10.insert(6,\"EXCL\", predicted_EXCL_10_return)\n",
        "predicted10.insert(7,\"MFIN\", predicted_MFIN_10_return)\n",
        "predicted10.insert(8,\"PGAS\", predicted_PGAS_10_return)\n",
        "predicted10.insert(9,\"TLKM\", predicted_TLKM_10_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBVQ5nGER-3L",
        "outputId": "4c8c1b26-d6a0-4882-ec9c-3ebdb64e81a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADRO      ASII      BBRI      BBTN      BMRI      BUMI      EXCL  \\\n",
              "0  0.013315  0.026434 -0.018602  0.034396  0.023089 -0.001409 -0.046919   \n",
              "1  0.012546  0.025373 -0.019079  0.033020  0.022316 -0.002244 -0.046769   \n",
              "2  0.011620  0.024079 -0.019690  0.031390  0.021338 -0.003238 -0.046623   \n",
              "3  0.010505  0.022509 -0.020456  0.029467  0.020112 -0.004417 -0.046490   \n",
              "4  0.009163  0.020614 -0.021399  0.027207  0.018586 -0.005809 -0.046379   \n",
              "5  0.007552  0.018341 -0.022539  0.024564  0.016703 -0.007444 -0.046303   \n",
              "6  0.005621  0.015633 -0.023893  0.021487  0.014398 -0.009353 -0.046276   \n",
              "7  0.003317  0.012432 -0.025477  0.017928  0.011604 -0.011568 -0.046318   \n",
              "8  0.000582  0.008683 -0.027299  0.013838  0.008251 -0.014116 -0.046450   \n",
              "9 -0.002643  0.004338 -0.029362  0.009177  0.004274 -0.017019 -0.046696   \n",
              "\n",
              "       MFIN      PGAS      TLKM  \n",
              "0  0.013404  0.004852  0.062402  \n",
              "1  0.012730  0.003635  0.060714  \n",
              "2  0.011869  0.002207  0.058692  \n",
              "3  0.010783  0.000539  0.056279  \n",
              "4  0.009426 -0.001395  0.053412  \n",
              "5  0.007749 -0.003624  0.050019  \n",
              "6  0.005699 -0.006172  0.046030  \n",
              "7  0.003221 -0.009059  0.041371  \n",
              "8  0.000262 -0.012297  0.035974  \n",
              "9 -0.003227 -0.015886  0.029784  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8475b06c-acb4-4da1-96ef-9364b7ef1376\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADRO</th>\n",
              "      <th>ASII</th>\n",
              "      <th>BBRI</th>\n",
              "      <th>BBTN</th>\n",
              "      <th>BMRI</th>\n",
              "      <th>BUMI</th>\n",
              "      <th>EXCL</th>\n",
              "      <th>MFIN</th>\n",
              "      <th>PGAS</th>\n",
              "      <th>TLKM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013315</td>\n",
              "      <td>0.026434</td>\n",
              "      <td>-0.018602</td>\n",
              "      <td>0.034396</td>\n",
              "      <td>0.023089</td>\n",
              "      <td>-0.001409</td>\n",
              "      <td>-0.046919</td>\n",
              "      <td>0.013404</td>\n",
              "      <td>0.004852</td>\n",
              "      <td>0.062402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.012546</td>\n",
              "      <td>0.025373</td>\n",
              "      <td>-0.019079</td>\n",
              "      <td>0.033020</td>\n",
              "      <td>0.022316</td>\n",
              "      <td>-0.002244</td>\n",
              "      <td>-0.046769</td>\n",
              "      <td>0.012730</td>\n",
              "      <td>0.003635</td>\n",
              "      <td>0.060714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.011620</td>\n",
              "      <td>0.024079</td>\n",
              "      <td>-0.019690</td>\n",
              "      <td>0.031390</td>\n",
              "      <td>0.021338</td>\n",
              "      <td>-0.003238</td>\n",
              "      <td>-0.046623</td>\n",
              "      <td>0.011869</td>\n",
              "      <td>0.002207</td>\n",
              "      <td>0.058692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.010505</td>\n",
              "      <td>0.022509</td>\n",
              "      <td>-0.020456</td>\n",
              "      <td>0.029467</td>\n",
              "      <td>0.020112</td>\n",
              "      <td>-0.004417</td>\n",
              "      <td>-0.046490</td>\n",
              "      <td>0.010783</td>\n",
              "      <td>0.000539</td>\n",
              "      <td>0.056279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.009163</td>\n",
              "      <td>0.020614</td>\n",
              "      <td>-0.021399</td>\n",
              "      <td>0.027207</td>\n",
              "      <td>0.018586</td>\n",
              "      <td>-0.005809</td>\n",
              "      <td>-0.046379</td>\n",
              "      <td>0.009426</td>\n",
              "      <td>-0.001395</td>\n",
              "      <td>0.053412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.007552</td>\n",
              "      <td>0.018341</td>\n",
              "      <td>-0.022539</td>\n",
              "      <td>0.024564</td>\n",
              "      <td>0.016703</td>\n",
              "      <td>-0.007444</td>\n",
              "      <td>-0.046303</td>\n",
              "      <td>0.007749</td>\n",
              "      <td>-0.003624</td>\n",
              "      <td>0.050019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.005621</td>\n",
              "      <td>0.015633</td>\n",
              "      <td>-0.023893</td>\n",
              "      <td>0.021487</td>\n",
              "      <td>0.014398</td>\n",
              "      <td>-0.009353</td>\n",
              "      <td>-0.046276</td>\n",
              "      <td>0.005699</td>\n",
              "      <td>-0.006172</td>\n",
              "      <td>0.046030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.003317</td>\n",
              "      <td>0.012432</td>\n",
              "      <td>-0.025477</td>\n",
              "      <td>0.017928</td>\n",
              "      <td>0.011604</td>\n",
              "      <td>-0.011568</td>\n",
              "      <td>-0.046318</td>\n",
              "      <td>0.003221</td>\n",
              "      <td>-0.009059</td>\n",
              "      <td>0.041371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000582</td>\n",
              "      <td>0.008683</td>\n",
              "      <td>-0.027299</td>\n",
              "      <td>0.013838</td>\n",
              "      <td>0.008251</td>\n",
              "      <td>-0.014116</td>\n",
              "      <td>-0.046450</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>-0.012297</td>\n",
              "      <td>0.035974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.002643</td>\n",
              "      <td>0.004338</td>\n",
              "      <td>-0.029362</td>\n",
              "      <td>0.009177</td>\n",
              "      <td>0.004274</td>\n",
              "      <td>-0.017019</td>\n",
              "      <td>-0.046696</td>\n",
              "      <td>-0.003227</td>\n",
              "      <td>-0.015886</td>\n",
              "      <td>0.029784</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8475b06c-acb4-4da1-96ef-9364b7ef1376')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8475b06c-acb4-4da1-96ef-9364b7ef1376 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8475b06c-acb4-4da1-96ef-9364b7ef1376');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYL6xjHacjIc"
      },
      "source": [
        "## Data Preparation 11\n",
        "1st of January 2018 - 9th of April 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfhxglI8oPmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852c4365-8f62-48e4-fead-b610a6b36e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 10s 58ms/step - loss: 0.2015\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0520\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0458\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0415\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0402\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0459\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0453\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0466\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0460\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0463\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 10s 44ms/step - loss: 0.1174\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0371\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0353\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0260\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0233\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0263\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0239\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0218\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0257\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0221\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 77ms/step - loss: 0.0515\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0131\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 62ms/step - loss: 0.0109\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0078\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 0.0079\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.0072\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0070\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 0.0075\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 0.0067\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.0089\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 41ms/step - loss: 0.1380\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0508\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0484\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0534\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0402\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0408\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0426\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0479\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0445\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0375\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 10s 41ms/step - loss: 0.1934\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0411\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0257\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0209\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0172\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0143\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0172\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0190\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0177\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0169\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 43ms/step - loss: 0.1626\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0741\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0675\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0588\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0536\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0489\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0420\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0435\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0452\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0476\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 42ms/step - loss: 0.0323\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0084\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0064\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0064\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0058\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0060\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0065\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 61ms/step - loss: 0.0062\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0062\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0060\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 8s 42ms/step - loss: 0.0114\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0090\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0084\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0082\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0082\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 61ms/step - loss: 0.0082\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0084\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0081\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 71ms/step - loss: 0.0085\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 0.0081\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 8s 42ms/step - loss: 0.1695\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0506\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0464\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 0.0358\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0309\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0293\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.0349\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 0.0346\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 0.0322\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.0358\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 44ms/step - loss: 0.2177\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0667\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0473\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0306\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0283\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0338\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0281\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0260\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0270\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0289\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efae524e5f0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Period parameters\n",
        "days_period = 20\n",
        "days_predict = 10\n",
        "\n",
        "# ADRO\n",
        "ADRO_11 = yf.download(\"ADRO.JK\", start=\"2022-10-10\", end=\"2023-04-10\")\n",
        "ADRO_11.insert(4,\"Return\", ADRO_11['Close'].pct_change())\n",
        "ADRO_11 = ADRO_11.dropna()\n",
        "ADRO_11_test = yf.download(\"ADRO.JK\", start=\"2023-04-09\", end=\"2023-05-10\")\n",
        "ADRO_11_test.insert(4,\"Return\", ADRO_11_test['Close'].pct_change())\n",
        "ADRO_11_test = ADRO_11_test.dropna()\n",
        "training_ADRO_11 = ADRO_11.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ADRO_11_scaled = sc.fit_transform(training_ADRO_11)\n",
        "X_ADRO_11_train = []\n",
        "y_ADRO_11_train = []\n",
        "for i in range(days_period, len(ADRO_11)-1):\n",
        "    X_ADRO_11_train.append(training_ADRO_11_scaled[i-days_period:i, 0])\n",
        "    y_ADRO_11_train.append(training_ADRO_11_scaled[i, 0])\n",
        "X_ADRO_11_train, y_ADRO_11_train = np.array(X_ADRO_11_train), np.array(y_ADRO_11_train)\n",
        "X_ADRO_11_train = np.reshape(X_ADRO_11_train, (X_ADRO_11_train.shape[0], X_ADRO_11_train.shape[1], 1))\n",
        "model_ADRO_11 = Sequential()\n",
        "model_ADRO_11.add(LSTM(units=50,return_sequences=True,input_shape=(X_ADRO_11_train.shape[1], 1)))\n",
        "model_ADRO_11.add(Dropout(0.2))\n",
        "model_ADRO_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_11.add(Dropout(0.2))\n",
        "model_ADRO_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_ADRO_11.add(Dropout(0.2))\n",
        "model_ADRO_11.add(LSTM(units=50))\n",
        "model_ADRO_11.add(Dropout(0.2))\n",
        "model_ADRO_11.add(Dense(units=1))\n",
        "model_ADRO_11.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ADRO_11.fit(X_ADRO_11_train,y_ADRO_11_train,epochs=10,batch_size=16)\n",
        "\n",
        "# ASII\n",
        "ASII_11 = yf.download(\"ASII.JK\", start=\"2022-10-10\", end=\"2023-04-10\")\n",
        "ASII_11.insert(4,\"Return\", ASII_11['Close'].pct_change())\n",
        "ASII_11 = ASII_11.dropna()\n",
        "ASII_11_test = yf.download(\"ASII.JK\", start=\"2023-04-09\", end=\"2023-05-10\")\n",
        "ASII_11_test.insert(4,\"Return\", ASII_11_test['Close'].pct_change())\n",
        "ASII_11_test = ASII_11_test.dropna()\n",
        "training_ASII_11 = ASII_11.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_ASII_11_scaled = sc.fit_transform(training_ASII_11)\n",
        "X_ASII_11_train = []\n",
        "y_ASII_11_train = []\n",
        "for i in range(days_period, len(ASII_11)-1):\n",
        "    X_ASII_11_train.append(training_ASII_11_scaled[i-days_period:i, 0])\n",
        "    y_ASII_11_train.append(training_ASII_11_scaled[i, 0])\n",
        "X_ASII_11_train, y_ASII_11_train = np.array(X_ASII_11_train), np.array(y_ASII_11_train)\n",
        "X_ASII_11_train = np.reshape(X_ASII_11_train, (X_ASII_11_train.shape[0], X_ASII_11_train.shape[1], 1))\n",
        "model_ASII_11 = Sequential()\n",
        "model_ASII_11.add(LSTM(units=50,return_sequences=True,input_shape=(X_ASII_11_train.shape[1], 1)))\n",
        "model_ASII_11.add(Dropout(0.2))\n",
        "model_ASII_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_11.add(Dropout(0.2))\n",
        "model_ASII_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_ASII_11.add(Dropout(0.2))\n",
        "model_ASII_11.add(LSTM(units=50))\n",
        "model_ASII_11.add(Dropout(0.2))\n",
        "model_ASII_11.add(Dense(units=1))\n",
        "model_ASII_11.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_ASII_11.fit(X_ASII_11_train,y_ASII_11_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BMRI\n",
        "BMRI_11 = yf.download(\"BMRI.JK\", start=\"2022-10-10\", end=\"2023-04-10\")\n",
        "BMRI_11.insert(4,\"Return\", BMRI_11['Close'].pct_change())\n",
        "BMRI_11 = BMRI_11.dropna()\n",
        "BMRI_11_test = yf.download(\"BMRI.JK\", start=\"2023-04-09\", end=\"2023-05-10\")\n",
        "BMRI_11_test.insert(4,\"Return\", BMRI_11_test['Close'].pct_change())\n",
        "BMRI_11_test = BMRI_11_test.dropna()\n",
        "training_BMRI_11 = BMRI_11.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BMRI_11_scaled = sc.fit_transform(training_BMRI_11)\n",
        "X_BMRI_11_train = []\n",
        "y_BMRI_11_train = []\n",
        "for i in range(days_period, len(BMRI_11)-1):\n",
        "    X_BMRI_11_train.append(training_BMRI_11_scaled[i-days_period:i, 0])\n",
        "    y_BMRI_11_train.append(training_BMRI_11_scaled[i, 0])\n",
        "X_BMRI_11_train, y_BMRI_11_train = np.array(X_BMRI_11_train), np.array(y_BMRI_11_train)\n",
        "X_BMRI_11_train = np.reshape(X_BMRI_11_train, (X_BMRI_11_train.shape[0], X_BMRI_11_train.shape[1], 1))\n",
        "model_BMRI_11 = Sequential()\n",
        "model_BMRI_11.add(LSTM(units=50,return_sequences=True,input_shape=(X_BMRI_11_train.shape[1], 1)))\n",
        "model_BMRI_11.add(Dropout(0.2))\n",
        "model_BMRI_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_11.add(Dropout(0.2))\n",
        "model_BMRI_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_BMRI_11.add(Dropout(0.2))\n",
        "model_BMRI_11.add(LSTM(units=50))\n",
        "model_BMRI_11.add(Dropout(0.2))\n",
        "model_BMRI_11.add(Dense(units=1))\n",
        "model_BMRI_11.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BMRI_11.fit(X_BMRI_11_train,y_BMRI_11_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBRI\n",
        "BBRI_11 = yf.download(\"BBRI.JK\", start=\"2022-10-10\", end=\"2023-04-10\")\n",
        "BBRI_11.insert(4,\"Return\", BBRI_11['Close'].pct_change())\n",
        "BBRI_11 = BBRI_11.dropna()\n",
        "BBRI_11_test = yf.download(\"BBRI.JK\", start=\"2023-04-09\", end=\"2023-05-10\")\n",
        "BBRI_11_test.insert(4,\"Return\", BBRI_11_test['Close'].pct_change())\n",
        "BBRI_11_test = BBRI_11_test.dropna()\n",
        "training_BBRI_11 = BBRI_11.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBRI_11_scaled = sc.fit_transform(training_BBRI_11)\n",
        "X_BBRI_11_train = []\n",
        "y_BBRI_11_train = []\n",
        "for i in range(days_period, len(BBRI_11)-1):\n",
        "    X_BBRI_11_train.append(training_BBRI_11_scaled[i-days_period:i, 0])\n",
        "    y_BBRI_11_train.append(training_BBRI_11_scaled[i, 0])\n",
        "X_BBRI_11_train, y_BBRI_11_train = np.array(X_BBRI_11_train), np.array(y_BBRI_11_train)\n",
        "X_BBRI_11_train = np.reshape(X_BBRI_11_train, (X_BBRI_11_train.shape[0], X_BBRI_11_train.shape[1], 1))\n",
        "model_BBRI_11 = Sequential()\n",
        "model_BBRI_11.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBRI_11_train.shape[1], 1)))\n",
        "model_BBRI_11.add(Dropout(0.2))\n",
        "model_BBRI_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_11.add(Dropout(0.2))\n",
        "model_BBRI_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBRI_11.add(Dropout(0.2))\n",
        "model_BBRI_11.add(LSTM(units=50))\n",
        "model_BBRI_11.add(Dropout(0.2))\n",
        "model_BBRI_11.add(Dense(units=1))\n",
        "model_BBRI_11.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBRI_11.fit(X_BBRI_11_train,y_BBRI_11_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BBTN\n",
        "BBTN_11 = yf.download(\"BBTN.JK\", start=\"2022-10-10\", end=\"2023-04-10\")\n",
        "BBTN_11.insert(4,\"Return\", BBTN_11['Close'].pct_change())\n",
        "BBTN_11 = BBTN_11.dropna()\n",
        "BBTN_11_test = yf.download(\"BBTN.JK\", start=\"2023-04-09\", end=\"2023-05-10\")\n",
        "BBTN_11_test.insert(4,\"Return\", BBTN_11_test['Close'].pct_change())\n",
        "BBTN_11_test = BBTN_11_test.dropna()\n",
        "training_BBTN_11 = BBTN_11.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BBTN_11_scaled = sc.fit_transform(training_BBTN_11)\n",
        "X_BBTN_11_train = []\n",
        "y_BBTN_11_train = []\n",
        "for i in range(days_period, len(BBTN_11)-1):\n",
        "    X_BBTN_11_train.append(training_BBTN_11_scaled[i-days_period:i, 0])\n",
        "    y_BBTN_11_train.append(training_BBTN_11_scaled[i, 0])\n",
        "X_BBTN_11_train, y_BBTN_11_train = np.array(X_BBTN_11_train), np.array(y_BBTN_11_train)\n",
        "X_BBTN_11_train = np.reshape(X_BBTN_11_train, (X_BBTN_11_train.shape[0], X_BBTN_11_train.shape[1], 1))\n",
        "model_BBTN_11 = Sequential()\n",
        "model_BBTN_11.add(LSTM(units=50,return_sequences=True,input_shape=(X_BBTN_11_train.shape[1], 1)))\n",
        "model_BBTN_11.add(Dropout(0.2))\n",
        "model_BBTN_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_11.add(Dropout(0.2))\n",
        "model_BBTN_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_BBTN_11.add(Dropout(0.2))\n",
        "model_BBTN_11.add(LSTM(units=50))\n",
        "model_BBTN_11.add(Dropout(0.2))\n",
        "model_BBTN_11.add(Dense(units=1))\n",
        "model_BBTN_11.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BBTN_11.fit(X_BBTN_11_train,y_BBTN_11_train,epochs=10,batch_size=16)\n",
        "\n",
        "# BUMI\n",
        "BUMI_11 = yf.download(\"BUMI.JK\", start=\"2022-10-10\", end=\"2023-04-10\")\n",
        "BUMI_11.insert(4,\"Return\", BUMI_11['Close'].pct_change())\n",
        "BUMI_11 = BUMI_11.dropna()\n",
        "BUMI_11_test = yf.download(\"BUMI.JK\", start=\"2023-04-09\", end=\"2023-05-10\")\n",
        "BUMI_11_test.insert(4,\"Return\", BUMI_11_test['Close'].pct_change())\n",
        "BUMI_11_test = BUMI_11_test.dropna()\n",
        "training_BUMI_11 = BUMI_11.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_BUMI_11_scaled = sc.fit_transform(training_BUMI_11)\n",
        "X_BUMI_11_train = []\n",
        "y_BUMI_11_train = []\n",
        "for i in range(days_period, len(BUMI_11)-1):\n",
        "    X_BUMI_11_train.append(training_BUMI_11_scaled[i-days_period:i, 0])\n",
        "    y_BUMI_11_train.append(training_BUMI_11_scaled[i, 0])\n",
        "X_BUMI_11_train, y_BUMI_11_train = np.array(X_BUMI_11_train), np.array(y_BUMI_11_train)\n",
        "X_BUMI_11_train = np.reshape(X_BUMI_11_train, (X_BUMI_11_train.shape[0], X_BUMI_11_train.shape[1], 1))\n",
        "model_BUMI_11 = Sequential()\n",
        "model_BUMI_11.add(LSTM(units=50,return_sequences=True,input_shape=(X_BUMI_11_train.shape[1], 1)))\n",
        "model_BUMI_11.add(Dropout(0.2))\n",
        "model_BUMI_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_11.add(Dropout(0.2))\n",
        "model_BUMI_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_BUMI_11.add(Dropout(0.2))\n",
        "model_BUMI_11.add(LSTM(units=50))\n",
        "model_BUMI_11.add(Dropout(0.2))\n",
        "model_BUMI_11.add(Dense(units=1))\n",
        "model_BUMI_11.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_BUMI_11.fit(X_BUMI_11_train,y_BUMI_11_train,epochs=10,batch_size=16)\n",
        "\n",
        "# MFIN\n",
        "MFIN_11 = yf.download(\"MFIN.JK\", start=\"2022-10-10\", end=\"2023-04-10\")\n",
        "MFIN_11.insert(4,\"Return\", MFIN_11['Close'].pct_change())\n",
        "MFIN_11 = MFIN_11.dropna()\n",
        "MFIN_11_test = yf.download(\"MFIN.JK\", start=\"2023-04-09\", end=\"2023-05-10\")\n",
        "MFIN_11_test.insert(4,\"Return\", MFIN_11_test['Close'].pct_change())\n",
        "MFIN_11_test = MFIN_11_test.dropna()\n",
        "training_MFIN_11 = MFIN_11.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_MFIN_11_scaled = sc.fit_transform(training_MFIN_11)\n",
        "X_MFIN_11_train = []\n",
        "y_MFIN_11_train = []\n",
        "for i in range(days_period, len(MFIN_11)-1):\n",
        "    X_MFIN_11_train.append(training_MFIN_11_scaled[i-days_period:i, 0])\n",
        "    y_MFIN_11_train.append(training_MFIN_11_scaled[i, 0])\n",
        "X_MFIN_11_train, y_MFIN_11_train = np.array(X_MFIN_11_train), np.array(y_MFIN_11_train)\n",
        "X_MFIN_11_train = np.reshape(X_MFIN_11_train, (X_MFIN_11_train.shape[0], X_MFIN_11_train.shape[1], 1))\n",
        "model_MFIN_11 = Sequential()\n",
        "model_MFIN_11.add(LSTM(units=50,return_sequences=True,input_shape=(X_MFIN_11_train.shape[1], 1)))\n",
        "model_MFIN_11.add(Dropout(0.2))\n",
        "model_MFIN_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_11.add(Dropout(0.2))\n",
        "model_MFIN_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_MFIN_11.add(Dropout(0.2))\n",
        "model_MFIN_11.add(LSTM(units=50))\n",
        "model_MFIN_11.add(Dropout(0.2))\n",
        "model_MFIN_11.add(Dense(units=1))\n",
        "model_MFIN_11.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_MFIN_11.fit(X_MFIN_11_train,y_MFIN_11_train,epochs=10,batch_size=16)\n",
        "\n",
        "# EXCL\n",
        "EXCL_11 = yf.download(\"EXCL.JK\", start=\"2022-10-10\", end=\"2023-04-10\")\n",
        "EXCL_11.insert(4,\"Return\", EXCL_11['Close'].pct_change())\n",
        "EXCL_11 = EXCL_11.dropna()\n",
        "EXCL_11_test = yf.download(\"EXCL.JK\", start=\"2023-04-09\", end=\"2023-05-10\")\n",
        "EXCL_11_test.insert(4,\"Return\", EXCL_11_test['Close'].pct_change())\n",
        "EXCL_11_test = EXCL_11_test.dropna()\n",
        "training_EXCL_11 = EXCL_11.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_EXCL_11_scaled = sc.fit_transform(training_EXCL_11)\n",
        "X_EXCL_11_train = []\n",
        "y_EXCL_11_train = []\n",
        "for i in range(days_period, len(EXCL_11)-1):\n",
        "    X_EXCL_11_train.append(training_EXCL_11_scaled[i-days_period:i, 0])\n",
        "    y_EXCL_11_train.append(training_EXCL_11_scaled[i, 0])\n",
        "X_EXCL_11_train, y_EXCL_11_train = np.array(X_EXCL_11_train), np.array(y_EXCL_11_train)\n",
        "X_EXCL_11_train = np.reshape(X_EXCL_11_train, (X_EXCL_11_train.shape[0], X_EXCL_11_train.shape[1], 1))\n",
        "model_EXCL_11 = Sequential()\n",
        "model_EXCL_11.add(LSTM(units=50,return_sequences=True,input_shape=(X_EXCL_11_train.shape[1], 1)))\n",
        "model_EXCL_11.add(Dropout(0.2))\n",
        "model_EXCL_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_11.add(Dropout(0.2))\n",
        "model_EXCL_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_EXCL_11.add(Dropout(0.2))\n",
        "model_EXCL_11.add(LSTM(units=50))\n",
        "model_EXCL_11.add(Dropout(0.2))\n",
        "model_EXCL_11.add(Dense(units=1))\n",
        "model_EXCL_11.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_EXCL_11.fit(X_EXCL_11_train,y_EXCL_11_train,epochs=10,batch_size=16)\n",
        "\n",
        "# PGAS\n",
        "PGAS_11 = yf.download(\"PGAS.JK\", start=\"2022-10-10\", end=\"2023-04-10\")\n",
        "PGAS_11.insert(4,\"Return\", PGAS_11['Close'].pct_change())\n",
        "PGAS_11 = PGAS_11.dropna()\n",
        "PGAS_11_test = yf.download(\"PGAS.JK\", start=\"2023-04-09\", end=\"2023-05-10\")\n",
        "PGAS_11_test.insert(4,\"Return\", PGAS_11_test['Close'].pct_change())\n",
        "PGAS_11_test = PGAS_11_test.dropna()\n",
        "training_PGAS_11 = PGAS_11.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_PGAS_11_scaled = sc.fit_transform(training_PGAS_11)\n",
        "X_PGAS_11_train = []\n",
        "y_PGAS_11_train = []\n",
        "for i in range(days_period, len(PGAS_11)-1):\n",
        "    X_PGAS_11_train.append(training_PGAS_11_scaled[i-days_period:i, 0])\n",
        "    y_PGAS_11_train.append(training_PGAS_11_scaled[i, 0])\n",
        "X_PGAS_11_train, y_PGAS_11_train = np.array(X_PGAS_11_train), np.array(y_PGAS_11_train)\n",
        "X_PGAS_11_train = np.reshape(X_PGAS_11_train, (X_PGAS_11_train.shape[0], X_PGAS_11_train.shape[1], 1))\n",
        "model_PGAS_11 = Sequential()\n",
        "model_PGAS_11.add(LSTM(units=50,return_sequences=True,input_shape=(X_PGAS_11_train.shape[1], 1)))\n",
        "model_PGAS_11.add(Dropout(0.2))\n",
        "model_PGAS_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_11.add(Dropout(0.2))\n",
        "model_PGAS_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_PGAS_11.add(Dropout(0.2))\n",
        "model_PGAS_11.add(LSTM(units=50))\n",
        "model_PGAS_11.add(Dropout(0.2))\n",
        "model_PGAS_11.add(Dense(units=1))\n",
        "model_PGAS_11.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_PGAS_11.fit(X_PGAS_11_train,y_PGAS_11_train,epochs=10,batch_size=16)\n",
        "\n",
        "# TLKM\n",
        "TLKM_11 = yf.download(\"TLKM.JK\", start=\"2022-10-10\", end=\"2023-04-10\")\n",
        "TLKM_11.insert(4,\"Return\", TLKM_11['Close'].pct_change())\n",
        "TLKM_11 = TLKM_11.dropna()\n",
        "TLKM_11_test = yf.download(\"TLKM.JK\", start=\"2023-04-09\", end=\"2023-05-10\")\n",
        "TLKM_11_test.insert(4,\"Return\", TLKM_11_test['Close'].pct_change())\n",
        "TLKM_11_test = TLKM_11_test.dropna()\n",
        "training_TLKM_11 = TLKM_11.iloc[:, 4:5].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_TLKM_11_scaled = sc.fit_transform(training_TLKM_11)\n",
        "X_TLKM_11_train = []\n",
        "y_TLKM_11_train = []\n",
        "for i in range(days_period, len(TLKM_11)-1):\n",
        "    X_TLKM_11_train.append(training_TLKM_11_scaled[i-days_period:i, 0])\n",
        "    y_TLKM_11_train.append(training_TLKM_11_scaled[i, 0])\n",
        "X_TLKM_11_train, y_TLKM_11_train = np.array(X_TLKM_11_train), np.array(y_TLKM_11_train)\n",
        "X_TLKM_11_train = np.reshape(X_TLKM_11_train, (X_TLKM_11_train.shape[0], X_TLKM_11_train.shape[1], 1))\n",
        "model_TLKM_11 = Sequential()\n",
        "model_TLKM_11.add(LSTM(units=50,return_sequences=True,input_shape=(X_TLKM_11_train.shape[1], 1)))\n",
        "model_TLKM_11.add(Dropout(0.2))\n",
        "model_TLKM_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_11.add(Dropout(0.2))\n",
        "model_TLKM_11.add(LSTM(units=50,return_sequences=True))\n",
        "model_TLKM_11.add(Dropout(0.2))\n",
        "model_TLKM_11.add(LSTM(units=50))\n",
        "model_TLKM_11.add(Dropout(0.2))\n",
        "model_TLKM_11.add(Dense(units=1))\n",
        "model_TLKM_11.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model_TLKM_11.fit(X_TLKM_11_train,y_TLKM_11_train,epochs=10,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km8jik4joPmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf9f65d-6d9a-4eb3-99a3-4d94f108592a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n"
          ]
        }
      ],
      "source": [
        "# ADRO\n",
        "real_ADRO_11_return = ADRO_11_test.iloc[:, 4:5].values\n",
        "real_ADRO_11_return = real_ADRO_11_return[:days_predict]\n",
        "ADRO_11_total = ADRO_11['Close'].copy(deep=True)\n",
        "inputs_ADRO_11 = ADRO_11_total[len(ADRO_11) - days_period: len(ADRO_11)].values\n",
        "inputs_ADRO_11 = inputs_ADRO_11.reshape(-1,1)\n",
        "inputs_ADRO_11 = sc.transform(inputs_ADRO_11)\n",
        "predicted_ADRO_11_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ADRO_11_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ADRO_11_test.append(inputs_ADRO_11[i:i+days_period, 0])\n",
        "  X_ADRO_11_test = np.array(X_ADRO_11_test)\n",
        "  X_ADRO_11_test = np.reshape(X_ADRO_11_test, (X_ADRO_11_test.shape[0], X_ADRO_11_test.shape[1], 1))\n",
        "  predicted_ADRO_11_return[j] = model_ADRO_11.predict(X_ADRO_11_test)\n",
        "  inputs_ADRO_11 += (predicted_ADRO_11_return[j])\n",
        "  inputs_ADRO_11 = inputs_ADRO_11.reshape(-1,1)\n",
        "\n",
        "# ASII\n",
        "real_ASII_11_return = ASII_11_test.iloc[:, 4:5].values\n",
        "real_ASII_11_return = real_ASII_11_return[:days_predict]\n",
        "ASII_11_total = ASII_11['Close'].copy(deep=True)\n",
        "inputs_ASII_11 = ASII_11_total[len(ASII_11) - days_period: len(ASII_11)].values\n",
        "inputs_ASII_11 = inputs_ASII_11.reshape(-1,1)\n",
        "inputs_ASII_11 = sc.transform(inputs_ASII_11)\n",
        "predicted_ASII_11_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_ASII_11_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_ASII_11_test.append(inputs_ASII_11[i:i+days_period, 0])\n",
        "  X_ASII_11_test = np.array(X_ASII_11_test)\n",
        "  X_ASII_11_test = np.reshape(X_ASII_11_test, (X_ASII_11_test.shape[0], X_ASII_11_test.shape[1], 1))\n",
        "  predicted_ASII_11_return[j] = model_ASII_11.predict(X_ASII_11_test)\n",
        "  inputs_ASII_11 += (predicted_ASII_11_return[j])\n",
        "  inputs_ASII_11 = inputs_ASII_11.reshape(-1,1)\n",
        "\n",
        "# BMRI\n",
        "real_BMRI_11_return = BMRI_11_test.iloc[:, 4:5].values\n",
        "real_BMRI_11_return = real_BMRI_11_return[:days_predict]\n",
        "BMRI_11_total = BMRI_11['Close'].copy(deep=True)\n",
        "inputs_BMRI_11 = BMRI_11_total[len(BMRI_11) - days_period: len(BMRI_11)].values\n",
        "inputs_BMRI_11 = inputs_BMRI_11.reshape(-1,1)\n",
        "inputs_BMRI_11 = sc.transform(inputs_BMRI_11)\n",
        "predicted_BMRI_11_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BMRI_11_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BMRI_11_test.append(inputs_BMRI_11[i:i+days_period, 0])\n",
        "  X_BMRI_11_test = np.array(X_BMRI_11_test)\n",
        "  X_BMRI_11_test = np.reshape(X_BMRI_11_test, (X_BMRI_11_test.shape[0], X_BMRI_11_test.shape[1], 1))\n",
        "  predicted_BMRI_11_return[j] = model_BMRI_11.predict(X_BMRI_11_test)\n",
        "  inputs_BMRI_11 += (predicted_BMRI_11_return[j])\n",
        "  inputs_BMRI_11 = inputs_BMRI_11.reshape(-1,1)\n",
        "\n",
        "# BBRI\n",
        "real_BBRI_11_return = BBRI_11_test.iloc[:, 4:5].values\n",
        "real_BBRI_11_return = real_BBRI_11_return[:days_predict]\n",
        "BBRI_11_total = BBRI_11['Close'].copy(deep=True)\n",
        "inputs_BBRI_11 = BBRI_11_total[len(BBRI_11) - days_period: len(BBRI_11)].values\n",
        "inputs_BBRI_11 = inputs_BBRI_11.reshape(-1,1)\n",
        "inputs_BBRI_11 = sc.transform(inputs_BBRI_11)\n",
        "predicted_BBRI_11_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBRI_11_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBRI_11_test.append(inputs_BBRI_11[i:i+days_period, 0])\n",
        "  X_BBRI_11_test = np.array(X_BBRI_11_test)\n",
        "  X_BBRI_11_test = np.reshape(X_BBRI_11_test, (X_BBRI_11_test.shape[0], X_BBRI_11_test.shape[1], 1))\n",
        "  predicted_BBRI_11_return[j] = model_BBRI_11.predict(X_BBRI_11_test)\n",
        "  inputs_BBRI_11 += (predicted_BBRI_11_return[j])\n",
        "  inputs_BBRI_11 = inputs_BBRI_11.reshape(-1,1)\n",
        "\n",
        "# BBTN\n",
        "real_BBTN_11_return = BBTN_11_test.iloc[:, 4:5].values\n",
        "real_BBTN_11_return = real_BBTN_11_return[:days_predict]\n",
        "BBTN_11_total = BBTN_11['Close'].copy(deep=True)\n",
        "inputs_BBTN_11 = BBTN_11_total[len(BBTN_11) - days_period: len(BBTN_11)].values\n",
        "inputs_BBTN_11 = inputs_BBTN_11.reshape(-1,1)\n",
        "inputs_BBTN_11 = sc.transform(inputs_BBTN_11)\n",
        "predicted_BBTN_11_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BBTN_11_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BBTN_11_test.append(inputs_BBTN_11[i:i+days_period, 0])\n",
        "  X_BBTN_11_test = np.array(X_BBTN_11_test)\n",
        "  X_BBTN_11_test = np.reshape(X_BBTN_11_test, (X_BBTN_11_test.shape[0], X_BBTN_11_test.shape[1], 1))\n",
        "  predicted_BBTN_11_return[j] = model_BBTN_11.predict(X_BBTN_11_test)\n",
        "  inputs_BBTN_11 += (predicted_BBTN_11_return[j])\n",
        "  inputs_BBTN_11 = inputs_BBTN_11.reshape(-1,1)\n",
        "\n",
        "# BUMI\n",
        "real_BUMI_11_return = BUMI_11_test.iloc[:, 4:5].values\n",
        "real_BUMI_11_return = real_BUMI_11_return[:days_predict]\n",
        "BUMI_11_total = BUMI_11['Close'].copy(deep=True)\n",
        "inputs_BUMI_11 = BUMI_11_total[len(BUMI_11) - days_period: len(BUMI_11)].values\n",
        "inputs_BUMI_11 = inputs_BUMI_11.reshape(-1,1)\n",
        "inputs_BUMI_11 = sc.transform(inputs_BUMI_11)\n",
        "predicted_BUMI_11_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_BUMI_11_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_BUMI_11_test.append(inputs_BUMI_11[i:i+days_period, 0])\n",
        "  X_BUMI_11_test = np.array(X_BUMI_11_test)\n",
        "  X_BUMI_11_test = np.reshape(X_BUMI_11_test, (X_BUMI_11_test.shape[0], X_BUMI_11_test.shape[1], 1))\n",
        "  predicted_BUMI_11_return[j] = model_BUMI_11.predict(X_BUMI_11_test)\n",
        "  inputs_BUMI_11 += (predicted_BUMI_11_return[j])\n",
        "  inputs_BUMI_11 = inputs_BUMI_11.reshape(-1,1)\n",
        "\n",
        "# MFIN\n",
        "real_MFIN_11_return = MFIN_11_test.iloc[:, 4:5].values\n",
        "real_MFIN_11_return = real_MFIN_11_return[:days_predict]\n",
        "MFIN_11_total = MFIN_11['Close'].copy(deep=True)\n",
        "inputs_MFIN_11 = MFIN_11_total[len(MFIN_11) - days_period: len(MFIN_11)].values\n",
        "inputs_MFIN_11 = inputs_MFIN_11.reshape(-1,1)\n",
        "inputs_MFIN_11 = sc.transform(inputs_MFIN_11)\n",
        "predicted_MFIN_11_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_MFIN_11_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_MFIN_11_test.append(inputs_MFIN_11[i:i+days_period, 0])\n",
        "  X_MFIN_11_test = np.array(X_MFIN_11_test)\n",
        "  X_MFIN_11_test = np.reshape(X_MFIN_11_test, (X_MFIN_11_test.shape[0], X_MFIN_11_test.shape[1], 1))\n",
        "  predicted_MFIN_11_return[j] = model_MFIN_11.predict(X_MFIN_11_test)\n",
        "  inputs_MFIN_11 += (predicted_MFIN_11_return[j])\n",
        "  inputs_MFIN_11 = inputs_MFIN_11.reshape(-1,1)\n",
        "\n",
        "# EXCL\n",
        "real_EXCL_11_return = EXCL_11_test.iloc[:, 4:5].values\n",
        "real_EXCL_11_return = real_EXCL_11_return[:days_predict]\n",
        "EXCL_11_total = EXCL_11['Close'].copy(deep=True)\n",
        "inputs_EXCL_11 = EXCL_11_total[len(EXCL_11) - days_period: len(EXCL_11)].values\n",
        "inputs_EXCL_11 = inputs_EXCL_11.reshape(-1,1)\n",
        "inputs_EXCL_11 = sc.transform(inputs_EXCL_11)\n",
        "predicted_EXCL_11_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_EXCL_11_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_EXCL_11_test.append(inputs_EXCL_11[i:i+days_period, 0])\n",
        "  X_EXCL_11_test = np.array(X_EXCL_11_test)\n",
        "  X_EXCL_11_test = np.reshape(X_EXCL_11_test, (X_EXCL_11_test.shape[0], X_EXCL_11_test.shape[1], 1))\n",
        "  predicted_EXCL_11_return[j] = model_EXCL_11.predict(X_EXCL_11_test)\n",
        "  inputs_EXCL_11 += (predicted_EXCL_11_return[j])\n",
        "  inputs_EXCL_11 = inputs_EXCL_11.reshape(-1,1)\n",
        "\n",
        "# PGAS\n",
        "real_PGAS_11_return = PGAS_11_test.iloc[:, 4:5].values\n",
        "real_PGAS_11_return = real_PGAS_11_return[:days_predict]\n",
        "PGAS_11_total = PGAS_11['Close'].copy(deep=True)\n",
        "inputs_PGAS_11 = PGAS_11_total[len(PGAS_11) - days_period: len(PGAS_11)].values\n",
        "inputs_PGAS_11 = inputs_PGAS_11.reshape(-1,1)\n",
        "inputs_PGAS_11 = sc.transform(inputs_PGAS_11)\n",
        "predicted_PGAS_11_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_PGAS_11_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_PGAS_11_test.append(inputs_PGAS_11[i:i+days_period, 0])\n",
        "  X_PGAS_11_test = np.array(X_PGAS_11_test)\n",
        "  X_PGAS_11_test = np.reshape(X_PGAS_11_test, (X_PGAS_11_test.shape[0], X_PGAS_11_test.shape[1], 1))\n",
        "  predicted_PGAS_11_return[j] = model_PGAS_11.predict(X_PGAS_11_test)\n",
        "  inputs_PGAS_11 += (predicted_PGAS_11_return[j])\n",
        "  inputs_PGAS_11 = inputs_PGAS_11.reshape(-1,1)\n",
        "\n",
        "# TLKM\n",
        "real_TLKM_11_return = TLKM_11_test.iloc[:, 4:5].values\n",
        "real_TLKM_11_return = real_TLKM_11_return[:days_predict]\n",
        "TLKM_11_total = TLKM_11['Close'].copy(deep=True)\n",
        "inputs_TLKM_11 = TLKM_11_total[len(TLKM_11) - days_period: len(TLKM_11)].values\n",
        "inputs_TLKM_11 = inputs_TLKM_11.reshape(-1,1)\n",
        "inputs_TLKM_11 = sc.transform(inputs_TLKM_11)\n",
        "predicted_TLKM_11_return = [0 for i in range (days_predict)]\n",
        "for j in range (days_predict):\n",
        "  X_TLKM_11_test = []\n",
        "  for i in range(j, j+1):\n",
        "      X_TLKM_11_test.append(inputs_TLKM_11[i:i+days_period, 0])\n",
        "  X_TLKM_11_test = np.array(X_TLKM_11_test)\n",
        "  X_TLKM_11_test = np.reshape(X_TLKM_11_test, (X_TLKM_11_test.shape[0], X_TLKM_11_test.shape[1], 1))\n",
        "  predicted_TLKM_11_return[j] = model_TLKM_11.predict(X_TLKM_11_test)\n",
        "  inputs_TLKM_11 += (predicted_TLKM_11_return[j])\n",
        "  inputs_TLKM_11 = inputs_TLKM_11.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnx7Ew4KoPmV"
      },
      "outputs": [],
      "source": [
        "# ADRO\n",
        "predicted_ADRO_11_return = np.squeeze(np.asarray(predicted_ADRO_11_return))\n",
        "predicted_ADRO_11_return = predicted_ADRO_11_return.reshape(-1,1)\n",
        "predicted_ADRO_11_return = sc.inverse_transform(predicted_ADRO_11_return)\n",
        "# ASII\n",
        "predicted_ASII_11_return = np.squeeze(np.asarray(predicted_ASII_11_return))\n",
        "predicted_ASII_11_return = predicted_ASII_11_return.reshape(-1,1)\n",
        "predicted_ASII_11_return = sc.inverse_transform(predicted_ASII_11_return)\n",
        "# BMRI\n",
        "predicted_BMRI_11_return = np.squeeze(np.asarray(predicted_BMRI_11_return))\n",
        "predicted_BMRI_11_return = predicted_BMRI_11_return.reshape(-1,1)\n",
        "predicted_BMRI_11_return = sc.inverse_transform(predicted_BMRI_11_return)\n",
        "# BBRI\n",
        "predicted_BBRI_11_return = np.squeeze(np.asarray(predicted_BBRI_11_return))\n",
        "predicted_BBRI_11_return = predicted_BBRI_11_return.reshape(-1,1)\n",
        "predicted_BBRI_11_return = sc.inverse_transform(predicted_BBRI_11_return)\n",
        "# BBTN\n",
        "predicted_BBTN_11_return = np.squeeze(np.asarray(predicted_BBTN_11_return))\n",
        "predicted_BBTN_11_return = predicted_BBTN_11_return.reshape(-1,1)\n",
        "predicted_BBTN_11_return = sc.inverse_transform(predicted_BBTN_11_return)\n",
        "# BUMI\n",
        "predicted_BUMI_11_return = np.squeeze(np.asarray(predicted_BUMI_11_return))\n",
        "predicted_BUMI_11_return = predicted_BUMI_11_return.reshape(-1,1)\n",
        "predicted_BUMI_11_return = sc.inverse_transform(predicted_BUMI_11_return)\n",
        "# MFIN\n",
        "predicted_MFIN_11_return = np.squeeze(np.asarray(predicted_MFIN_11_return))\n",
        "predicted_MFIN_11_return = predicted_MFIN_11_return.reshape(-1,1)\n",
        "predicted_MFIN_11_return = sc.inverse_transform(predicted_MFIN_11_return)\n",
        "# EXCL\n",
        "predicted_EXCL_11_return = np.squeeze(np.asarray(predicted_EXCL_11_return))\n",
        "predicted_EXCL_11_return = predicted_EXCL_11_return.reshape(-1,1)\n",
        "predicted_EXCL_11_return = sc.inverse_transform(predicted_EXCL_11_return)\n",
        "# PGAS\n",
        "predicted_PGAS_11_return = np.squeeze(np.asarray(predicted_PGAS_11_return))\n",
        "predicted_PGAS_11_return = predicted_PGAS_11_return.reshape(-1,1)\n",
        "predicted_PGAS_11_return = sc.inverse_transform(predicted_PGAS_11_return)\n",
        "# TLKM\n",
        "predicted_TLKM_11_return = np.squeeze(np.asarray(predicted_TLKM_11_return))\n",
        "predicted_TLKM_11_return = predicted_TLKM_11_return.reshape(-1,1)\n",
        "predicted_TLKM_11_return = sc.inverse_transform(predicted_TLKM_11_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdxctjjYoPmX"
      },
      "outputs": [],
      "source": [
        "predicted11 = pd.DataFrame(predicted_ADRO_11_return)\n",
        "predicted11.rename(columns={0:'ADRO'}, inplace=True)\n",
        "predicted11.insert(1,\"ASII\", predicted_ASII_11_return)\n",
        "predicted11.insert(2,\"BBRI\", predicted_BBRI_11_return)\n",
        "predicted11.insert(3,\"BBTN\", predicted_BBTN_11_return)\n",
        "predicted11.insert(4,\"BMRI\", predicted_BMRI_11_return)\n",
        "predicted11.insert(5,\"BUMI\", predicted_BUMI_11_return)\n",
        "predicted11.insert(6,\"EXCL\", predicted_EXCL_11_return)\n",
        "predicted11.insert(7,\"MFIN\", predicted_MFIN_11_return)\n",
        "predicted11.insert(8,\"PGAS\", predicted_PGAS_11_return)\n",
        "predicted11.insert(9,\"TLKM\", predicted_TLKM_11_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "rjLggVJiSAUu",
        "outputId": "08fbf242-7bfe-40c9-ca29-b271de1dba1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADRO      ASII      BBRI      BBTN      BMRI      BUMI      EXCL  \\\n",
              "0 -0.014619  0.017145  0.002093  0.042702  0.007592  0.031070 -0.052988   \n",
              "1 -0.015170  0.016056  0.001255  0.041500  0.006957  0.030062 -0.053035   \n",
              "2 -0.015835  0.014746  0.000261  0.040047  0.006150  0.028825 -0.053110   \n",
              "3 -0.016633  0.013180 -0.000915  0.038297  0.005132  0.027311 -0.053220   \n",
              "4 -0.017587  0.011315 -0.002300  0.036198  0.003863  0.025464 -0.053372   \n",
              "5 -0.018719  0.009110 -0.003926  0.033691  0.002296  0.023226 -0.053574   \n",
              "6 -0.020054  0.006521 -0.005826  0.030711  0.000380  0.020528 -0.053831   \n",
              "7 -0.021618  0.003507 -0.008035  0.027190 -0.001937  0.017312 -0.054150   \n",
              "8 -0.023434  0.000033 -0.010586  0.023053 -0.004705  0.013505 -0.054531   \n",
              "9 -0.025524 -0.003929 -0.013513  0.018232 -0.007970  0.009047 -0.054973   \n",
              "\n",
              "       MFIN      PGAS      TLKM  \n",
              "0 -0.011197  0.003260  0.004318  \n",
              "1 -0.011690  0.002307  0.003644  \n",
              "2 -0.012302  0.001141  0.002831  \n",
              "3 -0.013056 -0.000270  0.001849  \n",
              "4 -0.013983 -0.001963  0.000666  \n",
              "5 -0.015111 -0.003972 -0.000754  \n",
              "6 -0.016477 -0.006330 -0.002455  \n",
              "7 -0.018117 -0.009066 -0.004482  \n",
              "8 -0.020067 -0.012197 -0.006883  \n",
              "9 -0.022362 -0.015730 -0.009709  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdb11dd9-53ba-47eb-a8e0-1e216eb621b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADRO</th>\n",
              "      <th>ASII</th>\n",
              "      <th>BBRI</th>\n",
              "      <th>BBTN</th>\n",
              "      <th>BMRI</th>\n",
              "      <th>BUMI</th>\n",
              "      <th>EXCL</th>\n",
              "      <th>MFIN</th>\n",
              "      <th>PGAS</th>\n",
              "      <th>TLKM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.014619</td>\n",
              "      <td>0.017145</td>\n",
              "      <td>0.002093</td>\n",
              "      <td>0.042702</td>\n",
              "      <td>0.007592</td>\n",
              "      <td>0.031070</td>\n",
              "      <td>-0.052988</td>\n",
              "      <td>-0.011197</td>\n",
              "      <td>0.003260</td>\n",
              "      <td>0.004318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.015170</td>\n",
              "      <td>0.016056</td>\n",
              "      <td>0.001255</td>\n",
              "      <td>0.041500</td>\n",
              "      <td>0.006957</td>\n",
              "      <td>0.030062</td>\n",
              "      <td>-0.053035</td>\n",
              "      <td>-0.011690</td>\n",
              "      <td>0.002307</td>\n",
              "      <td>0.003644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.015835</td>\n",
              "      <td>0.014746</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.040047</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.028825</td>\n",
              "      <td>-0.053110</td>\n",
              "      <td>-0.012302</td>\n",
              "      <td>0.001141</td>\n",
              "      <td>0.002831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.016633</td>\n",
              "      <td>0.013180</td>\n",
              "      <td>-0.000915</td>\n",
              "      <td>0.038297</td>\n",
              "      <td>0.005132</td>\n",
              "      <td>0.027311</td>\n",
              "      <td>-0.053220</td>\n",
              "      <td>-0.013056</td>\n",
              "      <td>-0.000270</td>\n",
              "      <td>0.001849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.017587</td>\n",
              "      <td>0.011315</td>\n",
              "      <td>-0.002300</td>\n",
              "      <td>0.036198</td>\n",
              "      <td>0.003863</td>\n",
              "      <td>0.025464</td>\n",
              "      <td>-0.053372</td>\n",
              "      <td>-0.013983</td>\n",
              "      <td>-0.001963</td>\n",
              "      <td>0.000666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.018719</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>-0.003926</td>\n",
              "      <td>0.033691</td>\n",
              "      <td>0.002296</td>\n",
              "      <td>0.023226</td>\n",
              "      <td>-0.053574</td>\n",
              "      <td>-0.015111</td>\n",
              "      <td>-0.003972</td>\n",
              "      <td>-0.000754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.020054</td>\n",
              "      <td>0.006521</td>\n",
              "      <td>-0.005826</td>\n",
              "      <td>0.030711</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>0.020528</td>\n",
              "      <td>-0.053831</td>\n",
              "      <td>-0.016477</td>\n",
              "      <td>-0.006330</td>\n",
              "      <td>-0.002455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.021618</td>\n",
              "      <td>0.003507</td>\n",
              "      <td>-0.008035</td>\n",
              "      <td>0.027190</td>\n",
              "      <td>-0.001937</td>\n",
              "      <td>0.017312</td>\n",
              "      <td>-0.054150</td>\n",
              "      <td>-0.018117</td>\n",
              "      <td>-0.009066</td>\n",
              "      <td>-0.004482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.023434</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>-0.010586</td>\n",
              "      <td>0.023053</td>\n",
              "      <td>-0.004705</td>\n",
              "      <td>0.013505</td>\n",
              "      <td>-0.054531</td>\n",
              "      <td>-0.020067</td>\n",
              "      <td>-0.012197</td>\n",
              "      <td>-0.006883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.025524</td>\n",
              "      <td>-0.003929</td>\n",
              "      <td>-0.013513</td>\n",
              "      <td>0.018232</td>\n",
              "      <td>-0.007970</td>\n",
              "      <td>0.009047</td>\n",
              "      <td>-0.054973</td>\n",
              "      <td>-0.022362</td>\n",
              "      <td>-0.015730</td>\n",
              "      <td>-0.009709</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdb11dd9-53ba-47eb-a8e0-1e216eb621b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bdb11dd9-53ba-47eb-a8e0-1e216eb621b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bdb11dd9-53ba-47eb-a8e0-1e216eb621b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aMvmi20iXtZ7",
        "c9SgrfrfsoRa",
        "n4gKUvoiYqN8",
        "fWO-2sVncbua",
        "HNLf1Q4Hcc2j",
        "gm259gTHcf0D",
        "eNrs-XcLcgJ7",
        "GR901b1icghZ",
        "s0n3TGP8cg9z",
        "NfmgwSaychfd",
        "varGnXGtch2T",
        "Kw0DVZbAciU-",
        "oYL6xjHacjIc",
        "XTXhx55ALBcM",
        "xCikAb3Ge85m"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}